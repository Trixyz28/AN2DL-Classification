{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGEgyogRPFYc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Notebook for ANNDL - Homework 1\n",
    "\n",
    "Team: All Is Well\n",
    "\n",
    "Team members: Fatma Hamila, Kodai Takigawa, Zheng Maria Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_QsOhFvo7qr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup\n",
    "Firstly, we need to setup the environment by importing the required libraries, setting the current path (eventually mounting Google Drive), and fixing the random seed for our experiments' reproducibility.\n",
    "\n",
    "The dataset should be present in the same folder of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2682,
     "status": "ok",
     "timestamp": 1667962381289,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "Z9l-AdB1uPvC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "use_drive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zheng\\Documents\\Uni\\Magistrale\\ANNDL\\22-23\\Homework1\\Env\n"
     ]
    }
   ],
   "source": [
    "# Connect to Google Drive\n",
    "# Set path\n",
    "\n",
    "if(use_drive):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/gdrive')\n",
    "    path = \"/gdrive/My Drive/ANNDL/2022-23/Homework1\"\n",
    "    %cd /gdrive/My Drive/ANNDL/2022-23/Homework1\n",
    "else:\n",
    "    path = os.getcwd()\n",
    "    print(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667962381289,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "76iRDDThuZsI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "seed = 23\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tiaTPpzp3xZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data splitting\n",
    "Now the dataset file should be unzipped and split into two parts: a training folder and a validation folder.\n",
    "\n",
    "Two data splitting modes are provided here:\n",
    "- make a random split using the package split-folders,\n",
    "- make a regular split using the function we defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set to True to use the random seed for data splitting\n",
    "random_split = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set to True if we want to split the dataset folder\n",
    "split_dataset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Handle the dataset splitting\n",
    "# Random split: the operation is based on the chosen random seed\n",
    "# Regular split: the operation selects a validation sample per n images (current: n=20)\n",
    "\n",
    "if(split_dataset):\n",
    "    \n",
    "    # Unzip the dataset file\n",
    "    !unzip dataset.zip\n",
    "    \n",
    "    # Import the splitfolders funtion for random splitting\n",
    "    if(random_split):\n",
    "        !pip install split-folders\n",
    "        import splitfolders\n",
    "        \n",
    "        splitfolders.ratio(\"training\", output=\"output\", seed=seed, ratio=(.8, .2), group_prefix=None)\n",
    "        print(\"Random split completed\")\n",
    "    \n",
    "    else:\n",
    "        import glob\n",
    "        import shutil\n",
    "    \n",
    "        path = path + \"/dataset\"\n",
    "        os.chdir(path)\n",
    "        cwd = os.getcwd()\n",
    "        cwd\n",
    "    \n",
    "        os.makedirs(\"validation\", exist_ok=True)\n",
    "    \n",
    "        i = 0\n",
    "        n = 20\n",
    "    \n",
    "        for file in glob.glob(\"training/*/*.jpg\", recursive=True):\n",
    "            if i == n:\n",
    "                old_path = os.path.join(cwd, str(file))\n",
    "                new_path = old_path.replace(\"training\", \"validation\")\n",
    "                print(\"Image: \" + new_path)\n",
    "            \n",
    "                if not os.path.exists(os.path.dirname(new_path)):\n",
    "                    os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
    "            \n",
    "                shutil.move(old_path, new_path)\n",
    "                i = 0\n",
    "                continue\n",
    "            i += 1\n",
    "        print(\"Regular split completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set working paths\n",
    "\n",
    "if(random_split):\n",
    "    data_dir = os.path.join(path, 'dataset')\n",
    "    dataset_dir = os.path.join(data_dir, 'output')\n",
    "    training_dir = os.path.join(dataset_dir, 'train')\n",
    "    validation_dir = os.path.join(dataset_dir, 'val')\n",
    "\n",
    "else:\n",
    "    dataset_dir = cwd\n",
    "    training_dir = os.path.join(dataset_dir, 'training')\n",
    "    validation_dir = os.path.join(dataset_dir, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqDbLz4_rf_c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Mode selection\n",
    "There are different available options for the model: it can be a basic convolutional neural network or based on a pre-trained one.\n",
    "\n",
    "The pre-trained models that we tried out are MobileNetV2, ResNet50V2, VGG19, EfficientNetB7.\n",
    "\n",
    "In transfer learning mode, the parameters of the supernet are freezed temporarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1667962506362,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "iKtdPypGrfPK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Params: [Baseline, Mobilenet, Resnet, VGG, Efficientnet, EfficientnetV2]\n",
    "mode = 'EfficientnetV2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyKeLF_IqD6j",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data pre-processing\n",
    "In this part, data preprocessing is done with the corresponding preprocessing function or with the rescale factor.\n",
    "\n",
    "Data augmentation options are also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import the correct preprocessing function for pre-trained models\n",
    "if mode == 'EfficientnetV2':\n",
    "    from tensorflow.keras.applications.efficientnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667963090875,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "1Twnvp3TuTWq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1667967399878,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "-IKTqKzA4pkf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set to True to apply data augmentation methods\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing function applied\n"
     ]
    }
   ],
   "source": [
    "# Load data with ImageDataGenerator\n",
    "# Other available parameters: width_shift_range = 0.2, height_shift_range = 0.2, zoom_range = 0.15, rotation_range = 20\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "if(mode == 'Baseline'):\n",
    "    train_data_gen = ImageDataGenerator(\n",
    "        rescale = 1/255.\n",
    "    )\n",
    "        \n",
    "    val_data_gen = ImageDataGenerator(\n",
    "        rescale = 1/255.\n",
    "    )\n",
    "    \n",
    "    print(\"Rescaling completed\")\n",
    "    \n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input)\n",
    "    \n",
    "    val_data_gen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input\n",
    "    )\n",
    "        \n",
    "    print(\"Preprocessing function applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2829 images belonging to 8 classes.\n",
      "Found 713 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create iterators\n",
    "train_gen = train_data_gen.flow_from_directory(\n",
    "    directory = training_dir,\n",
    "    target_size = (96,96),\n",
    "    color_mode = 'rgb',\n",
    "    classes = None,\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    seed = seed\n",
    ")\n",
    "\n",
    "val_gen = val_data_gen.flow_from_directory(\n",
    "    directory = validation_dir,\n",
    "    target_size = (96,96),\n",
    "    color_mode = 'rgb',\n",
    "    classes = None,\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    seed = seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define augmented images generator\n",
    "\n",
    "import albumentations as alb\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class AugmentDataGenerator(Sequence):\n",
    "    def __init__(self, datagen, augment=None):\n",
    "        self.datagen = datagen\n",
    "        if augment is None:\n",
    "            self.augment = alb.Compose([])\n",
    "        else:\n",
    "            self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datagen)\n",
    "    \n",
    "    def __getitem__(self, x):\n",
    "        images, *rest = self.datagen[x]\n",
    "        augmented = []\n",
    "        for image in images:\n",
    "            image = self.augment(image=image)['image']\n",
    "            augmented.append(image)\n",
    "        return (np.array(augmented), *rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation applied\n"
     ]
    }
   ],
   "source": [
    "if(data_augmentation):\n",
    "    train_gen = AugmentDataGenerator(train_gen, alb.Compose([\n",
    "        alb.OneOf([\n",
    "            alb.HorizontalFlip(),\n",
    "            alb.VerticalFlip()\n",
    "        ]),\n",
    "        alb.Transpose(),\n",
    "        alb.GaussNoise(),\n",
    "        alb.CoarseDropout(),\n",
    "        alb.RandomBrightnessContrast(),\n",
    "        alb.SafeRotate(limit=20),\n",
    "        alb.OneOf([\n",
    "            alb.OpticalDistortion(),\n",
    "            alb.GridDistortion()\n",
    "        ], p=0.3)\n",
    "    ]))\n",
    "    \n",
    "    print(\"Data augmentation applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7jnjBD2u2tS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hyperparameters setting\n",
    "In this part, the hyperparameters of the model are defining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1667967497148,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "tFigwY1Kx1eH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fix input shape and number of epochs\n",
    "input_shape = (96, 96, 3)\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the categorical focal loss\n",
    "from keras import backend as K\n",
    "\n",
    "def categorical_focal_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Softmax version of focal loss.\n",
    "    When there is a skew between different categories/labels in your data set, you can try to apply this function as a\n",
    "    loss.\n",
    "           m\n",
    "      FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
    "          c=1\n",
    "      where m = number of classes, c = class and o = observation\n",
    "    Parameters:\n",
    "      alpha -- the same as weighing factor in balanced cross entropy. Alpha is used to specify the weight of different\n",
    "      categories/labels, the size of the array needs to be consistent with the number of classes.\n",
    "      gamma -- focusing parameter for modulating factor (1-p)\n",
    "    Default value:\n",
    "      gamma -- 2.0 as mentioned in the paper\n",
    "      alpha -- 0.25 as mentioned in the paper\n",
    "    References:\n",
    "        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
    "        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
    "    Usage:\n",
    "     model.compile(loss=[categorical_focal_loss(alpha=[[.25, .25, .25]], gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = [[.25, .1, .1, .1, .1, .1, .1, .15]]\n",
    "\n",
    "    alpha = np.array(alpha, dtype=np.float32)\n",
    "    \n",
    "    gamma = 2.\n",
    "\n",
    "    \"\"\"\n",
    "    :param y_true: A tensor of the same shape as `y_pred`\n",
    "    :param y_pred: A tensor resulting from a softmax\n",
    "    :return: Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "    # Calculate Cross Entropy\n",
    "    cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "    # Calculate Focal Loss\n",
    "    c_loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "    # Compute mean loss in mini_batch\n",
    "    return K.mean(K.sum(c_loss, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1667967499409,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "5moa_FFb3xX8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define loss\n",
    "loss = tfk.losses.CategoricalCrossentropy()\n",
    "# loss = categorical_focal_loss\n",
    "\n",
    "# Define learning rate\n",
    "lr = 1e-3\n",
    "\n",
    "# Define optimizer for regularization\n",
    "optimizer = tfk.optimizers.Adam(learning_rate = lr, epsilon = 0.1)\n",
    "\n",
    "# Define metrics for evaluation\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# optimizer = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate=lr, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0lT-umHqX8j",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model structure\n",
    "According to the chosen mode, the corresponding model structure is loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use base CNN model\n",
    "if(mode == 'Baseline'):\n",
    "    model = tfk.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(tfkl.Input(shape=input_shape, name='Input'))\n",
    "\n",
    "    # Convolution + Pooling\n",
    "    model.add(tfkl.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    ))\n",
    "    model.add(tfkl.BatchNormalization())\n",
    "    model.add(tfkl.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tfkl.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    ))\n",
    "    model.add(tfkl.BatchNormalization())\n",
    "    model.add(tfkl.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    ))\n",
    "    model.add(tfkl.BatchNormalization())\n",
    "    model.add(tfkl.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(tfkl.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    ))\n",
    "    model.add(tfkl.BatchNormalization())\n",
    "    model.add(tfkl.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(tfkl.Conv2D(\n",
    "        filters=512,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    ))\n",
    "    model.add(tfkl.BatchNormalization())\n",
    "    model.add(tfkl.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    \n",
    "    # Flatten\n",
    "    model.add(tfkl.Flatten(name='Flatten'))\n",
    "\n",
    "    \n",
    "    # Linear layer with ReLU activation\n",
    "    model.add(tfkl.Dense(\n",
    "        units=128,\n",
    "        activation='relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    ))\n",
    "    \n",
    "    # Dropout layer\n",
    "    model.add(tfkl.Dropout(0.2, seed=seed))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(tfkl.Dense(\n",
    "        units=8,\n",
    "        activation='softmax',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
    "        name='Output'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Supernet: EfficientNetV2B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if(mode == 'EfficientnetV2'):\n",
    "    supernet = tfk.applications.EfficientNetV2B0(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_shape = (224, 224, 3)\n",
    "    )\n",
    "#     supernet.trainable = True\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tfkl.Input(shape=input_shape, name='Input'))\n",
    "    model.add(tfkl.Resizing(height=224, width=224))\n",
    "    model.add(supernet)\n",
    "    model.add(tfkl.GlobalAveragePooling2D())\n",
    "    \n",
    "    model.add(tfkl.Dense(\n",
    "        units = 128,\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)))\n",
    "    \n",
    "    model.add(tfkl.Dense(\n",
    "        units = 8,\n",
    "        activation = 'softmax',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDPUj0TwR0rW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model summary and compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnetv2-b0\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 224, 224, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 224, 224, 3)  0           ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['normalization[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 16  4608        ['stem_activation[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_activation (Ac  (None, 112, 112, 16  0          ['block1a_project_bn[0][0]']     \n",
      " tivation)                      )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 56, 56, 64)   9216        ['block1a_project_activation[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 56, 56, 64)  256         ['block2a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 56, 56, 64)  0           ['block2a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 32)   2048        ['block2a_expand_activation[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 32)  128         ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 128)  36864       ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 128)  512        ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 56, 56, 128)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 32)   4096        ['block2b_expand_activation[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 32)  128         ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)         (None, 56, 56, 32)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 56, 56, 32)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 28, 28, 128)  36864       ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 28, 28, 128)  512        ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 28, 28, 128)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 48)   6144        ['block3a_expand_activation[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 48)  192         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 192)  82944       ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 192)  768        ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 28, 28, 192)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 48)   9216        ['block3b_expand_activation[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 48)  192         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)         (None, 28, 28, 48)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 28, 28, 48)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 192)  9216        ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 192)  768        ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 28, 28, 192)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv2 (DepthwiseConv  (None, 14, 14, 192)  1728       ['block4a_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 192)  768        ['block4a_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, 14, 14, 192)  0          ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 192)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 12)     2316        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 192)    2496        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 192)  0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 96)   18432       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 96)  384         ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 384)  36864       ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 384)  1536       ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 14, 14, 384)  0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv2 (DepthwiseConv  (None, 14, 14, 384)  3456       ['block4b_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 384)  1536       ['block4b_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 14, 14, 384)  0          ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 384)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 384)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 24)     9240        ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 384)    9600        ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 384)  0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 96)   36864       ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 96)  384         ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)         (None, 14, 14, 96)   0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 14, 14, 96)   0           ['block4b_drop[0][0]',           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 384)  36864       ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 384)  1536       ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 14, 14, 384)  0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv2 (DepthwiseConv  (None, 14, 14, 384)  3456       ['block4c_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 384)  1536       ['block4c_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 14, 14, 384)  0          ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 384)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 384)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 24)     9240        ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 384)    9600        ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 384)  0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 96)   36864       ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 96)  384         ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)         (None, 14, 14, 96)   0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 14, 14, 96)   0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 576)  55296       ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 576)  2304       ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 14, 14, 576)  0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv2 (DepthwiseConv  (None, 14, 14, 576)  5184       ['block5a_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 576)  2304       ['block5a_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 14, 14, 576)  0          ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 576)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 576)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 24)     13848       ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 576)    14400       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 576)  0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  64512       ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block5b_dwconv2 (DepthwiseConv  (None, 14, 14, 672)  6048       ['block5b_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     \n",
      "                                                                  'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_dwconv2 (DepthwiseConv  (None, 14, 14, 672)  6048       ['block5c_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     \n",
      "                                                                  'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5d_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5d_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5d_expand_activation (Act  (None, 14, 14, 672)  0          ['block5d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5d_dwconv2 (DepthwiseConv  (None, 14, 14, 672)  6048       ['block5d_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block5d_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5d_dwconv2[0][0]']        \n",
      " )                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block5d_activation (Activation  (None, 14, 14, 672)  0          ['block5d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5d_se_squeeze (GlobalAver  (None, 672)         0           ['block5d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5d_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5d_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5d_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5d_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5d_activation[0][0]',     \n",
      "                                                                  'block5d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5d_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5d_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5d_drop (Dropout)         (None, 14, 14, 112)  0           ['block5d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5d_add (Add)              (None, 14, 14, 112)  0           ['block5d_drop[0][0]',           \n",
      "                                                                  'block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5e_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5e_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5e_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5e_expand_activation (Act  (None, 14, 14, 672)  0          ['block5e_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5e_dwconv2 (DepthwiseConv  (None, 14, 14, 672)  6048       ['block5e_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block5e_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5e_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5e_activation (Activation  (None, 14, 14, 672)  0          ['block5e_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5e_se_squeeze (GlobalAver  (None, 672)         0           ['block5e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5e_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5e_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5e_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5e_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5e_activation[0][0]',     \n",
      "                                                                  'block5e_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5e_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5e_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5e_drop (Dropout)         (None, 14, 14, 112)  0           ['block5e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5e_add (Add)              (None, 14, 14, 112)  0           ['block5e_drop[0][0]',           \n",
      "                                                                  'block5d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_dwconv2 (DepthwiseConv  (None, 7, 7, 672)   6048        ['block6a_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_dwconv2 (DepthwiseConv  (None, 7, 7, 1152)  10368       ['block6b_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     \n",
      "                                                                  'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_dwconv2 (DepthwiseConv  (None, 7, 7, 1152)  10368       ['block6c_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     \n",
      "                                                                  'block6c_se_expand[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_dwconv2 (DepthwiseConv  (None, 7, 7, 1152)  10368       ['block6d_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     \n",
      "                                                                  'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6e_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6e_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6e_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6e_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6e_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6e_dwconv2 (DepthwiseConv  (None, 7, 7, 1152)  10368       ['block6e_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block6e_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6e_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6e_activation (Activation  (None, 7, 7, 1152)  0           ['block6e_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6e_se_squeeze (GlobalAver  (None, 1152)        0           ['block6e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6e_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6e_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6e_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6e_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6e_activation[0][0]',     \n",
      "                                                                  'block6e_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6e_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6e_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block6e_drop (Dropout)         (None, 7, 7, 192)    0           ['block6e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6e_add (Add)              (None, 7, 7, 192)    0           ['block6e_drop[0][0]',           \n",
      "                                                                  'block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6f_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6f_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6f_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6f_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6f_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6f_dwconv2 (DepthwiseConv  (None, 7, 7, 1152)  10368       ['block6f_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block6f_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6f_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6f_activation (Activation  (None, 7, 7, 1152)  0           ['block6f_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6f_se_squeeze (GlobalAver  (None, 1152)        0           ['block6f_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6f_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6f_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6f_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6f_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6f_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6f_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6f_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6f_activation[0][0]',     \n",
      "                                                                  'block6f_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6f_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6f_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6f_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6f_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6f_drop (Dropout)         (None, 7, 7, 192)    0           ['block6f_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6f_add (Add)              (None, 7, 7, 192)    0           ['block6f_drop[0][0]',           \n",
      "                                                                  'block6e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6g_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6g_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6g_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6g_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6g_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6g_dwconv2 (DepthwiseConv  (None, 7, 7, 1152)  10368       ['block6g_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block6g_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6g_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6g_activation (Activation  (None, 7, 7, 1152)  0           ['block6g_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6g_se_squeeze (GlobalAver  (None, 1152)        0           ['block6g_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6g_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6g_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6g_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6g_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6g_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6g_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6g_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6g_activation[0][0]',     \n",
      "                                                                  'block6g_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6g_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6g_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6g_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6g_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6g_drop (Dropout)         (None, 7, 7, 192)    0           ['block6g_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6g_add (Add)              (None, 7, 7, 192)    0           ['block6g_drop[0][0]',           \n",
      "                                                                  'block6f_add[0][0]']            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block6h_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6g_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6h_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6h_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6h_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6h_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6h_dwconv2 (DepthwiseConv  (None, 7, 7, 1152)  10368       ['block6h_expand_activation[0][0]\n",
      " 2D)                                                             ']                               \n",
      "                                                                                                  \n",
      " block6h_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6h_dwconv2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6h_activation (Activation  (None, 7, 7, 1152)  0           ['block6h_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6h_se_squeeze (GlobalAver  (None, 1152)        0           ['block6h_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6h_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6h_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6h_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6h_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6h_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6h_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6h_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6h_activation[0][0]',     \n",
      "                                                                  'block6h_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6h_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6h_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6h_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6h_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6h_drop (Dropout)         (None, 7, 7, 192)    0           ['block6h_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6h_add (Add)              (None, 7, 7, 192)    0           ['block6h_drop[0][0]',           \n",
      "                                                                  'block6g_add[0][0]']            \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 7, 7, 1280)   245760      ['block6h_add[0][0]']            \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,919,312\n",
      "Trainable params: 5,858,704\n",
      "Non-trainable params: 60,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if(mode != 'Baseline'):\n",
    "    supernet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 7, 7, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,084,312\n",
      "Trainable params: 6,023,704\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok9qde99qbhC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checkpoint and Early stopping settings\n",
    "Early stopping options can be activated to limit model overfitting.\n",
    "\n",
    "There is possibility to save checkpoints during the training, in order to keep track of the performance and to get more choices of the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\zheng\\\\Documents\\\\Uni\\\\Magistrale\\\\ANNDL\\\\22-23\\\\Homework1\\\\Env'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def create_folders_and_callbacks(model_name):\n",
    "    \n",
    "    exps_dir = os.path.join('experiments')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "\n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "    print(now)\n",
    "\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    # Model checkpoint\n",
    "    ckpt_dir = os.path.join(exp_dir, 'base_ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'),\n",
    "                                                     save_weights_only=False, # True to save only weights\n",
    "                                                     save_best_only=True,# True to save only the best epoch\n",
    "                                                     monitor='val_accuracy')\n",
    "    callbacks.append(ckpt_callback)\n",
    "\n",
    "    # Visualize Learning on Tensorboard\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "\n",
    "    # By default shows losses and metrics for both training and validation\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                               profile_batch=0,\n",
    "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "    callbacks.append(tb_callback)\n",
    "\n",
    "    \n",
    "\n",
    "    return callbacks, now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nov22_23-39-14\n"
     ]
    }
   ],
   "source": [
    "callbacks, date = create_folders_and_callbacks(\"EfficientnetV2B0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientnetV2_Nov22_23-39-14\n"
     ]
    }
   ],
   "source": [
    "foldername = mode + '_' + str(date)\n",
    "print(foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 22s 263ms/step - loss: 2.0969 - accuracy: 0.1276 - val_loss: 2.0985 - val_accuracy: 0.1403\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 2.0717 - accuracy: 0.1605 - val_loss: 2.0582 - val_accuracy: 0.1823\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 10s 224ms/step - loss: 2.0536 - accuracy: 0.1785 - val_loss: 2.0378 - val_accuracy: 0.1711\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 10s 222ms/step - loss: 2.0328 - accuracy: 0.1863 - val_loss: 2.0183 - val_accuracy: 0.1935\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 10s 221ms/step - loss: 2.0109 - accuracy: 0.2131 - val_loss: 1.9685 - val_accuracy: 0.2553\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 10s 218ms/step - loss: 1.9954 - accuracy: 0.2149 - val_loss: 1.9468 - val_accuracy: 0.2693\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 10s 226ms/step - loss: 1.9810 - accuracy: 0.2329 - val_loss: 1.9062 - val_accuracy: 0.2875\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 10s 224ms/step - loss: 1.9599 - accuracy: 0.2464 - val_loss: 1.8881 - val_accuracy: 0.3212\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 10s 220ms/step - loss: 1.9416 - accuracy: 0.2453 - val_loss: 1.8318 - val_accuracy: 0.3520\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 10s 218ms/step - loss: 1.9184 - accuracy: 0.2708 - val_loss: 1.7798 - val_accuracy: 0.3703\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.9008 - accuracy: 0.2715 - val_loss: 1.7439 - val_accuracy: 0.4067\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.8827 - accuracy: 0.2796 - val_loss: 1.7239 - val_accuracy: 0.3955\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.8594 - accuracy: 0.3005 - val_loss: 1.6795 - val_accuracy: 0.4039\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.8616 - accuracy: 0.2930 - val_loss: 1.6135 - val_accuracy: 0.4530\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.8327 - accuracy: 0.3043 - val_loss: 1.5361 - val_accuracy: 0.4769\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.8212 - accuracy: 0.3086 - val_loss: 1.5179 - val_accuracy: 0.4853\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.8044 - accuracy: 0.3199 - val_loss: 1.4756 - val_accuracy: 0.4881\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.7911 - accuracy: 0.3146 - val_loss: 1.3863 - val_accuracy: 0.5203\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.7781 - accuracy: 0.3273 - val_loss: 1.3615 - val_accuracy: 0.5203\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 10s 228ms/step - loss: 1.7658 - accuracy: 0.3238 - val_loss: 1.3419 - val_accuracy: 0.5302\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 10s 219ms/step - loss: 1.7520 - accuracy: 0.3365 - val_loss: 1.2670 - val_accuracy: 0.5288\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.7255 - accuracy: 0.3538 - val_loss: 1.2723 - val_accuracy: 0.5484\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.7241 - accuracy: 0.3411 - val_loss: 1.2104 - val_accuracy: 0.5554\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6985 - accuracy: 0.3510 - val_loss: 1.1706 - val_accuracy: 0.5736\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.7084 - accuracy: 0.3634 - val_loss: 1.1393 - val_accuracy: 0.5849\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 10s 225ms/step - loss: 1.6947 - accuracy: 0.3616 - val_loss: 1.1408 - val_accuracy: 0.5863\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6926 - accuracy: 0.3595 - val_loss: 1.1087 - val_accuracy: 0.5792\n",
      "Epoch 28/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6841 - accuracy: 0.3644 - val_loss: 1.0677 - val_accuracy: 0.6115\n",
      "Epoch 29/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6637 - accuracy: 0.3662 - val_loss: 1.0540 - val_accuracy: 0.6185\n",
      "Epoch 30/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6584 - accuracy: 0.3708 - val_loss: 1.0376 - val_accuracy: 0.6269\n",
      "Epoch 31/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6709 - accuracy: 0.3641 - val_loss: 1.0402 - val_accuracy: 0.6185\n",
      "Epoch 32/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6558 - accuracy: 0.3736 - val_loss: 1.0161 - val_accuracy: 0.6129\n",
      "Epoch 33/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6585 - accuracy: 0.3701 - val_loss: 1.0069 - val_accuracy: 0.6185\n",
      "Epoch 34/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.6391 - accuracy: 0.3832 - val_loss: 0.9477 - val_accuracy: 0.6339\n",
      "Epoch 35/200\n",
      "45/45 [==============================] - 10s 220ms/step - loss: 1.6286 - accuracy: 0.3934 - val_loss: 0.9392 - val_accuracy: 0.6550\n",
      "Epoch 36/200\n",
      "45/45 [==============================] - 10s 218ms/step - loss: 1.6577 - accuracy: 0.3747 - val_loss: 0.9282 - val_accuracy: 0.6564\n",
      "Epoch 37/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.6226 - accuracy: 0.3945 - val_loss: 0.9381 - val_accuracy: 0.6704\n",
      "Epoch 38/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6053 - accuracy: 0.4065 - val_loss: 0.9099 - val_accuracy: 0.6648\n",
      "Epoch 39/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.6217 - accuracy: 0.3786 - val_loss: 0.9015 - val_accuracy: 0.6662\n",
      "Epoch 40/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.6096 - accuracy: 0.3917 - val_loss: 0.8928 - val_accuracy: 0.6662\n",
      "Epoch 41/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.6249 - accuracy: 0.3878 - val_loss: 0.8644 - val_accuracy: 0.6718\n",
      "Epoch 42/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6073 - accuracy: 0.3973 - val_loss: 0.8545 - val_accuracy: 0.6858\n",
      "Epoch 43/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.6016 - accuracy: 0.3917 - val_loss: 0.8510 - val_accuracy: 0.6858\n",
      "Epoch 44/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.5753 - accuracy: 0.4129 - val_loss: 0.8545 - val_accuracy: 0.6886\n",
      "Epoch 45/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5904 - accuracy: 0.4069 - val_loss: 0.8291 - val_accuracy: 0.6985\n",
      "Epoch 46/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5711 - accuracy: 0.4023 - val_loss: 0.8286 - val_accuracy: 0.6999\n",
      "Epoch 47/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5630 - accuracy: 0.4100 - val_loss: 0.7955 - val_accuracy: 0.7125\n",
      "Epoch 48/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.5539 - accuracy: 0.4104 - val_loss: 0.8196 - val_accuracy: 0.6985\n",
      "Epoch 49/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5915 - accuracy: 0.3959 - val_loss: 0.7893 - val_accuracy: 0.7195\n",
      "Epoch 50/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5943 - accuracy: 0.3959 - val_loss: 0.7959 - val_accuracy: 0.7181\n",
      "Epoch 51/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5537 - accuracy: 0.4104 - val_loss: 0.7668 - val_accuracy: 0.7069\n",
      "Epoch 52/200\n",
      "45/45 [==============================] - 10s 219ms/step - loss: 1.5546 - accuracy: 0.4125 - val_loss: 0.7691 - val_accuracy: 0.7181\n",
      "Epoch 53/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.5495 - accuracy: 0.4136 - val_loss: 0.7916 - val_accuracy: 0.7125\n",
      "Epoch 54/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5540 - accuracy: 0.4157 - val_loss: 0.7665 - val_accuracy: 0.7279\n",
      "Epoch 55/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.5588 - accuracy: 0.4136 - val_loss: 0.7557 - val_accuracy: 0.7223\n",
      "Epoch 56/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5432 - accuracy: 0.4111 - val_loss: 0.7384 - val_accuracy: 0.7293\n",
      "Epoch 57/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5427 - accuracy: 0.4221 - val_loss: 0.7764 - val_accuracy: 0.7223\n",
      "Epoch 58/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5337 - accuracy: 0.4203 - val_loss: 0.7311 - val_accuracy: 0.7391\n",
      "Epoch 59/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5401 - accuracy: 0.4206 - val_loss: 0.7384 - val_accuracy: 0.7349\n",
      "Epoch 60/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5184 - accuracy: 0.4305 - val_loss: 0.7214 - val_accuracy: 0.7391\n",
      "Epoch 61/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5354 - accuracy: 0.4288 - val_loss: 0.6944 - val_accuracy: 0.7574\n",
      "Epoch 62/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5241 - accuracy: 0.4323 - val_loss: 0.6998 - val_accuracy: 0.7546\n",
      "Epoch 63/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5126 - accuracy: 0.4348 - val_loss: 0.7108 - val_accuracy: 0.7447\n",
      "Epoch 64/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.4953 - accuracy: 0.4383 - val_loss: 0.7037 - val_accuracy: 0.7658\n",
      "Epoch 65/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.5312 - accuracy: 0.4221 - val_loss: 0.6927 - val_accuracy: 0.7560\n",
      "Epoch 66/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4936 - accuracy: 0.4429 - val_loss: 0.6802 - val_accuracy: 0.7644\n",
      "Epoch 67/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.4791 - accuracy: 0.4475 - val_loss: 0.6609 - val_accuracy: 0.7798\n",
      "Epoch 68/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.5138 - accuracy: 0.4327 - val_loss: 0.6687 - val_accuracy: 0.7700\n",
      "Epoch 69/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4898 - accuracy: 0.4433 - val_loss: 0.6707 - val_accuracy: 0.7658\n",
      "Epoch 70/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.4914 - accuracy: 0.4549 - val_loss: 0.6704 - val_accuracy: 0.7686\n",
      "Epoch 71/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4815 - accuracy: 0.4422 - val_loss: 0.6861 - val_accuracy: 0.7560\n",
      "Epoch 72/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.4774 - accuracy: 0.4482 - val_loss: 0.6536 - val_accuracy: 0.7686\n",
      "Epoch 73/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4733 - accuracy: 0.4397 - val_loss: 0.6496 - val_accuracy: 0.7728\n",
      "Epoch 74/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4641 - accuracy: 0.4440 - val_loss: 0.6353 - val_accuracy: 0.7840\n",
      "Epoch 75/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.4798 - accuracy: 0.4489 - val_loss: 0.6558 - val_accuracy: 0.7784\n",
      "Epoch 76/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.4896 - accuracy: 0.4457 - val_loss: 0.6469 - val_accuracy: 0.7854\n",
      "Epoch 77/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.4466 - accuracy: 0.4723 - val_loss: 0.6237 - val_accuracy: 0.7812\n",
      "Epoch 78/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4549 - accuracy: 0.4581 - val_loss: 0.7274 - val_accuracy: 0.7588\n",
      "Epoch 79/200\n",
      "45/45 [==============================] - 10s 219ms/step - loss: 1.4612 - accuracy: 0.4634 - val_loss: 0.6225 - val_accuracy: 0.7826\n",
      "Epoch 80/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4601 - accuracy: 0.4560 - val_loss: 0.6344 - val_accuracy: 0.7812\n",
      "Epoch 81/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4445 - accuracy: 0.4641 - val_loss: 0.6025 - val_accuracy: 0.7966\n",
      "Epoch 82/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4364 - accuracy: 0.4624 - val_loss: 0.5964 - val_accuracy: 0.7854\n",
      "Epoch 83/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.4268 - accuracy: 0.4698 - val_loss: 0.5826 - val_accuracy: 0.7952\n",
      "Epoch 84/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4362 - accuracy: 0.4744 - val_loss: 0.5988 - val_accuracy: 0.7910\n",
      "Epoch 85/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4386 - accuracy: 0.4571 - val_loss: 0.6059 - val_accuracy: 0.7826\n",
      "Epoch 86/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4454 - accuracy: 0.4609 - val_loss: 0.6437 - val_accuracy: 0.7742\n",
      "Epoch 87/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4082 - accuracy: 0.4797 - val_loss: 0.5684 - val_accuracy: 0.8079\n",
      "Epoch 88/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3922 - accuracy: 0.4892 - val_loss: 0.5989 - val_accuracy: 0.7868\n",
      "Epoch 89/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.4102 - accuracy: 0.4864 - val_loss: 0.5760 - val_accuracy: 0.8008\n",
      "Epoch 90/200\n",
      "45/45 [==============================] - 10s 222ms/step - loss: 1.4280 - accuracy: 0.4680 - val_loss: 0.6601 - val_accuracy: 0.7546\n",
      "Epoch 91/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4112 - accuracy: 0.4850 - val_loss: 0.5819 - val_accuracy: 0.7924\n",
      "Epoch 92/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4058 - accuracy: 0.4857 - val_loss: 0.5700 - val_accuracy: 0.8065\n",
      "Epoch 93/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4573 - accuracy: 0.4553 - val_loss: 0.5905 - val_accuracy: 0.8050\n",
      "Epoch 94/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3914 - accuracy: 0.4906 - val_loss: 0.5887 - val_accuracy: 0.8022\n",
      "Epoch 95/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3877 - accuracy: 0.4945 - val_loss: 0.5899 - val_accuracy: 0.7980\n",
      "Epoch 96/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4304 - accuracy: 0.4708 - val_loss: 0.6122 - val_accuracy: 0.7840\n",
      "Epoch 97/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.3959 - accuracy: 0.4875 - val_loss: 0.5686 - val_accuracy: 0.8008\n",
      "Epoch 98/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3928 - accuracy: 0.4882 - val_loss: 0.5720 - val_accuracy: 0.7994\n",
      "Epoch 99/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.4053 - accuracy: 0.4878 - val_loss: 0.5950 - val_accuracy: 0.7938\n",
      "Epoch 100/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3918 - accuracy: 0.4857 - val_loss: 0.5974 - val_accuracy: 0.7896\n",
      "Epoch 101/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3706 - accuracy: 0.4860 - val_loss: 0.5498 - val_accuracy: 0.8149\n",
      "Epoch 102/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3898 - accuracy: 0.4973 - val_loss: 0.6044 - val_accuracy: 0.7924\n",
      "Epoch 103/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3978 - accuracy: 0.4896 - val_loss: 0.6001 - val_accuracy: 0.7910\n",
      "Epoch 104/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.3848 - accuracy: 0.4920 - val_loss: 0.5588 - val_accuracy: 0.8036\n",
      "Epoch 105/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3934 - accuracy: 0.4892 - val_loss: 0.5716 - val_accuracy: 0.7896\n",
      "Epoch 106/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3580 - accuracy: 0.5012 - val_loss: 0.5656 - val_accuracy: 0.8079\n",
      "Epoch 107/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3799 - accuracy: 0.4871 - val_loss: 0.5625 - val_accuracy: 0.8050\n",
      "Epoch 108/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3701 - accuracy: 0.4913 - val_loss: 0.5943 - val_accuracy: 0.7812\n",
      "Epoch 109/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3691 - accuracy: 0.5012 - val_loss: 0.5716 - val_accuracy: 0.8065\n",
      "Epoch 110/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3526 - accuracy: 0.5094 - val_loss: 0.5486 - val_accuracy: 0.8079\n",
      "Epoch 111/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3621 - accuracy: 0.5090 - val_loss: 0.5004 - val_accuracy: 0.8401\n",
      "Epoch 112/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3712 - accuracy: 0.5009 - val_loss: 0.5232 - val_accuracy: 0.8177\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3431 - accuracy: 0.5157 - val_loss: 0.5203 - val_accuracy: 0.8247\n",
      "Epoch 114/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3509 - accuracy: 0.5157 - val_loss: 0.5447 - val_accuracy: 0.8107\n",
      "Epoch 115/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3503 - accuracy: 0.5147 - val_loss: 0.5248 - val_accuracy: 0.8205\n",
      "Epoch 116/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3383 - accuracy: 0.5133 - val_loss: 0.5334 - val_accuracy: 0.8149\n",
      "Epoch 117/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3378 - accuracy: 0.5171 - val_loss: 0.5204 - val_accuracy: 0.8205\n",
      "Epoch 118/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3291 - accuracy: 0.5232 - val_loss: 0.5309 - val_accuracy: 0.8233\n",
      "Epoch 119/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3071 - accuracy: 0.5182 - val_loss: 0.5324 - val_accuracy: 0.8050\n",
      "Epoch 120/200\n",
      "45/45 [==============================] - 10s 220ms/step - loss: 1.3228 - accuracy: 0.5182 - val_loss: 0.5530 - val_accuracy: 0.8163\n",
      "Epoch 121/200\n",
      "45/45 [==============================] - 10s 218ms/step - loss: 1.3334 - accuracy: 0.5129 - val_loss: 0.5452 - val_accuracy: 0.8135\n",
      "Epoch 122/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3385 - accuracy: 0.5108 - val_loss: 0.5183 - val_accuracy: 0.8247\n",
      "Epoch 123/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3157 - accuracy: 0.5171 - val_loss: 0.5229 - val_accuracy: 0.8233\n",
      "Epoch 124/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3270 - accuracy: 0.5175 - val_loss: 0.5652 - val_accuracy: 0.7938\n",
      "Epoch 125/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3295 - accuracy: 0.5101 - val_loss: 0.5458 - val_accuracy: 0.8050\n",
      "Epoch 126/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3339 - accuracy: 0.5097 - val_loss: 0.5215 - val_accuracy: 0.8247\n",
      "Epoch 127/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3259 - accuracy: 0.5210 - val_loss: 0.5335 - val_accuracy: 0.8107\n",
      "Epoch 128/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.2963 - accuracy: 0.5242 - val_loss: 0.5186 - val_accuracy: 0.8275\n",
      "Epoch 129/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2991 - accuracy: 0.5295 - val_loss: 0.5183 - val_accuracy: 0.8247\n",
      "Epoch 130/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3179 - accuracy: 0.5235 - val_loss: 0.5189 - val_accuracy: 0.8135\n",
      "Epoch 131/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3170 - accuracy: 0.5224 - val_loss: 0.6114 - val_accuracy: 0.7952\n",
      "Epoch 132/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.3204 - accuracy: 0.5221 - val_loss: 0.5369 - val_accuracy: 0.8177\n",
      "Epoch 133/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3083 - accuracy: 0.5235 - val_loss: 0.5068 - val_accuracy: 0.8303\n",
      "Epoch 134/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3186 - accuracy: 0.5217 - val_loss: 0.5052 - val_accuracy: 0.8275\n",
      "Epoch 135/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2903 - accuracy: 0.5285 - val_loss: 0.4845 - val_accuracy: 0.8247\n",
      "Epoch 136/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.2884 - accuracy: 0.5419 - val_loss: 0.5267 - val_accuracy: 0.8135\n",
      "Epoch 137/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2899 - accuracy: 0.5391 - val_loss: 0.4980 - val_accuracy: 0.8359\n",
      "Epoch 138/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2965 - accuracy: 0.5334 - val_loss: 0.5160 - val_accuracy: 0.8093\n",
      "Epoch 139/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2692 - accuracy: 0.5422 - val_loss: 0.4898 - val_accuracy: 0.8233\n",
      "Epoch 140/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.3124 - accuracy: 0.5249 - val_loss: 0.5462 - val_accuracy: 0.8093\n",
      "Epoch 141/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2847 - accuracy: 0.5391 - val_loss: 0.5069 - val_accuracy: 0.8233\n",
      "Epoch 142/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2740 - accuracy: 0.5550 - val_loss: 0.5032 - val_accuracy: 0.8261\n",
      "Epoch 143/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2978 - accuracy: 0.5366 - val_loss: 0.4917 - val_accuracy: 0.8317\n",
      "Epoch 144/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2856 - accuracy: 0.5391 - val_loss: 0.4950 - val_accuracy: 0.8289\n",
      "Epoch 145/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2740 - accuracy: 0.5458 - val_loss: 0.4899 - val_accuracy: 0.8303\n",
      "Epoch 146/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2774 - accuracy: 0.5543 - val_loss: 0.4782 - val_accuracy: 0.8261\n",
      "Epoch 147/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2389 - accuracy: 0.5490 - val_loss: 0.4880 - val_accuracy: 0.8345\n",
      "Epoch 148/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2447 - accuracy: 0.5546 - val_loss: 0.4805 - val_accuracy: 0.8345\n",
      "Epoch 149/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2928 - accuracy: 0.5316 - val_loss: 0.4972 - val_accuracy: 0.8289\n",
      "Epoch 150/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2673 - accuracy: 0.5465 - val_loss: 0.4736 - val_accuracy: 0.8373\n",
      "Epoch 151/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2496 - accuracy: 0.5581 - val_loss: 0.4782 - val_accuracy: 0.8345\n",
      "Epoch 152/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2759 - accuracy: 0.5369 - val_loss: 0.5003 - val_accuracy: 0.8205\n",
      "Epoch 153/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2698 - accuracy: 0.5518 - val_loss: 0.4775 - val_accuracy: 0.8345\n",
      "Epoch 154/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.2681 - accuracy: 0.5429 - val_loss: 0.5517 - val_accuracy: 0.8065\n",
      "Epoch 155/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2486 - accuracy: 0.5613 - val_loss: 0.5094 - val_accuracy: 0.8177\n",
      "Epoch 156/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2423 - accuracy: 0.5532 - val_loss: 0.4593 - val_accuracy: 0.8401\n",
      "Epoch 157/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2176 - accuracy: 0.5634 - val_loss: 0.4593 - val_accuracy: 0.8359\n",
      "Epoch 158/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2500 - accuracy: 0.5581 - val_loss: 0.4985 - val_accuracy: 0.8289\n",
      "Epoch 159/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2428 - accuracy: 0.5578 - val_loss: 0.4539 - val_accuracy: 0.8443\n",
      "Epoch 160/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2332 - accuracy: 0.5550 - val_loss: 0.4564 - val_accuracy: 0.8415\n",
      "Epoch 161/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2427 - accuracy: 0.5483 - val_loss: 0.4642 - val_accuracy: 0.8317\n",
      "Epoch 162/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2321 - accuracy: 0.5716 - val_loss: 0.4535 - val_accuracy: 0.8443\n",
      "Epoch 163/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.2463 - accuracy: 0.5475 - val_loss: 0.4537 - val_accuracy: 0.8373\n",
      "Epoch 164/200\n",
      "45/45 [==============================] - 10s 219ms/step - loss: 1.2244 - accuracy: 0.5613 - val_loss: 0.4708 - val_accuracy: 0.8373\n",
      "Epoch 165/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.2255 - accuracy: 0.5659 - val_loss: 0.4620 - val_accuracy: 0.8359\n",
      "Epoch 166/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2203 - accuracy: 0.5624 - val_loss: 0.4566 - val_accuracy: 0.8429\n",
      "Epoch 167/200\n",
      "45/45 [==============================] - 10s 219ms/step - loss: 1.2226 - accuracy: 0.5634 - val_loss: 0.4391 - val_accuracy: 0.8555\n",
      "Epoch 168/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2040 - accuracy: 0.5645 - val_loss: 0.4647 - val_accuracy: 0.8401\n",
      "Epoch 169/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2365 - accuracy: 0.5634 - val_loss: 0.4686 - val_accuracy: 0.8429\n",
      "Epoch 170/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2310 - accuracy: 0.5652 - val_loss: 0.4613 - val_accuracy: 0.8485\n",
      "Epoch 171/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2374 - accuracy: 0.5589 - val_loss: 0.4751 - val_accuracy: 0.8415\n",
      "Epoch 172/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2367 - accuracy: 0.5525 - val_loss: 0.4741 - val_accuracy: 0.8317\n",
      "Epoch 173/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2424 - accuracy: 0.5603 - val_loss: 0.4597 - val_accuracy: 0.8429\n",
      "Epoch 174/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2195 - accuracy: 0.5581 - val_loss: 0.4412 - val_accuracy: 0.8541\n",
      "Epoch 175/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2153 - accuracy: 0.5709 - val_loss: 0.4584 - val_accuracy: 0.8443\n",
      "Epoch 176/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2402 - accuracy: 0.5528 - val_loss: 0.4307 - val_accuracy: 0.8541\n",
      "Epoch 177/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2056 - accuracy: 0.5613 - val_loss: 0.4513 - val_accuracy: 0.8485\n",
      "Epoch 178/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2000 - accuracy: 0.5642 - val_loss: 0.4294 - val_accuracy: 0.8499\n",
      "Epoch 179/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.2061 - accuracy: 0.5649 - val_loss: 0.4250 - val_accuracy: 0.8612\n",
      "Epoch 180/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1778 - accuracy: 0.5794 - val_loss: 0.4375 - val_accuracy: 0.8513\n",
      "Epoch 181/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1988 - accuracy: 0.5691 - val_loss: 0.4427 - val_accuracy: 0.8569\n",
      "Epoch 182/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.2021 - accuracy: 0.5779 - val_loss: 0.4444 - val_accuracy: 0.8373\n",
      "Epoch 183/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2226 - accuracy: 0.5680 - val_loss: 0.4530 - val_accuracy: 0.8401\n",
      "Epoch 184/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2365 - accuracy: 0.5603 - val_loss: 0.4546 - val_accuracy: 0.8415\n",
      "Epoch 185/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1994 - accuracy: 0.5772 - val_loss: 0.4631 - val_accuracy: 0.8429\n",
      "Epoch 186/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2088 - accuracy: 0.5758 - val_loss: 0.4736 - val_accuracy: 0.8387\n",
      "Epoch 187/200\n",
      "45/45 [==============================] - 10s 215ms/step - loss: 1.1858 - accuracy: 0.5765 - val_loss: 0.4458 - val_accuracy: 0.8429\n",
      "Epoch 188/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1830 - accuracy: 0.5811 - val_loss: 0.4907 - val_accuracy: 0.8345\n",
      "Epoch 189/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2222 - accuracy: 0.5649 - val_loss: 0.4310 - val_accuracy: 0.8569\n",
      "Epoch 190/200\n",
      "45/45 [==============================] - 10s 218ms/step - loss: 1.2091 - accuracy: 0.5631 - val_loss: 0.4328 - val_accuracy: 0.8499\n",
      "Epoch 191/200\n",
      "45/45 [==============================] - 10s 217ms/step - loss: 1.1853 - accuracy: 0.5656 - val_loss: 0.4750 - val_accuracy: 0.8345\n",
      "Epoch 192/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1896 - accuracy: 0.5673 - val_loss: 0.4435 - val_accuracy: 0.8513\n",
      "Epoch 193/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1972 - accuracy: 0.5751 - val_loss: 0.4264 - val_accuracy: 0.8569\n",
      "Epoch 194/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2093 - accuracy: 0.5730 - val_loss: 0.4657 - val_accuracy: 0.8359\n",
      "Epoch 195/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.2000 - accuracy: 0.5719 - val_loss: 0.4338 - val_accuracy: 0.8485\n",
      "Epoch 196/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1923 - accuracy: 0.5786 - val_loss: 0.4232 - val_accuracy: 0.8612\n",
      "Epoch 197/200\n",
      "45/45 [==============================] - 10s 226ms/step - loss: 1.1925 - accuracy: 0.5709 - val_loss: 0.4730 - val_accuracy: 0.8317\n",
      "Epoch 198/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1753 - accuracy: 0.5730 - val_loss: 0.4237 - val_accuracy: 0.8597\n",
      "Epoch 199/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1928 - accuracy: 0.5741 - val_loss: 0.4282 - val_accuracy: 0.8612\n",
      "Epoch 200/200\n",
      "45/45 [==============================] - 10s 216ms/step - loss: 1.1737 - accuracy: 0.5719 - val_loss: 0.4395 - val_accuracy: 0.8471\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = train_gen,\n",
    "    validation_data = val_gen,\n",
    "    epochs = 200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1991 - accuracy: 0.5712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_01.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_01.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 62s 1s/step - loss: 1.1991 - accuracy: 0.5712 - val_loss: 0.4414 - val_accuracy: 0.8541\n",
      "Epoch 2/800\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 1.1683 - accuracy: 0.5794 - val_loss: 0.4515 - val_accuracy: 0.8373\n",
      "Epoch 3/800\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 1.1957 - accuracy: 0.5737 - val_loss: 0.4419 - val_accuracy: 0.8457\n",
      "Epoch 4/800\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 1.1538 - accuracy: 0.5857 - val_loss: 0.4437 - val_accuracy: 0.8527\n",
      "Epoch 5/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1514 - accuracy: 0.5917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_05.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_05.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 60s 1s/step - loss: 1.1514 - accuracy: 0.5917 - val_loss: 0.4305 - val_accuracy: 0.8555\n",
      "Epoch 6/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1771 - accuracy: 0.5832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_06.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_06.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 61s 1s/step - loss: 1.1771 - accuracy: 0.5832 - val_loss: 0.4291 - val_accuracy: 0.8597\n",
      "Epoch 7/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1727 - accuracy: 0.5744 - val_loss: 0.4502 - val_accuracy: 0.8541\n",
      "Epoch 8/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1707 - accuracy: 0.5748 - val_loss: 0.4543 - val_accuracy: 0.8443\n",
      "Epoch 9/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1763 - accuracy: 0.5762 - val_loss: 0.4448 - val_accuracy: 0.8471\n",
      "Epoch 10/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1506 - accuracy: 0.5903 - val_loss: 0.4559 - val_accuracy: 0.8499\n",
      "Epoch 11/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1385 - accuracy: 0.5885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_11.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_11.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 60s 1s/step - loss: 1.1385 - accuracy: 0.5885 - val_loss: 0.4171 - val_accuracy: 0.8626\n",
      "Epoch 12/800\n",
      "45/45 [==============================] - 12s 247ms/step - loss: 1.1677 - accuracy: 0.5811 - val_loss: 0.4271 - val_accuracy: 0.8612\n",
      "Epoch 13/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1765 - accuracy: 0.5751 - val_loss: 0.4596 - val_accuracy: 0.8401\n",
      "Epoch 14/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1883 - accuracy: 0.5755 - val_loss: 0.4472 - val_accuracy: 0.8387\n",
      "Epoch 15/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1711 - accuracy: 0.5885 - val_loss: 0.4393 - val_accuracy: 0.8555\n",
      "Epoch 16/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1256 - accuracy: 0.5935 - val_loss: 0.4262 - val_accuracy: 0.8569\n",
      "Epoch 17/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1685 - accuracy: 0.5861 - val_loss: 0.4383 - val_accuracy: 0.8541\n",
      "Epoch 18/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1339 - accuracy: 0.5946 - val_loss: 0.4264 - val_accuracy: 0.8583\n",
      "Epoch 19/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1209 - accuracy: 0.5995 - val_loss: 0.4302 - val_accuracy: 0.8569\n",
      "Epoch 20/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1710 - accuracy: 0.5786 - val_loss: 0.4428 - val_accuracy: 0.8583\n",
      "Epoch 21/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1411 - accuracy: 0.5822 - val_loss: 0.4520 - val_accuracy: 0.8527\n",
      "Epoch 22/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1490 - accuracy: 0.5977 - val_loss: 0.4149 - val_accuracy: 0.8626\n",
      "Epoch 23/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1718 - accuracy: 0.5864 - val_loss: 0.4224 - val_accuracy: 0.8612\n",
      "Epoch 24/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1894 - accuracy: 0.5698 - val_loss: 0.4324 - val_accuracy: 0.8513\n",
      "Epoch 25/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1703 - accuracy: 0.5786 - val_loss: 0.4083 - val_accuracy: 0.8555\n",
      "Epoch 26/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1647 - accuracy: 0.5762 - val_loss: 0.4244 - val_accuracy: 0.8555\n",
      "Epoch 27/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1557 - accuracy: 0.5931 - val_loss: 0.4344 - val_accuracy: 0.8443\n",
      "Epoch 28/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1522 - accuracy: 0.5832 - val_loss: 0.4249 - val_accuracy: 0.8527\n",
      "Epoch 29/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1613 - accuracy: 0.5850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_29.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_29.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 61s 1s/step - loss: 1.1613 - accuracy: 0.5850 - val_loss: 0.4063 - val_accuracy: 0.8668\n",
      "Epoch 30/800\n",
      "45/45 [==============================] - 12s 247ms/step - loss: 1.1523 - accuracy: 0.5914 - val_loss: 0.4180 - val_accuracy: 0.8612\n",
      "Epoch 31/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1643 - accuracy: 0.5829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_31.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_31.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 60s 1s/step - loss: 1.1643 - accuracy: 0.5829 - val_loss: 0.4026 - val_accuracy: 0.8724\n",
      "Epoch 32/800\n",
      "45/45 [==============================] - 12s 249ms/step - loss: 1.1341 - accuracy: 0.6030 - val_loss: 0.3978 - val_accuracy: 0.8654\n",
      "Epoch 33/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.1447 - accuracy: 0.5900 - val_loss: 0.4069 - val_accuracy: 0.8668\n",
      "Epoch 34/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1407 - accuracy: 0.6009 - val_loss: 0.4037 - val_accuracy: 0.8668\n",
      "Epoch 35/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1595 - accuracy: 0.5843 - val_loss: 0.4183 - val_accuracy: 0.8626\n",
      "Epoch 36/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1571 - accuracy: 0.5815 - val_loss: 0.4211 - val_accuracy: 0.8541\n",
      "Epoch 37/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1454 - accuracy: 0.5854 - val_loss: 0.3964 - val_accuracy: 0.8668\n",
      "Epoch 38/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1565 - accuracy: 0.5744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_38.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_38.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 62s 1s/step - loss: 1.1565 - accuracy: 0.5744 - val_loss: 0.3912 - val_accuracy: 0.8752\n",
      "Epoch 39/800\n",
      "45/45 [==============================] - 12s 248ms/step - loss: 1.1651 - accuracy: 0.5779 - val_loss: 0.4520 - val_accuracy: 0.8527\n",
      "Epoch 40/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1413 - accuracy: 0.5931 - val_loss: 0.4205 - val_accuracy: 0.8640\n",
      "Epoch 41/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1545 - accuracy: 0.5829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_41.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_41.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 60s 1s/step - loss: 1.1545 - accuracy: 0.5829 - val_loss: 0.3913 - val_accuracy: 0.8794\n",
      "Epoch 42/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1288 - accuracy: 0.6023 - val_loss: 0.4104 - val_accuracy: 0.8710\n",
      "Epoch 43/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0942 - accuracy: 0.6214 - val_loss: 0.3983 - val_accuracy: 0.8752\n",
      "Epoch 44/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.1388 - accuracy: 0.5868 - val_loss: 0.3994 - val_accuracy: 0.8766\n",
      "Epoch 45/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 1.1219 - accuracy: 0.5924 - val_loss: 0.4095 - val_accuracy: 0.8640\n",
      "Epoch 46/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1355 - accuracy: 0.5953 - val_loss: 0.3874 - val_accuracy: 0.8752\n",
      "Epoch 47/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1006 - accuracy: 0.6013 - val_loss: 0.4145 - val_accuracy: 0.8668\n",
      "Epoch 48/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1116 - accuracy: 0.5928 - val_loss: 0.4252 - val_accuracy: 0.8513\n",
      "Epoch 49/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1181 - accuracy: 0.6037 - val_loss: 0.4103 - val_accuracy: 0.8626\n",
      "Epoch 50/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1191 - accuracy: 0.5988 - val_loss: 0.3928 - val_accuracy: 0.8724\n",
      "Epoch 51/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 1.1366 - accuracy: 0.5854 - val_loss: 0.3930 - val_accuracy: 0.8724\n",
      "Epoch 52/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.0894 - accuracy: 0.6122 - val_loss: 0.4014 - val_accuracy: 0.8668\n",
      "Epoch 53/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.1116 - accuracy: 0.5967 - val_loss: 0.4085 - val_accuracy: 0.8668\n",
      "Epoch 54/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0967 - accuracy: 0.6034 - val_loss: 0.3984 - val_accuracy: 0.8654\n",
      "Epoch 55/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.1397 - accuracy: 0.5946 - val_loss: 0.4178 - val_accuracy: 0.8612\n",
      "Epoch 56/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1337 - accuracy: 0.5967 - val_loss: 0.4069 - val_accuracy: 0.8682\n",
      "Epoch 57/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0965 - accuracy: 0.6101 - val_loss: 0.4082 - val_accuracy: 0.8583\n",
      "Epoch 58/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1357 - accuracy: 0.5960 - val_loss: 0.3878 - val_accuracy: 0.8668\n",
      "Epoch 59/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0838 - accuracy: 0.6105 - val_loss: 0.4069 - val_accuracy: 0.8696\n",
      "Epoch 60/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1276 - accuracy: 0.5981 - val_loss: 0.4194 - val_accuracy: 0.8766\n",
      "Epoch 61/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0866 - accuracy: 0.6076 - val_loss: 0.4031 - val_accuracy: 0.8668\n",
      "Epoch 62/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0777 - accuracy: 0.6133 - val_loss: 0.4028 - val_accuracy: 0.8738\n",
      "Epoch 63/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1204 - accuracy: 0.5977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_63.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_63.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 63s 1s/step - loss: 1.1204 - accuracy: 0.5977 - val_loss: 0.3894 - val_accuracy: 0.8864\n",
      "Epoch 64/800\n",
      "45/45 [==============================] - 12s 248ms/step - loss: 1.0999 - accuracy: 0.6052 - val_loss: 0.3750 - val_accuracy: 0.8794\n",
      "Epoch 65/800\n",
      "45/45 [==============================] - 11s 247ms/step - loss: 1.1008 - accuracy: 0.6062 - val_loss: 0.4063 - val_accuracy: 0.8640\n",
      "Epoch 66/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.0999 - accuracy: 0.6087 - val_loss: 0.4096 - val_accuracy: 0.8696\n",
      "Epoch 67/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1071 - accuracy: 0.6062 - val_loss: 0.3889 - val_accuracy: 0.8808\n",
      "Epoch 68/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1160 - accuracy: 0.5977 - val_loss: 0.3781 - val_accuracy: 0.8836\n",
      "Epoch 69/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1108 - accuracy: 0.6030 - val_loss: 0.4172 - val_accuracy: 0.8682\n",
      "Epoch 70/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1010 - accuracy: 0.5992 - val_loss: 0.4190 - val_accuracy: 0.8738\n",
      "Epoch 71/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.1302 - accuracy: 0.5903 - val_loss: 0.3749 - val_accuracy: 0.8808\n",
      "Epoch 72/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0916 - accuracy: 0.6059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_72.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_72.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 61s 1s/step - loss: 1.0916 - accuracy: 0.6059 - val_loss: 0.3639 - val_accuracy: 0.8906\n",
      "Epoch 73/800\n",
      "45/45 [==============================] - 12s 253ms/step - loss: 1.0989 - accuracy: 0.6129 - val_loss: 0.3905 - val_accuracy: 0.8766\n",
      "Epoch 74/800\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 1.0756 - accuracy: 0.6260 - val_loss: 0.3942 - val_accuracy: 0.8738\n",
      "Epoch 75/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0998 - accuracy: 0.6041 - val_loss: 0.3998 - val_accuracy: 0.8738\n",
      "Epoch 76/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0988 - accuracy: 0.6055 - val_loss: 0.3715 - val_accuracy: 0.8850\n",
      "Epoch 77/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1174 - accuracy: 0.6059 - val_loss: 0.3874 - val_accuracy: 0.8808\n",
      "Epoch 78/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.1016 - accuracy: 0.5995 - val_loss: 0.3859 - val_accuracy: 0.8808\n",
      "Epoch 79/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0946 - accuracy: 0.6048 - val_loss: 0.3765 - val_accuracy: 0.8864\n",
      "Epoch 80/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0758 - accuracy: 0.6133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_80.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_80.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 61s 1s/step - loss: 1.0758 - accuracy: 0.6133 - val_loss: 0.3872 - val_accuracy: 0.8920\n",
      "Epoch 81/800\n",
      "45/45 [==============================] - 12s 249ms/step - loss: 1.0829 - accuracy: 0.6041 - val_loss: 0.4084 - val_accuracy: 0.8738\n",
      "Epoch 82/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0574 - accuracy: 0.6221 - val_loss: 0.3737 - val_accuracy: 0.8822\n",
      "Epoch 83/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0793 - accuracy: 0.6154 - val_loss: 0.3786 - val_accuracy: 0.8808\n",
      "Epoch 84/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0696 - accuracy: 0.6281 - val_loss: 0.3863 - val_accuracy: 0.8780\n",
      "Epoch 85/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0879 - accuracy: 0.5999 - val_loss: 0.3940 - val_accuracy: 0.8822\n",
      "Epoch 86/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0861 - accuracy: 0.6151 - val_loss: 0.3874 - val_accuracy: 0.8794\n",
      "Epoch 87/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.1140 - accuracy: 0.5995 - val_loss: 0.3908 - val_accuracy: 0.8808\n",
      "Epoch 88/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1028 - accuracy: 0.6087 - val_loss: 0.3969 - val_accuracy: 0.8808\n",
      "Epoch 89/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0902 - accuracy: 0.6129 - val_loss: 0.3967 - val_accuracy: 0.8808\n",
      "Epoch 90/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0956 - accuracy: 0.6136 - val_loss: 0.4121 - val_accuracy: 0.8766\n",
      "Epoch 91/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.1031 - accuracy: 0.5977 - val_loss: 0.3957 - val_accuracy: 0.8780\n",
      "Epoch 92/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0924 - accuracy: 0.6172 - val_loss: 0.3812 - val_accuracy: 0.8794\n",
      "Epoch 93/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0725 - accuracy: 0.6186 - val_loss: 0.3769 - val_accuracy: 0.8906\n",
      "Epoch 94/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0922 - accuracy: 0.6083 - val_loss: 0.3813 - val_accuracy: 0.8878\n",
      "Epoch 95/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0716 - accuracy: 0.6182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_95.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_95.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 63s 1s/step - loss: 1.0716 - accuracy: 0.6182 - val_loss: 0.3740 - val_accuracy: 0.8934\n",
      "Epoch 96/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.0727 - accuracy: 0.6211 - val_loss: 0.3632 - val_accuracy: 0.8920\n",
      "Epoch 97/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0618 - accuracy: 0.6288 - val_loss: 0.4021 - val_accuracy: 0.8724\n",
      "Epoch 98/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0630 - accuracy: 0.6214 - val_loss: 0.3734 - val_accuracy: 0.8892\n",
      "Epoch 99/800\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 1.0583 - accuracy: 0.6182 - val_loss: 0.3907 - val_accuracy: 0.8878\n",
      "Epoch 100/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0856 - accuracy: 0.6151 - val_loss: 0.3881 - val_accuracy: 0.8850\n",
      "Epoch 101/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0716 - accuracy: 0.6218 - val_loss: 0.3817 - val_accuracy: 0.8836\n",
      "Epoch 102/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0716 - accuracy: 0.6161 - val_loss: 0.3777 - val_accuracy: 0.8878\n",
      "Epoch 103/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0836 - accuracy: 0.6080 - val_loss: 0.3872 - val_accuracy: 0.8864\n",
      "Epoch 104/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0850 - accuracy: 0.6108 - val_loss: 0.3784 - val_accuracy: 0.8864\n",
      "Epoch 105/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0723 - accuracy: 0.6122 - val_loss: 0.3884 - val_accuracy: 0.8864\n",
      "Epoch 106/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0770 - accuracy: 0.6189 - val_loss: 0.3829 - val_accuracy: 0.8878\n",
      "Epoch 107/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0763 - accuracy: 0.6112 - val_loss: 0.3723 - val_accuracy: 0.8906\n",
      "Epoch 108/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0559 - accuracy: 0.6207 - val_loss: 0.3777 - val_accuracy: 0.8864\n",
      "Epoch 109/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0590 - accuracy: 0.6179 - val_loss: 0.4179 - val_accuracy: 0.8710\n",
      "Epoch 110/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0731 - accuracy: 0.6126"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_110.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_110.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 61s 1s/step - loss: 1.0731 - accuracy: 0.6126 - val_loss: 0.3703 - val_accuracy: 0.8948\n",
      "Epoch 111/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 1.0441 - accuracy: 0.6239 - val_loss: 0.3707 - val_accuracy: 0.8906\n",
      "Epoch 112/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0647 - accuracy: 0.6165 - val_loss: 0.3746 - val_accuracy: 0.8794\n",
      "Epoch 113/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0488 - accuracy: 0.6271 - val_loss: 0.3980 - val_accuracy: 0.8738\n",
      "Epoch 114/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0818 - accuracy: 0.6069 - val_loss: 0.3699 - val_accuracy: 0.8920\n",
      "Epoch 115/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0688 - accuracy: 0.6225 - val_loss: 0.3976 - val_accuracy: 0.8836\n",
      "Epoch 116/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 1.0162 - accuracy: 0.6433 - val_loss: 0.3926 - val_accuracy: 0.8780\n",
      "Epoch 117/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0843 - accuracy: 0.6168 - val_loss: 0.3951 - val_accuracy: 0.8878\n",
      "Epoch 118/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0244 - accuracy: 0.6257 - val_loss: 0.3712 - val_accuracy: 0.8906\n",
      "Epoch 119/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0663 - accuracy: 0.6211 - val_loss: 0.3811 - val_accuracy: 0.8906\n",
      "Epoch 120/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0796 - accuracy: 0.6122 - val_loss: 0.4121 - val_accuracy: 0.8794\n",
      "Epoch 121/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0747 - accuracy: 0.6182 - val_loss: 0.3669 - val_accuracy: 0.8934\n",
      "Epoch 122/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0409 - accuracy: 0.6281 - val_loss: 0.3666 - val_accuracy: 0.8850\n",
      "Epoch 123/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0516 - accuracy: 0.6200 - val_loss: 0.3609 - val_accuracy: 0.8836\n",
      "Epoch 124/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0461 - accuracy: 0.6264 - val_loss: 0.3787 - val_accuracy: 0.8906\n",
      "Epoch 125/800\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 1.0705 - accuracy: 0.6246 - val_loss: 0.3514 - val_accuracy: 0.8906\n",
      "Epoch 126/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0620 - accuracy: 0.6204 - val_loss: 0.3478 - val_accuracy: 0.8920\n",
      "Epoch 127/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0464 - accuracy: 0.6257 - val_loss: 0.3809 - val_accuracy: 0.8752\n",
      "Epoch 128/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0513 - accuracy: 0.6228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_128.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_128.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 61s 1s/step - loss: 1.0513 - accuracy: 0.6228 - val_loss: 0.3500 - val_accuracy: 0.8962\n",
      "Epoch 129/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0576 - accuracy: 0.6246 - val_loss: 0.3561 - val_accuracy: 0.8906\n",
      "Epoch 130/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0467 - accuracy: 0.6221 - val_loss: 0.3543 - val_accuracy: 0.8920\n",
      "Epoch 131/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0357 - accuracy: 0.6285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_131.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_131.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 64s 1s/step - loss: 1.0357 - accuracy: 0.6285 - val_loss: 0.3402 - val_accuracy: 0.9046\n",
      "Epoch 132/800\n",
      "45/45 [==============================] - 12s 249ms/step - loss: 1.0438 - accuracy: 0.6296 - val_loss: 0.3853 - val_accuracy: 0.8738\n",
      "Epoch 133/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0517 - accuracy: 0.6250 - val_loss: 0.3506 - val_accuracy: 0.8976\n",
      "Epoch 134/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0693 - accuracy: 0.6165 - val_loss: 0.3656 - val_accuracy: 0.8836\n",
      "Epoch 135/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0859 - accuracy: 0.6080 - val_loss: 0.3719 - val_accuracy: 0.8794\n",
      "Epoch 136/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0501 - accuracy: 0.6197 - val_loss: 0.3717 - val_accuracy: 0.8766\n",
      "Epoch 137/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0345 - accuracy: 0.6197 - val_loss: 0.3807 - val_accuracy: 0.8766\n",
      "Epoch 138/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0711 - accuracy: 0.6193 - val_loss: 0.3717 - val_accuracy: 0.8752\n",
      "Epoch 139/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0457 - accuracy: 0.6338 - val_loss: 0.3623 - val_accuracy: 0.8850\n",
      "Epoch 140/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0501 - accuracy: 0.6306 - val_loss: 0.3769 - val_accuracy: 0.8724\n",
      "Epoch 141/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0240 - accuracy: 0.6228 - val_loss: 0.3552 - val_accuracy: 0.8892\n",
      "Epoch 142/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0389 - accuracy: 0.6352 - val_loss: 0.3580 - val_accuracy: 0.8836\n",
      "Epoch 143/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0445 - accuracy: 0.6260 - val_loss: 0.3729 - val_accuracy: 0.8836\n",
      "Epoch 144/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0479 - accuracy: 0.6225 - val_loss: 0.3593 - val_accuracy: 0.8822\n",
      "Epoch 145/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0376 - accuracy: 0.6221 - val_loss: 0.3521 - val_accuracy: 0.8752\n",
      "Epoch 146/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0189 - accuracy: 0.6366 - val_loss: 0.3743 - val_accuracy: 0.8780\n",
      "Epoch 147/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0536 - accuracy: 0.6211 - val_loss: 0.3571 - val_accuracy: 0.8878\n",
      "Epoch 148/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0277 - accuracy: 0.6299 - val_loss: 0.3793 - val_accuracy: 0.8822\n",
      "Epoch 149/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0466 - accuracy: 0.6257 - val_loss: 0.3730 - val_accuracy: 0.8850\n",
      "Epoch 150/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0450 - accuracy: 0.6151 - val_loss: 0.3574 - val_accuracy: 0.8934\n",
      "Epoch 151/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0335 - accuracy: 0.6246 - val_loss: 0.3417 - val_accuracy: 0.8934\n",
      "Epoch 152/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0481 - accuracy: 0.6296 - val_loss: 0.3516 - val_accuracy: 0.8906\n",
      "Epoch 153/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0101 - accuracy: 0.6327 - val_loss: 0.3569 - val_accuracy: 0.8822\n",
      "Epoch 154/800\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 1.0101 - accuracy: 0.6476 - val_loss: 0.3757 - val_accuracy: 0.8738\n",
      "Epoch 155/800\n",
      "45/45 [==============================] - 12s 266ms/step - loss: 1.0239 - accuracy: 0.6320 - val_loss: 0.3611 - val_accuracy: 0.8906\n",
      "Epoch 156/800\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 1.0249 - accuracy: 0.6242 - val_loss: 0.3564 - val_accuracy: 0.8962\n",
      "Epoch 157/800\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 1.0075 - accuracy: 0.6345 - val_loss: 0.3861 - val_accuracy: 0.8780\n",
      "Epoch 158/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0251 - accuracy: 0.6356 - val_loss: 0.3701 - val_accuracy: 0.8766\n",
      "Epoch 159/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0232 - accuracy: 0.6359 - val_loss: 0.3480 - val_accuracy: 0.8962\n",
      "Epoch 160/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0137 - accuracy: 0.6402 - val_loss: 0.3549 - val_accuracy: 0.8878\n",
      "Epoch 161/800\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 1.0360 - accuracy: 0.6317 - val_loss: 0.3748 - val_accuracy: 0.8780\n",
      "Epoch 162/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0138 - accuracy: 0.6288 - val_loss: 0.3632 - val_accuracy: 0.8878\n",
      "Epoch 163/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0238 - accuracy: 0.6317 - val_loss: 0.3663 - val_accuracy: 0.8836\n",
      "Epoch 164/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9972 - accuracy: 0.6331 - val_loss: 0.3579 - val_accuracy: 0.8920\n",
      "Epoch 165/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0331 - accuracy: 0.6264 - val_loss: 0.3903 - val_accuracy: 0.8696\n",
      "Epoch 166/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0248 - accuracy: 0.6444 - val_loss: 0.3690 - val_accuracy: 0.8808\n",
      "Epoch 167/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0352 - accuracy: 0.6292 - val_loss: 0.3620 - val_accuracy: 0.8836\n",
      "Epoch 168/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0078 - accuracy: 0.6373 - val_loss: 0.3471 - val_accuracy: 0.8892\n",
      "Epoch 169/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0213 - accuracy: 0.6306 - val_loss: 0.3732 - val_accuracy: 0.8808\n",
      "Epoch 170/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0480 - accuracy: 0.6193 - val_loss: 0.3907 - val_accuracy: 0.8766\n",
      "Epoch 171/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0293 - accuracy: 0.6349 - val_loss: 0.3812 - val_accuracy: 0.8850\n",
      "Epoch 172/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0244 - accuracy: 0.6242 - val_loss: 0.3734 - val_accuracy: 0.8836\n",
      "Epoch 173/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0242 - accuracy: 0.6394 - val_loss: 0.3471 - val_accuracy: 0.8920\n",
      "Epoch 174/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9851 - accuracy: 0.6430 - val_loss: 0.3660 - val_accuracy: 0.8906\n",
      "Epoch 175/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0144 - accuracy: 0.6324 - val_loss: 0.3515 - val_accuracy: 0.8976\n",
      "Epoch 176/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0122 - accuracy: 0.6377 - val_loss: 0.3604 - val_accuracy: 0.8962\n",
      "Epoch 177/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0041 - accuracy: 0.6497 - val_loss: 0.3691 - val_accuracy: 0.8920\n",
      "Epoch 178/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0322 - accuracy: 0.6271 - val_loss: 0.3705 - val_accuracy: 0.8920\n",
      "Epoch 179/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9896 - accuracy: 0.6497 - val_loss: 0.3484 - val_accuracy: 0.8934\n",
      "Epoch 180/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0054 - accuracy: 0.6405 - val_loss: 0.3722 - val_accuracy: 0.8836\n",
      "Epoch 181/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0091 - accuracy: 0.6433 - val_loss: 0.3471 - val_accuracy: 0.8934\n",
      "Epoch 182/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9949 - accuracy: 0.6412 - val_loss: 0.3496 - val_accuracy: 0.8990\n",
      "Epoch 183/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0168 - accuracy: 0.6338 - val_loss: 0.3857 - val_accuracy: 0.8766\n",
      "Epoch 184/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0150 - accuracy: 0.6402 - val_loss: 0.3611 - val_accuracy: 0.8850\n",
      "Epoch 185/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9852 - accuracy: 0.6451 - val_loss: 0.3685 - val_accuracy: 0.8920\n",
      "Epoch 186/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 1.0090 - accuracy: 0.6384 - val_loss: 0.3764 - val_accuracy: 0.8794\n",
      "Epoch 187/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9924 - accuracy: 0.6472 - val_loss: 0.3541 - val_accuracy: 0.8962\n",
      "Epoch 188/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0192 - accuracy: 0.6356 - val_loss: 0.3627 - val_accuracy: 0.8850\n",
      "Epoch 189/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0111 - accuracy: 0.6345 - val_loss: 0.3466 - val_accuracy: 0.8892\n",
      "Epoch 190/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0022 - accuracy: 0.6426 - val_loss: 0.3532 - val_accuracy: 0.8892\n",
      "Epoch 191/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 1.0005 - accuracy: 0.6486 - val_loss: 0.3833 - val_accuracy: 0.8780\n",
      "Epoch 192/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0036 - accuracy: 0.6416 - val_loss: 0.3666 - val_accuracy: 0.8948\n",
      "Epoch 193/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9858 - accuracy: 0.6440 - val_loss: 0.3467 - val_accuracy: 0.8990\n",
      "Epoch 194/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9914 - accuracy: 0.6451 - val_loss: 0.3709 - val_accuracy: 0.8836\n",
      "Epoch 195/800\n",
      "45/45 [==============================] - 12s 273ms/step - loss: 1.0271 - accuracy: 0.6274 - val_loss: 0.3526 - val_accuracy: 0.8948\n",
      "Epoch 196/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9878 - accuracy: 0.6511 - val_loss: 0.3874 - val_accuracy: 0.8752\n",
      "Epoch 197/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9810 - accuracy: 0.6391 - val_loss: 0.3720 - val_accuracy: 0.8892\n",
      "Epoch 198/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0092 - accuracy: 0.6426 - val_loss: 0.3900 - val_accuracy: 0.8780\n",
      "Epoch 199/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9850 - accuracy: 0.6462 - val_loss: 0.3699 - val_accuracy: 0.8864\n",
      "Epoch 200/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.9913 - accuracy: 0.6511 - val_loss: 0.3798 - val_accuracy: 0.8906\n",
      "Epoch 201/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9735 - accuracy: 0.6638 - val_loss: 0.3694 - val_accuracy: 0.8864\n",
      "Epoch 202/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0093 - accuracy: 0.6405 - val_loss: 0.3730 - val_accuracy: 0.8878\n",
      "Epoch 203/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9953 - accuracy: 0.6419 - val_loss: 0.3493 - val_accuracy: 0.8892\n",
      "Epoch 204/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9781 - accuracy: 0.6550 - val_loss: 0.3504 - val_accuracy: 0.9018\n",
      "Epoch 205/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9900 - accuracy: 0.6430 - val_loss: 0.3782 - val_accuracy: 0.8836\n",
      "Epoch 206/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9867 - accuracy: 0.6387 - val_loss: 0.3463 - val_accuracy: 0.8920\n",
      "Epoch 207/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9939 - accuracy: 0.6419 - val_loss: 0.3623 - val_accuracy: 0.8920\n",
      "Epoch 208/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9866 - accuracy: 0.6479 - val_loss: 0.3712 - val_accuracy: 0.8752\n",
      "Epoch 209/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9851 - accuracy: 0.6391 - val_loss: 0.3685 - val_accuracy: 0.8836\n",
      "Epoch 210/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 1.0116 - accuracy: 0.6359 - val_loss: 0.3816 - val_accuracy: 0.8752\n",
      "Epoch 211/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9805 - accuracy: 0.6504 - val_loss: 0.3819 - val_accuracy: 0.8906\n",
      "Epoch 212/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9644 - accuracy: 0.6617 - val_loss: 0.3858 - val_accuracy: 0.8836\n",
      "Epoch 213/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9937 - accuracy: 0.6448 - val_loss: 0.3879 - val_accuracy: 0.8850\n",
      "Epoch 214/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9925 - accuracy: 0.6423 - val_loss: 0.3660 - val_accuracy: 0.8920\n",
      "Epoch 215/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9887 - accuracy: 0.6448 - val_loss: 0.3458 - val_accuracy: 0.9032\n",
      "Epoch 216/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9823 - accuracy: 0.6444 - val_loss: 0.3538 - val_accuracy: 0.8850\n",
      "Epoch 217/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9690 - accuracy: 0.6504 - val_loss: 0.3747 - val_accuracy: 0.8864\n",
      "Epoch 218/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.9877 - accuracy: 0.6356 - val_loss: 0.3630 - val_accuracy: 0.8990\n",
      "Epoch 219/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9806 - accuracy: 0.6430 - val_loss: 0.3585 - val_accuracy: 0.8962\n",
      "Epoch 220/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9961 - accuracy: 0.6419 - val_loss: 0.3454 - val_accuracy: 0.8948\n",
      "Epoch 221/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9867 - accuracy: 0.6455 - val_loss: 0.3549 - val_accuracy: 0.8892\n",
      "Epoch 222/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9802 - accuracy: 0.6568 - val_loss: 0.3773 - val_accuracy: 0.8766\n",
      "Epoch 223/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.9697 - accuracy: 0.6564 - val_loss: 0.3545 - val_accuracy: 0.8976\n",
      "Epoch 224/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9671 - accuracy: 0.6444 - val_loss: 0.3535 - val_accuracy: 0.8976\n",
      "Epoch 225/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9511 - accuracy: 0.6617 - val_loss: 0.4127 - val_accuracy: 0.8738\n",
      "Epoch 226/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9585 - accuracy: 0.6607 - val_loss: 0.3692 - val_accuracy: 0.8864\n",
      "Epoch 227/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9789 - accuracy: 0.6405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_227.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_227.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 62s 1s/step - loss: 0.9789 - accuracy: 0.6405 - val_loss: 0.3402 - val_accuracy: 0.9074\n",
      "Epoch 228/800\n",
      "45/45 [==============================] - 12s 250ms/step - loss: 0.9750 - accuracy: 0.6557 - val_loss: 0.3475 - val_accuracy: 0.8976\n",
      "Epoch 229/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9936 - accuracy: 0.6479 - val_loss: 0.3467 - val_accuracy: 0.8920\n",
      "Epoch 230/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9911 - accuracy: 0.6433 - val_loss: 0.3679 - val_accuracy: 0.8948\n",
      "Epoch 231/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9697 - accuracy: 0.6483 - val_loss: 0.3675 - val_accuracy: 0.8878\n",
      "Epoch 232/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9815 - accuracy: 0.6539 - val_loss: 0.3736 - val_accuracy: 0.8878\n",
      "Epoch 233/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9555 - accuracy: 0.6592 - val_loss: 0.3370 - val_accuracy: 0.8962\n",
      "Epoch 234/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9614 - accuracy: 0.6614 - val_loss: 0.3579 - val_accuracy: 0.8892\n",
      "Epoch 235/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9592 - accuracy: 0.6433 - val_loss: 0.3519 - val_accuracy: 0.8892\n",
      "Epoch 236/800\n",
      "45/45 [==============================] - 12s 254ms/step - loss: 0.9609 - accuracy: 0.6568 - val_loss: 0.3563 - val_accuracy: 0.8892\n",
      "Epoch 237/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.9953 - accuracy: 0.6370 - val_loss: 0.3567 - val_accuracy: 0.8836\n",
      "Epoch 238/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9279 - accuracy: 0.6603 - val_loss: 0.3602 - val_accuracy: 0.8948\n",
      "Epoch 239/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9788 - accuracy: 0.6546 - val_loss: 0.3576 - val_accuracy: 0.8962\n",
      "Epoch 240/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9809 - accuracy: 0.6448 - val_loss: 0.3562 - val_accuracy: 0.8906\n",
      "Epoch 241/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9377 - accuracy: 0.6674 - val_loss: 0.3597 - val_accuracy: 0.8948\n",
      "Epoch 242/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9946 - accuracy: 0.6402 - val_loss: 0.3502 - val_accuracy: 0.8976\n",
      "Epoch 243/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9732 - accuracy: 0.6624 - val_loss: 0.3504 - val_accuracy: 0.8976\n",
      "Epoch 244/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9602 - accuracy: 0.6543 - val_loss: 0.3563 - val_accuracy: 0.9004\n",
      "Epoch 245/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9580 - accuracy: 0.6624 - val_loss: 0.3797 - val_accuracy: 0.8934\n",
      "Epoch 246/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9798 - accuracy: 0.6391 - val_loss: 0.3796 - val_accuracy: 0.8906\n",
      "Epoch 247/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9604 - accuracy: 0.6554 - val_loss: 0.3537 - val_accuracy: 0.9018\n",
      "Epoch 248/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9390 - accuracy: 0.6663 - val_loss: 0.3526 - val_accuracy: 0.9060\n",
      "Epoch 249/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9512 - accuracy: 0.6582 - val_loss: 0.3693 - val_accuracy: 0.8920\n",
      "Epoch 250/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9408 - accuracy: 0.6589 - val_loss: 0.3645 - val_accuracy: 0.8948\n",
      "Epoch 251/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9412 - accuracy: 0.6695 - val_loss: 0.3556 - val_accuracy: 0.8920\n",
      "Epoch 252/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9689 - accuracy: 0.6483 - val_loss: 0.3645 - val_accuracy: 0.8822\n",
      "Epoch 253/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9912 - accuracy: 0.6373 - val_loss: 0.3682 - val_accuracy: 0.8878\n",
      "Epoch 254/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9689 - accuracy: 0.6469 - val_loss: 0.3543 - val_accuracy: 0.9004\n",
      "Epoch 255/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9483 - accuracy: 0.6600 - val_loss: 0.3644 - val_accuracy: 0.8920\n",
      "Epoch 256/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9236 - accuracy: 0.6706 - val_loss: 0.3556 - val_accuracy: 0.8920\n",
      "Epoch 257/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9260 - accuracy: 0.6660 - val_loss: 0.3434 - val_accuracy: 0.8892\n",
      "Epoch 258/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9702 - accuracy: 0.6490 - val_loss: 0.3428 - val_accuracy: 0.8962\n",
      "Epoch 259/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9602 - accuracy: 0.6536 - val_loss: 0.3631 - val_accuracy: 0.8934\n",
      "Epoch 260/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9444 - accuracy: 0.6621 - val_loss: 0.3747 - val_accuracy: 0.8962\n",
      "Epoch 261/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9629 - accuracy: 0.6582 - val_loss: 0.3450 - val_accuracy: 0.9060\n",
      "Epoch 262/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9225 - accuracy: 0.6691 - val_loss: 0.3359 - val_accuracy: 0.9004\n",
      "Epoch 263/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9418 - accuracy: 0.6603 - val_loss: 0.3459 - val_accuracy: 0.8920\n",
      "Epoch 264/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9701 - accuracy: 0.6515 - val_loss: 0.3534 - val_accuracy: 0.8934\n",
      "Epoch 265/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9274 - accuracy: 0.6737 - val_loss: 0.3460 - val_accuracy: 0.8990\n",
      "Epoch 266/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9413 - accuracy: 0.6631 - val_loss: 0.4063 - val_accuracy: 0.8850\n",
      "Epoch 267/800\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.9361 - accuracy: 0.6610 - val_loss: 0.3622 - val_accuracy: 0.8948\n",
      "Epoch 268/800\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.9069 - accuracy: 0.6822 - val_loss: 0.3542 - val_accuracy: 0.8976\n",
      "Epoch 269/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9366 - accuracy: 0.6702 - val_loss: 0.3329 - val_accuracy: 0.9074\n",
      "Epoch 270/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9316 - accuracy: 0.6684 - val_loss: 0.3566 - val_accuracy: 0.8948\n",
      "Epoch 271/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9246 - accuracy: 0.6688 - val_loss: 0.3362 - val_accuracy: 0.9032\n",
      "Epoch 272/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9439 - accuracy: 0.6667 - val_loss: 0.3327 - val_accuracy: 0.9018\n",
      "Epoch 273/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9386 - accuracy: 0.6663 - val_loss: 0.3303 - val_accuracy: 0.9046\n",
      "Epoch 274/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9531 - accuracy: 0.6550 - val_loss: 0.3377 - val_accuracy: 0.8934\n",
      "Epoch 275/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9743 - accuracy: 0.6546 - val_loss: 0.3671 - val_accuracy: 0.8962\n",
      "Epoch 276/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9363 - accuracy: 0.6603 - val_loss: 0.3498 - val_accuracy: 0.9060\n",
      "Epoch 277/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9286 - accuracy: 0.6649 - val_loss: 0.3414 - val_accuracy: 0.8990\n",
      "Epoch 278/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9473 - accuracy: 0.6592 - val_loss: 0.3561 - val_accuracy: 0.8962\n",
      "Epoch 279/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9394 - accuracy: 0.6607 - val_loss: 0.3577 - val_accuracy: 0.8850\n",
      "Epoch 280/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9237 - accuracy: 0.6645 - val_loss: 0.3389 - val_accuracy: 0.8990\n",
      "Epoch 281/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9542 - accuracy: 0.6610 - val_loss: 0.3439 - val_accuracy: 0.9074\n",
      "Epoch 282/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9313 - accuracy: 0.6684 - val_loss: 0.3767 - val_accuracy: 0.8836\n",
      "Epoch 283/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9340 - accuracy: 0.6698 - val_loss: 0.3539 - val_accuracy: 0.8962\n",
      "Epoch 284/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9224 - accuracy: 0.6688 - val_loss: 0.3506 - val_accuracy: 0.8906\n",
      "Epoch 285/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9416 - accuracy: 0.6497 - val_loss: 0.3527 - val_accuracy: 0.9018\n",
      "Epoch 286/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9104 - accuracy: 0.6681 - val_loss: 0.3578 - val_accuracy: 0.8934\n",
      "Epoch 287/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9085 - accuracy: 0.6766 - val_loss: 0.3421 - val_accuracy: 0.8934\n",
      "Epoch 288/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9553 - accuracy: 0.6532 - val_loss: 0.3635 - val_accuracy: 0.8878\n",
      "Epoch 289/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9258 - accuracy: 0.6543 - val_loss: 0.3562 - val_accuracy: 0.8948\n",
      "Epoch 290/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9140 - accuracy: 0.6635 - val_loss: 0.3656 - val_accuracy: 0.8878\n",
      "Epoch 291/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9290 - accuracy: 0.6766 - val_loss: 0.3476 - val_accuracy: 0.8976\n",
      "Epoch 292/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9197 - accuracy: 0.6695 - val_loss: 0.3541 - val_accuracy: 0.8934\n",
      "Epoch 293/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9236 - accuracy: 0.6684 - val_loss: 0.3463 - val_accuracy: 0.8990\n",
      "Epoch 294/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9171 - accuracy: 0.6670 - val_loss: 0.3484 - val_accuracy: 0.9018\n",
      "Epoch 295/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8850 - accuracy: 0.6780 - val_loss: 0.3705 - val_accuracy: 0.8948\n",
      "Epoch 296/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9315 - accuracy: 0.6698 - val_loss: 0.3772 - val_accuracy: 0.8934\n",
      "Epoch 297/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9279 - accuracy: 0.6698 - val_loss: 0.3611 - val_accuracy: 0.9018\n",
      "Epoch 298/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9313 - accuracy: 0.6617 - val_loss: 0.3719 - val_accuracy: 0.8906\n",
      "Epoch 299/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9185 - accuracy: 0.6706 - val_loss: 0.3720 - val_accuracy: 0.8920\n",
      "Epoch 300/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9206 - accuracy: 0.6684 - val_loss: 0.3978 - val_accuracy: 0.8822\n",
      "Epoch 301/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9119 - accuracy: 0.6783 - val_loss: 0.3659 - val_accuracy: 0.8990\n",
      "Epoch 302/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9075 - accuracy: 0.6684 - val_loss: 0.3438 - val_accuracy: 0.8934\n",
      "Epoch 303/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9041 - accuracy: 0.6720 - val_loss: 0.3458 - val_accuracy: 0.9004\n",
      "Epoch 304/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8824 - accuracy: 0.6829 - val_loss: 0.3604 - val_accuracy: 0.8948\n",
      "Epoch 305/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9274 - accuracy: 0.6635 - val_loss: 0.3416 - val_accuracy: 0.9060\n",
      "Epoch 306/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9135 - accuracy: 0.6677 - val_loss: 0.3674 - val_accuracy: 0.8962\n",
      "Epoch 307/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8940 - accuracy: 0.6776 - val_loss: 0.3619 - val_accuracy: 0.8892\n",
      "Epoch 308/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9100 - accuracy: 0.6734 - val_loss: 0.3486 - val_accuracy: 0.8976\n",
      "Epoch 309/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9052 - accuracy: 0.6776 - val_loss: 0.3685 - val_accuracy: 0.8836\n",
      "Epoch 310/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9114 - accuracy: 0.6698 - val_loss: 0.3502 - val_accuracy: 0.9046\n",
      "Epoch 311/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8999 - accuracy: 0.6723 - val_loss: 0.3768 - val_accuracy: 0.8962\n",
      "Epoch 312/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9184 - accuracy: 0.6723 - val_loss: 0.3755 - val_accuracy: 0.8976\n",
      "Epoch 313/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9342 - accuracy: 0.6617 - val_loss: 0.3779 - val_accuracy: 0.8962\n",
      "Epoch 314/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9104 - accuracy: 0.6706 - val_loss: 0.3491 - val_accuracy: 0.8990\n",
      "Epoch 315/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9333 - accuracy: 0.6621 - val_loss: 0.3677 - val_accuracy: 0.8990\n",
      "Epoch 316/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9021 - accuracy: 0.6783 - val_loss: 0.3495 - val_accuracy: 0.8906\n",
      "Epoch 317/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8836 - accuracy: 0.6805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_317.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_317.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 61s 1s/step - loss: 0.8836 - accuracy: 0.6805 - val_loss: 0.3619 - val_accuracy: 0.9088\n",
      "Epoch 318/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9045 - accuracy: 0.6741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_318.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_318.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 62s 1s/step - loss: 0.9045 - accuracy: 0.6741 - val_loss: 0.3351 - val_accuracy: 0.9102\n",
      "Epoch 319/800\n",
      "45/45 [==============================] - 12s 250ms/step - loss: 0.8926 - accuracy: 0.6670 - val_loss: 0.3568 - val_accuracy: 0.8976\n",
      "Epoch 320/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.9411 - accuracy: 0.6628 - val_loss: 0.3540 - val_accuracy: 0.9018\n",
      "Epoch 321/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8725 - accuracy: 0.6903 - val_loss: 0.3718 - val_accuracy: 0.8962\n",
      "Epoch 322/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9232 - accuracy: 0.6720 - val_loss: 0.3569 - val_accuracy: 0.9032\n",
      "Epoch 323/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9117 - accuracy: 0.6723 - val_loss: 0.3611 - val_accuracy: 0.8948\n",
      "Epoch 324/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9118 - accuracy: 0.6709 - val_loss: 0.3711 - val_accuracy: 0.8920\n",
      "Epoch 325/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8722 - accuracy: 0.6861 - val_loss: 0.3463 - val_accuracy: 0.9018\n",
      "Epoch 326/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9075 - accuracy: 0.6713 - val_loss: 0.3683 - val_accuracy: 0.8934\n",
      "Epoch 327/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.9171 - accuracy: 0.6688 - val_loss: 0.3656 - val_accuracy: 0.8920\n",
      "Epoch 328/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8973 - accuracy: 0.6858 - val_loss: 0.3602 - val_accuracy: 0.9018\n",
      "Epoch 329/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8833 - accuracy: 0.6815 - val_loss: 0.3434 - val_accuracy: 0.9032\n",
      "Epoch 330/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8847 - accuracy: 0.6790 - val_loss: 0.3672 - val_accuracy: 0.8990\n",
      "Epoch 331/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9061 - accuracy: 0.6702 - val_loss: 0.3504 - val_accuracy: 0.9018\n",
      "Epoch 332/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8963 - accuracy: 0.6783 - val_loss: 0.3628 - val_accuracy: 0.8892\n",
      "Epoch 333/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8918 - accuracy: 0.6836 - val_loss: 0.3581 - val_accuracy: 0.8948\n",
      "Epoch 334/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9175 - accuracy: 0.6727 - val_loss: 0.3373 - val_accuracy: 0.9032\n",
      "Epoch 335/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8900 - accuracy: 0.6822 - val_loss: 0.3464 - val_accuracy: 0.9060\n",
      "Epoch 336/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8998 - accuracy: 0.6741 - val_loss: 0.3393 - val_accuracy: 0.9074\n",
      "Epoch 337/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8914 - accuracy: 0.6787 - val_loss: 0.3435 - val_accuracy: 0.9032\n",
      "Epoch 338/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9084 - accuracy: 0.6790 - val_loss: 0.3435 - val_accuracy: 0.8976\n",
      "Epoch 339/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8975 - accuracy: 0.6762 - val_loss: 0.3414 - val_accuracy: 0.9004\n",
      "Epoch 340/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8999 - accuracy: 0.6805 - val_loss: 0.3540 - val_accuracy: 0.8962\n",
      "Epoch 341/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8699 - accuracy: 0.6875 - val_loss: 0.3380 - val_accuracy: 0.9032\n",
      "Epoch 342/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8779 - accuracy: 0.6889 - val_loss: 0.3467 - val_accuracy: 0.9004\n",
      "Epoch 343/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8649 - accuracy: 0.6850 - val_loss: 0.3631 - val_accuracy: 0.8976\n",
      "Epoch 344/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.9099 - accuracy: 0.6645 - val_loss: 0.3493 - val_accuracy: 0.9046\n",
      "Epoch 345/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8650 - accuracy: 0.6974 - val_loss: 0.3530 - val_accuracy: 0.9046\n",
      "Epoch 346/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8628 - accuracy: 0.6815 - val_loss: 0.3644 - val_accuracy: 0.8934\n",
      "Epoch 347/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8867 - accuracy: 0.6872 - val_loss: 0.3669 - val_accuracy: 0.9032\n",
      "Epoch 348/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.9081 - accuracy: 0.6720 - val_loss: 0.3937 - val_accuracy: 0.8906\n",
      "Epoch 349/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8555 - accuracy: 0.6921 - val_loss: 0.3665 - val_accuracy: 0.9018\n",
      "Epoch 350/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8942 - accuracy: 0.6769 - val_loss: 0.3550 - val_accuracy: 0.9032\n",
      "Epoch 351/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.9065 - accuracy: 0.6656 - val_loss: 0.3564 - val_accuracy: 0.9018\n",
      "Epoch 352/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8759 - accuracy: 0.6896 - val_loss: 0.3631 - val_accuracy: 0.9046\n",
      "Epoch 353/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8938 - accuracy: 0.6850 - val_loss: 0.3425 - val_accuracy: 0.9088\n",
      "Epoch 354/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8412 - accuracy: 0.7006 - val_loss: 0.3373 - val_accuracy: 0.9088\n",
      "Epoch 355/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8748 - accuracy: 0.6918 - val_loss: 0.3725 - val_accuracy: 0.8920\n",
      "Epoch 356/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8791 - accuracy: 0.6872 - val_loss: 0.3718 - val_accuracy: 0.8962\n",
      "Epoch 357/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8815 - accuracy: 0.6833 - val_loss: 0.3616 - val_accuracy: 0.8990\n",
      "Epoch 358/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8826 - accuracy: 0.6935 - val_loss: 0.3736 - val_accuracy: 0.8976\n",
      "Epoch 359/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8728 - accuracy: 0.6868 - val_loss: 0.3846 - val_accuracy: 0.8878\n",
      "Epoch 360/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.8574 - accuracy: 0.6925 - val_loss: 0.4195 - val_accuracy: 0.8878\n",
      "Epoch 361/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8544 - accuracy: 0.6879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_361.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_361.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 63s 1s/step - loss: 0.8544 - accuracy: 0.6879 - val_loss: 0.3517 - val_accuracy: 0.9158\n",
      "Epoch 362/800\n",
      "45/45 [==============================] - 12s 251ms/step - loss: 0.8840 - accuracy: 0.6861 - val_loss: 0.3554 - val_accuracy: 0.9074\n",
      "Epoch 363/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8994 - accuracy: 0.6713 - val_loss: 0.3770 - val_accuracy: 0.9046\n",
      "Epoch 364/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8505 - accuracy: 0.6992 - val_loss: 0.3665 - val_accuracy: 0.9018\n",
      "Epoch 365/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8626 - accuracy: 0.6942 - val_loss: 0.3607 - val_accuracy: 0.8976\n",
      "Epoch 366/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8849 - accuracy: 0.6723 - val_loss: 0.3678 - val_accuracy: 0.9074\n",
      "Epoch 367/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8715 - accuracy: 0.6865 - val_loss: 0.3752 - val_accuracy: 0.9004\n",
      "Epoch 368/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8809 - accuracy: 0.6850 - val_loss: 0.3818 - val_accuracy: 0.9046\n",
      "Epoch 369/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8629 - accuracy: 0.6939 - val_loss: 0.3623 - val_accuracy: 0.8976\n",
      "Epoch 370/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.8455 - accuracy: 0.7006 - val_loss: 0.3568 - val_accuracy: 0.9032\n",
      "Epoch 371/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8553 - accuracy: 0.6935 - val_loss: 0.3756 - val_accuracy: 0.9004\n",
      "Epoch 372/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8881 - accuracy: 0.6889 - val_loss: 0.3605 - val_accuracy: 0.9004\n",
      "Epoch 373/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8772 - accuracy: 0.6858 - val_loss: 0.3691 - val_accuracy: 0.8990\n",
      "Epoch 374/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8488 - accuracy: 0.6935 - val_loss: 0.3948 - val_accuracy: 0.8836\n",
      "Epoch 375/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8650 - accuracy: 0.6914 - val_loss: 0.3672 - val_accuracy: 0.9032\n",
      "Epoch 376/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8793 - accuracy: 0.6776 - val_loss: 0.3627 - val_accuracy: 0.8962\n",
      "Epoch 377/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8591 - accuracy: 0.6921 - val_loss: 0.3739 - val_accuracy: 0.8920\n",
      "Epoch 378/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.8505 - accuracy: 0.6861 - val_loss: 0.3675 - val_accuracy: 0.9046\n",
      "Epoch 379/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8562 - accuracy: 0.6921 - val_loss: 0.3510 - val_accuracy: 0.9074\n",
      "Epoch 380/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8684 - accuracy: 0.6801 - val_loss: 0.3355 - val_accuracy: 0.9130\n",
      "Epoch 381/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8759 - accuracy: 0.6815 - val_loss: 0.3940 - val_accuracy: 0.8920\n",
      "Epoch 382/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8775 - accuracy: 0.6787 - val_loss: 0.3631 - val_accuracy: 0.9018\n",
      "Epoch 383/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8491 - accuracy: 0.6985 - val_loss: 0.3708 - val_accuracy: 0.9046\n",
      "Epoch 384/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8443 - accuracy: 0.6974 - val_loss: 0.3861 - val_accuracy: 0.8962\n",
      "Epoch 385/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8550 - accuracy: 0.6886 - val_loss: 0.3778 - val_accuracy: 0.9018\n",
      "Epoch 386/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8569 - accuracy: 0.6921 - val_loss: 0.3643 - val_accuracy: 0.9060\n",
      "Epoch 387/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8706 - accuracy: 0.6875 - val_loss: 0.3733 - val_accuracy: 0.8934\n",
      "Epoch 388/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8693 - accuracy: 0.6826 - val_loss: 0.3897 - val_accuracy: 0.8990\n",
      "Epoch 389/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8694 - accuracy: 0.6900 - val_loss: 0.3903 - val_accuracy: 0.8878\n",
      "Epoch 390/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8391 - accuracy: 0.6999 - val_loss: 0.3648 - val_accuracy: 0.9032\n",
      "Epoch 391/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8510 - accuracy: 0.7063 - val_loss: 0.3877 - val_accuracy: 0.8836\n",
      "Epoch 392/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8723 - accuracy: 0.6932 - val_loss: 0.3778 - val_accuracy: 0.8906\n",
      "Epoch 393/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8496 - accuracy: 0.6921 - val_loss: 0.3698 - val_accuracy: 0.8864\n",
      "Epoch 394/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8750 - accuracy: 0.6872 - val_loss: 0.3881 - val_accuracy: 0.8906\n",
      "Epoch 395/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8498 - accuracy: 0.6992 - val_loss: 0.3678 - val_accuracy: 0.9032\n",
      "Epoch 396/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8452 - accuracy: 0.7020 - val_loss: 0.3689 - val_accuracy: 0.8934\n",
      "Epoch 397/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8555 - accuracy: 0.6928 - val_loss: 0.4058 - val_accuracy: 0.8836\n",
      "Epoch 398/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8617 - accuracy: 0.6921 - val_loss: 0.3700 - val_accuracy: 0.8976\n",
      "Epoch 399/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8723 - accuracy: 0.6850 - val_loss: 0.4091 - val_accuracy: 0.8850\n",
      "Epoch 400/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8513 - accuracy: 0.6865 - val_loss: 0.3790 - val_accuracy: 0.8934\n",
      "Epoch 401/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8385 - accuracy: 0.6985 - val_loss: 0.3741 - val_accuracy: 0.8962\n",
      "Epoch 402/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8506 - accuracy: 0.6889 - val_loss: 0.3517 - val_accuracy: 0.9060\n",
      "Epoch 403/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.8544 - accuracy: 0.6886 - val_loss: 0.3870 - val_accuracy: 0.8794\n",
      "Epoch 404/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8460 - accuracy: 0.7006 - val_loss: 0.3558 - val_accuracy: 0.9018\n",
      "Epoch 405/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8619 - accuracy: 0.6872 - val_loss: 0.3765 - val_accuracy: 0.8934\n",
      "Epoch 406/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.8690 - accuracy: 0.6812 - val_loss: 0.4011 - val_accuracy: 0.8780\n",
      "Epoch 407/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8623 - accuracy: 0.6925 - val_loss: 0.3635 - val_accuracy: 0.8990\n",
      "Epoch 408/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8510 - accuracy: 0.6893 - val_loss: 0.3763 - val_accuracy: 0.8962\n",
      "Epoch 409/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8460 - accuracy: 0.7017 - val_loss: 0.3485 - val_accuracy: 0.9060\n",
      "Epoch 410/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8312 - accuracy: 0.7020 - val_loss: 0.3551 - val_accuracy: 0.9032\n",
      "Epoch 411/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8301 - accuracy: 0.6981 - val_loss: 0.3639 - val_accuracy: 0.9032\n",
      "Epoch 412/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8359 - accuracy: 0.7091 - val_loss: 0.3607 - val_accuracy: 0.9060\n",
      "Epoch 413/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8193 - accuracy: 0.6992 - val_loss: 0.3539 - val_accuracy: 0.9032\n",
      "Epoch 414/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8357 - accuracy: 0.6967 - val_loss: 0.3528 - val_accuracy: 0.9074\n",
      "Epoch 415/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8155 - accuracy: 0.7222 - val_loss: 0.3395 - val_accuracy: 0.9102\n",
      "Epoch 416/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8260 - accuracy: 0.7006 - val_loss: 0.3435 - val_accuracy: 0.9102\n",
      "Epoch 417/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8361 - accuracy: 0.6985 - val_loss: 0.3660 - val_accuracy: 0.9046\n",
      "Epoch 418/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8396 - accuracy: 0.7010 - val_loss: 0.3764 - val_accuracy: 0.8962\n",
      "Epoch 419/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8496 - accuracy: 0.6992 - val_loss: 0.3672 - val_accuracy: 0.8976\n",
      "Epoch 420/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8336 - accuracy: 0.7052 - val_loss: 0.3751 - val_accuracy: 0.8976\n",
      "Epoch 421/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.8262 - accuracy: 0.7020 - val_loss: 0.3591 - val_accuracy: 0.9046\n",
      "Epoch 422/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8158 - accuracy: 0.7048 - val_loss: 0.3853 - val_accuracy: 0.8948\n",
      "Epoch 423/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8410 - accuracy: 0.7024 - val_loss: 0.3707 - val_accuracy: 0.9032\n",
      "Epoch 424/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8496 - accuracy: 0.6939 - val_loss: 0.3681 - val_accuracy: 0.9046\n",
      "Epoch 425/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8570 - accuracy: 0.6939 - val_loss: 0.3717 - val_accuracy: 0.9004\n",
      "Epoch 426/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8487 - accuracy: 0.6903 - val_loss: 0.3778 - val_accuracy: 0.8920\n",
      "Epoch 427/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8429 - accuracy: 0.7024 - val_loss: 0.3793 - val_accuracy: 0.8850\n",
      "Epoch 428/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8168 - accuracy: 0.7024 - val_loss: 0.3556 - val_accuracy: 0.9046\n",
      "Epoch 429/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8445 - accuracy: 0.7041 - val_loss: 0.3705 - val_accuracy: 0.9074\n",
      "Epoch 430/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8418 - accuracy: 0.6939 - val_loss: 0.3526 - val_accuracy: 0.9088\n",
      "Epoch 431/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8074 - accuracy: 0.7179 - val_loss: 0.3550 - val_accuracy: 0.9004\n",
      "Epoch 432/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8317 - accuracy: 0.7002 - val_loss: 0.3672 - val_accuracy: 0.8990\n",
      "Epoch 433/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.8502 - accuracy: 0.6964 - val_loss: 0.3592 - val_accuracy: 0.9032\n",
      "Epoch 434/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.8384 - accuracy: 0.7038 - val_loss: 0.3845 - val_accuracy: 0.8878\n",
      "Epoch 435/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8298 - accuracy: 0.7038 - val_loss: 0.3618 - val_accuracy: 0.8962\n",
      "Epoch 436/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8161 - accuracy: 0.7002 - val_loss: 0.3530 - val_accuracy: 0.9046\n",
      "Epoch 437/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8282 - accuracy: 0.7055 - val_loss: 0.3827 - val_accuracy: 0.8892\n",
      "Epoch 438/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8355 - accuracy: 0.7077 - val_loss: 0.3569 - val_accuracy: 0.8962\n",
      "Epoch 439/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.8053 - accuracy: 0.7147 - val_loss: 0.3705 - val_accuracy: 0.8892\n",
      "Epoch 440/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.8190 - accuracy: 0.7098 - val_loss: 0.3722 - val_accuracy: 0.8948\n",
      "Epoch 441/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7876 - accuracy: 0.7158 - val_loss: 0.3505 - val_accuracy: 0.9018\n",
      "Epoch 442/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8015 - accuracy: 0.7077 - val_loss: 0.3629 - val_accuracy: 0.8976\n",
      "Epoch 443/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8332 - accuracy: 0.7077 - val_loss: 0.3682 - val_accuracy: 0.9018\n",
      "Epoch 444/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8280 - accuracy: 0.7140 - val_loss: 0.3428 - val_accuracy: 0.9060\n",
      "Epoch 445/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8119 - accuracy: 0.7094 - val_loss: 0.3455 - val_accuracy: 0.8976\n",
      "Epoch 446/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7998 - accuracy: 0.7193 - val_loss: 0.3643 - val_accuracy: 0.9004\n",
      "Epoch 447/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.8280 - accuracy: 0.7045 - val_loss: 0.3828 - val_accuracy: 0.8976\n",
      "Epoch 448/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8101 - accuracy: 0.7116 - val_loss: 0.3523 - val_accuracy: 0.9046\n",
      "Epoch 449/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8023 - accuracy: 0.7126 - val_loss: 0.3672 - val_accuracy: 0.8962\n",
      "Epoch 450/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8204 - accuracy: 0.7109 - val_loss: 0.3618 - val_accuracy: 0.9032\n",
      "Epoch 451/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8168 - accuracy: 0.6995 - val_loss: 0.3626 - val_accuracy: 0.9046\n",
      "Epoch 452/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8218 - accuracy: 0.7066 - val_loss: 0.3687 - val_accuracy: 0.8920\n",
      "Epoch 453/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8300 - accuracy: 0.7002 - val_loss: 0.3777 - val_accuracy: 0.8990\n",
      "Epoch 454/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8263 - accuracy: 0.7077 - val_loss: 0.3605 - val_accuracy: 0.9046\n",
      "Epoch 455/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8278 - accuracy: 0.7112 - val_loss: 0.3669 - val_accuracy: 0.8948\n",
      "Epoch 456/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8000 - accuracy: 0.7158 - val_loss: 0.3768 - val_accuracy: 0.8934\n",
      "Epoch 457/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8251 - accuracy: 0.7109 - val_loss: 0.3677 - val_accuracy: 0.8962\n",
      "Epoch 458/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8234 - accuracy: 0.7002 - val_loss: 0.3708 - val_accuracy: 0.9018\n",
      "Epoch 459/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7914 - accuracy: 0.7169 - val_loss: 0.3837 - val_accuracy: 0.8892\n",
      "Epoch 460/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8191 - accuracy: 0.7034 - val_loss: 0.3743 - val_accuracy: 0.8990\n",
      "Epoch 461/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8191 - accuracy: 0.7045 - val_loss: 0.3687 - val_accuracy: 0.9060\n",
      "Epoch 462/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8159 - accuracy: 0.7059 - val_loss: 0.3688 - val_accuracy: 0.9018\n",
      "Epoch 463/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8356 - accuracy: 0.7087 - val_loss: 0.3420 - val_accuracy: 0.9060\n",
      "Epoch 464/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8042 - accuracy: 0.7236 - val_loss: 0.3447 - val_accuracy: 0.9032\n",
      "Epoch 465/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8118 - accuracy: 0.7130 - val_loss: 0.3612 - val_accuracy: 0.9060\n",
      "Epoch 466/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8187 - accuracy: 0.7105 - val_loss: 0.3549 - val_accuracy: 0.9060\n",
      "Epoch 467/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8169 - accuracy: 0.6992 - val_loss: 0.3645 - val_accuracy: 0.9046\n",
      "Epoch 468/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8125 - accuracy: 0.7116 - val_loss: 0.3463 - val_accuracy: 0.9004\n",
      "Epoch 469/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8037 - accuracy: 0.7200 - val_loss: 0.3613 - val_accuracy: 0.9074\n",
      "Epoch 470/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7967 - accuracy: 0.7179 - val_loss: 0.3457 - val_accuracy: 0.9102\n",
      "Epoch 471/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.8055 - accuracy: 0.7119 - val_loss: 0.3563 - val_accuracy: 0.8990\n",
      "Epoch 472/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8259 - accuracy: 0.7084 - val_loss: 0.3422 - val_accuracy: 0.9060\n",
      "Epoch 473/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8016 - accuracy: 0.7140 - val_loss: 0.3527 - val_accuracy: 0.8990\n",
      "Epoch 474/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8015 - accuracy: 0.7172 - val_loss: 0.3346 - val_accuracy: 0.9074\n",
      "Epoch 475/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7909 - accuracy: 0.7275 - val_loss: 0.3410 - val_accuracy: 0.9074\n",
      "Epoch 476/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8020 - accuracy: 0.7123 - val_loss: 0.3374 - val_accuracy: 0.9116\n",
      "Epoch 477/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7813 - accuracy: 0.7140 - val_loss: 0.3727 - val_accuracy: 0.8934\n",
      "Epoch 478/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8125 - accuracy: 0.7034 - val_loss: 0.3424 - val_accuracy: 0.9032\n",
      "Epoch 479/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8311 - accuracy: 0.6974 - val_loss: 0.3523 - val_accuracy: 0.9074\n",
      "Epoch 480/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7891 - accuracy: 0.7179 - val_loss: 0.3553 - val_accuracy: 0.9046\n",
      "Epoch 481/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7910 - accuracy: 0.7123 - val_loss: 0.3493 - val_accuracy: 0.9102\n",
      "Epoch 482/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7956 - accuracy: 0.7162 - val_loss: 0.3496 - val_accuracy: 0.9032\n",
      "Epoch 483/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8197 - accuracy: 0.7137 - val_loss: 0.3565 - val_accuracy: 0.9018\n",
      "Epoch 484/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8120 - accuracy: 0.7151 - val_loss: 0.3658 - val_accuracy: 0.8990\n",
      "Epoch 485/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7867 - accuracy: 0.7186 - val_loss: 0.3504 - val_accuracy: 0.8990\n",
      "Epoch 486/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8377 - accuracy: 0.6967 - val_loss: 0.3720 - val_accuracy: 0.9018\n",
      "Epoch 487/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.7842 - accuracy: 0.7193 - val_loss: 0.3639 - val_accuracy: 0.9088\n",
      "Epoch 488/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7953 - accuracy: 0.7176 - val_loss: 0.4371 - val_accuracy: 0.8794\n",
      "Epoch 489/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.8064 - accuracy: 0.7126 - val_loss: 0.3537 - val_accuracy: 0.9046\n",
      "Epoch 490/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7784 - accuracy: 0.7225 - val_loss: 0.3579 - val_accuracy: 0.9060\n",
      "Epoch 491/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7813 - accuracy: 0.7243 - val_loss: 0.3427 - val_accuracy: 0.9102\n",
      "Epoch 492/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7638 - accuracy: 0.7207 - val_loss: 0.3330 - val_accuracy: 0.9144\n",
      "Epoch 493/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.8150 - accuracy: 0.7048 - val_loss: 0.3572 - val_accuracy: 0.9088\n",
      "Epoch 494/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7887 - accuracy: 0.7261 - val_loss: 0.3493 - val_accuracy: 0.9074\n",
      "Epoch 495/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8073 - accuracy: 0.7144 - val_loss: 0.3526 - val_accuracy: 0.9004\n",
      "Epoch 496/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7936 - accuracy: 0.7158 - val_loss: 0.3596 - val_accuracy: 0.9032\n",
      "Epoch 497/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8028 - accuracy: 0.7066 - val_loss: 0.4207 - val_accuracy: 0.8850\n",
      "Epoch 498/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7816 - accuracy: 0.7190 - val_loss: 0.3604 - val_accuracy: 0.9018\n",
      "Epoch 499/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.8062 - accuracy: 0.7154 - val_loss: 0.3588 - val_accuracy: 0.9088\n",
      "Epoch 500/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.8167 - accuracy: 0.7094 - val_loss: 0.3574 - val_accuracy: 0.9046\n",
      "Epoch 501/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7782 - accuracy: 0.7137 - val_loss: 0.3517 - val_accuracy: 0.9130\n",
      "Epoch 502/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7759 - accuracy: 0.7257 - val_loss: 0.3498 - val_accuracy: 0.9046\n",
      "Epoch 503/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7733 - accuracy: 0.7250 - val_loss: 0.3570 - val_accuracy: 0.9060\n",
      "Epoch 504/800\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7975 - accuracy: 0.7151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_504.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov22_23-39-14\\base_ckpts\\cp_504.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 62s 1s/step - loss: 0.7975 - accuracy: 0.7151 - val_loss: 0.3468 - val_accuracy: 0.9173\n",
      "Epoch 505/800\n",
      "45/45 [==============================] - 12s 251ms/step - loss: 0.7862 - accuracy: 0.7172 - val_loss: 0.3605 - val_accuracy: 0.9088\n",
      "Epoch 506/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7745 - accuracy: 0.7261 - val_loss: 0.3398 - val_accuracy: 0.9046\n",
      "Epoch 507/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7872 - accuracy: 0.7268 - val_loss: 0.3393 - val_accuracy: 0.9046\n",
      "Epoch 508/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7558 - accuracy: 0.7211 - val_loss: 0.3494 - val_accuracy: 0.9004\n",
      "Epoch 509/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7703 - accuracy: 0.7292 - val_loss: 0.3701 - val_accuracy: 0.8962\n",
      "Epoch 510/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7923 - accuracy: 0.7162 - val_loss: 0.3626 - val_accuracy: 0.9046\n",
      "Epoch 511/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7903 - accuracy: 0.7317 - val_loss: 0.3489 - val_accuracy: 0.9032\n",
      "Epoch 512/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7715 - accuracy: 0.7215 - val_loss: 0.3797 - val_accuracy: 0.8934\n",
      "Epoch 513/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7778 - accuracy: 0.7147 - val_loss: 0.3546 - val_accuracy: 0.9046\n",
      "Epoch 514/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7817 - accuracy: 0.7197 - val_loss: 0.3666 - val_accuracy: 0.9088\n",
      "Epoch 515/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8010 - accuracy: 0.7207 - val_loss: 0.3694 - val_accuracy: 0.9032\n",
      "Epoch 516/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7772 - accuracy: 0.7261 - val_loss: 0.3680 - val_accuracy: 0.9060\n",
      "Epoch 517/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7670 - accuracy: 0.7296 - val_loss: 0.5008 - val_accuracy: 0.8485\n",
      "Epoch 518/800\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 0.7624 - accuracy: 0.7243 - val_loss: 0.3785 - val_accuracy: 0.8948\n",
      "Epoch 519/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7526 - accuracy: 0.7285 - val_loss: 0.3604 - val_accuracy: 0.9060\n",
      "Epoch 520/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7861 - accuracy: 0.7193 - val_loss: 0.3398 - val_accuracy: 0.9130\n",
      "Epoch 521/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7680 - accuracy: 0.7225 - val_loss: 0.3715 - val_accuracy: 0.9074\n",
      "Epoch 522/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7763 - accuracy: 0.7151 - val_loss: 0.3637 - val_accuracy: 0.9060\n",
      "Epoch 523/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7951 - accuracy: 0.7207 - val_loss: 0.3598 - val_accuracy: 0.9130\n",
      "Epoch 524/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7673 - accuracy: 0.7200 - val_loss: 0.3629 - val_accuracy: 0.9060\n",
      "Epoch 525/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7789 - accuracy: 0.7190 - val_loss: 0.3946 - val_accuracy: 0.8948\n",
      "Epoch 526/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7540 - accuracy: 0.7275 - val_loss: 0.4387 - val_accuracy: 0.8794\n",
      "Epoch 527/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7744 - accuracy: 0.7250 - val_loss: 0.3998 - val_accuracy: 0.8948\n",
      "Epoch 528/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7560 - accuracy: 0.7328 - val_loss: 0.3591 - val_accuracy: 0.8962\n",
      "Epoch 529/800\n",
      "45/45 [==============================] - 12s 253ms/step - loss: 0.7641 - accuracy: 0.7310 - val_loss: 0.3681 - val_accuracy: 0.9004\n",
      "Epoch 530/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7760 - accuracy: 0.7200 - val_loss: 0.3476 - val_accuracy: 0.9116\n",
      "Epoch 531/800\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 0.7671 - accuracy: 0.7296 - val_loss: 0.3697 - val_accuracy: 0.9004\n",
      "Epoch 532/800\n",
      "45/45 [==============================] - 12s 273ms/step - loss: 0.7548 - accuracy: 0.7317 - val_loss: 0.3873 - val_accuracy: 0.8948\n",
      "Epoch 533/800\n",
      "45/45 [==============================] - 12s 265ms/step - loss: 0.7774 - accuracy: 0.7261 - val_loss: 0.3713 - val_accuracy: 0.8920\n",
      "Epoch 534/800\n",
      "45/45 [==============================] - 12s 268ms/step - loss: 0.7993 - accuracy: 0.7151 - val_loss: 0.3819 - val_accuracy: 0.8948\n",
      "Epoch 535/800\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 0.7473 - accuracy: 0.7257 - val_loss: 0.3984 - val_accuracy: 0.8976\n",
      "Epoch 536/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7544 - accuracy: 0.7275 - val_loss: 0.3797 - val_accuracy: 0.9032\n",
      "Epoch 537/800\n",
      "45/45 [==============================] - 12s 254ms/step - loss: 0.7568 - accuracy: 0.7303 - val_loss: 0.3809 - val_accuracy: 0.9004\n",
      "Epoch 538/800\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.7797 - accuracy: 0.7253 - val_loss: 0.3739 - val_accuracy: 0.8990\n",
      "Epoch 539/800\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.7871 - accuracy: 0.7158 - val_loss: 0.3890 - val_accuracy: 0.8962\n",
      "Epoch 540/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7758 - accuracy: 0.7218 - val_loss: 0.3743 - val_accuracy: 0.9018\n",
      "Epoch 541/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.8018 - accuracy: 0.7130 - val_loss: 0.3812 - val_accuracy: 0.8990\n",
      "Epoch 542/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7450 - accuracy: 0.7367 - val_loss: 0.3750 - val_accuracy: 0.9018\n",
      "Epoch 543/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7530 - accuracy: 0.7321 - val_loss: 0.3670 - val_accuracy: 0.8990\n",
      "Epoch 544/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7420 - accuracy: 0.7416 - val_loss: 0.3974 - val_accuracy: 0.8990\n",
      "Epoch 545/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7788 - accuracy: 0.7310 - val_loss: 0.3710 - val_accuracy: 0.9018\n",
      "Epoch 546/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7528 - accuracy: 0.7335 - val_loss: 0.3779 - val_accuracy: 0.8990\n",
      "Epoch 547/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7517 - accuracy: 0.7384 - val_loss: 0.3641 - val_accuracy: 0.9018\n",
      "Epoch 548/800\n",
      "45/45 [==============================] - 12s 254ms/step - loss: 0.7366 - accuracy: 0.7388 - val_loss: 0.3567 - val_accuracy: 0.9158\n",
      "Epoch 549/800\n",
      "45/45 [==============================] - 12s 254ms/step - loss: 0.7432 - accuracy: 0.7338 - val_loss: 0.3586 - val_accuracy: 0.9046\n",
      "Epoch 550/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7506 - accuracy: 0.7384 - val_loss: 0.3659 - val_accuracy: 0.9004\n",
      "Epoch 551/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7459 - accuracy: 0.7388 - val_loss: 0.3472 - val_accuracy: 0.9102\n",
      "Epoch 552/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7780 - accuracy: 0.7151 - val_loss: 0.3668 - val_accuracy: 0.9060\n",
      "Epoch 553/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7636 - accuracy: 0.7236 - val_loss: 0.3745 - val_accuracy: 0.9046\n",
      "Epoch 554/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7746 - accuracy: 0.7225 - val_loss: 0.3629 - val_accuracy: 0.9074\n",
      "Epoch 555/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7464 - accuracy: 0.7271 - val_loss: 0.3644 - val_accuracy: 0.9060\n",
      "Epoch 556/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7491 - accuracy: 0.7420 - val_loss: 0.3514 - val_accuracy: 0.9088\n",
      "Epoch 557/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7778 - accuracy: 0.7204 - val_loss: 0.3673 - val_accuracy: 0.9074\n",
      "Epoch 558/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7377 - accuracy: 0.7384 - val_loss: 0.3677 - val_accuracy: 0.9074\n",
      "Epoch 559/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7478 - accuracy: 0.7282 - val_loss: 0.3758 - val_accuracy: 0.9046\n",
      "Epoch 560/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7418 - accuracy: 0.7359 - val_loss: 0.3656 - val_accuracy: 0.9060\n",
      "Epoch 561/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7570 - accuracy: 0.7243 - val_loss: 0.3927 - val_accuracy: 0.8976\n",
      "Epoch 562/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7431 - accuracy: 0.7264 - val_loss: 0.3752 - val_accuracy: 0.8990\n",
      "Epoch 563/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7420 - accuracy: 0.7384 - val_loss: 0.3726 - val_accuracy: 0.9004\n",
      "Epoch 564/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7423 - accuracy: 0.7345 - val_loss: 0.3796 - val_accuracy: 0.9004\n",
      "Epoch 565/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7443 - accuracy: 0.7268 - val_loss: 0.3769 - val_accuracy: 0.9060\n",
      "Epoch 566/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7474 - accuracy: 0.7317 - val_loss: 0.3793 - val_accuracy: 0.9032\n",
      "Epoch 567/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7442 - accuracy: 0.7299 - val_loss: 0.3808 - val_accuracy: 0.9074\n",
      "Epoch 568/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7450 - accuracy: 0.7342 - val_loss: 0.3673 - val_accuracy: 0.9060\n",
      "Epoch 569/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7656 - accuracy: 0.7306 - val_loss: 0.3670 - val_accuracy: 0.9102\n",
      "Epoch 570/800\n",
      "45/45 [==============================] - 12s 266ms/step - loss: 0.7491 - accuracy: 0.7338 - val_loss: 0.3768 - val_accuracy: 0.9032\n",
      "Epoch 571/800\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.7301 - accuracy: 0.7494 - val_loss: 0.3701 - val_accuracy: 0.9018\n",
      "Epoch 572/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7683 - accuracy: 0.7261 - val_loss: 0.3531 - val_accuracy: 0.9102\n",
      "Epoch 573/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7460 - accuracy: 0.7356 - val_loss: 0.3759 - val_accuracy: 0.9004\n",
      "Epoch 574/800\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.7332 - accuracy: 0.7349 - val_loss: 0.3843 - val_accuracy: 0.8962\n",
      "Epoch 575/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7049 - accuracy: 0.7561 - val_loss: 0.3693 - val_accuracy: 0.9088\n",
      "Epoch 576/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7266 - accuracy: 0.7402 - val_loss: 0.3655 - val_accuracy: 0.9074\n",
      "Epoch 577/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7261 - accuracy: 0.7409 - val_loss: 0.3738 - val_accuracy: 0.9032\n",
      "Epoch 578/800\n",
      "45/45 [==============================] - 12s 254ms/step - loss: 0.7278 - accuracy: 0.7490 - val_loss: 0.4140 - val_accuracy: 0.9004\n",
      "Epoch 579/800\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.7404 - accuracy: 0.7289 - val_loss: 0.3831 - val_accuracy: 0.8962\n",
      "Epoch 580/800\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.7377 - accuracy: 0.7363 - val_loss: 0.3898 - val_accuracy: 0.8934\n",
      "Epoch 581/800\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 0.7212 - accuracy: 0.7317 - val_loss: 0.3764 - val_accuracy: 0.8976\n",
      "Epoch 582/800\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 0.7535 - accuracy: 0.7352 - val_loss: 0.3668 - val_accuracy: 0.9102\n",
      "Epoch 583/800\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.7289 - accuracy: 0.7306 - val_loss: 0.3701 - val_accuracy: 0.9046\n",
      "Epoch 584/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7126 - accuracy: 0.7536 - val_loss: 0.3691 - val_accuracy: 0.9046\n",
      "Epoch 585/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7352 - accuracy: 0.7359 - val_loss: 0.3858 - val_accuracy: 0.9018\n",
      "Epoch 586/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7250 - accuracy: 0.7423 - val_loss: 0.3977 - val_accuracy: 0.8934\n",
      "Epoch 587/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7457 - accuracy: 0.7388 - val_loss: 0.3877 - val_accuracy: 0.8990\n",
      "Epoch 588/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7199 - accuracy: 0.7391 - val_loss: 0.3826 - val_accuracy: 0.8962\n",
      "Epoch 589/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7435 - accuracy: 0.7416 - val_loss: 0.3955 - val_accuracy: 0.9018\n",
      "Epoch 590/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7487 - accuracy: 0.7331 - val_loss: 0.3636 - val_accuracy: 0.9060\n",
      "Epoch 591/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7426 - accuracy: 0.7420 - val_loss: 0.3660 - val_accuracy: 0.9102\n",
      "Epoch 592/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7278 - accuracy: 0.7423 - val_loss: 0.3778 - val_accuracy: 0.9032\n",
      "Epoch 593/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7362 - accuracy: 0.7409 - val_loss: 0.3762 - val_accuracy: 0.9032\n",
      "Epoch 594/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6976 - accuracy: 0.7561 - val_loss: 0.3795 - val_accuracy: 0.8976\n",
      "Epoch 595/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7125 - accuracy: 0.7487 - val_loss: 0.3662 - val_accuracy: 0.9074\n",
      "Epoch 596/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7539 - accuracy: 0.7261 - val_loss: 0.3668 - val_accuracy: 0.9046\n",
      "Epoch 597/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7060 - accuracy: 0.7579 - val_loss: 0.3594 - val_accuracy: 0.9074\n",
      "Epoch 598/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6946 - accuracy: 0.7554 - val_loss: 0.3668 - val_accuracy: 0.9074\n",
      "Epoch 599/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7307 - accuracy: 0.7416 - val_loss: 0.3561 - val_accuracy: 0.9088\n",
      "Epoch 600/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7326 - accuracy: 0.7402 - val_loss: 0.3681 - val_accuracy: 0.9116\n",
      "Epoch 601/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7093 - accuracy: 0.7405 - val_loss: 0.3606 - val_accuracy: 0.9102\n",
      "Epoch 602/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7272 - accuracy: 0.7370 - val_loss: 0.3901 - val_accuracy: 0.9060\n",
      "Epoch 603/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7365 - accuracy: 0.7434 - val_loss: 0.3525 - val_accuracy: 0.9158\n",
      "Epoch 604/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7368 - accuracy: 0.7349 - val_loss: 0.3750 - val_accuracy: 0.9046\n",
      "Epoch 605/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7183 - accuracy: 0.7473 - val_loss: 0.3879 - val_accuracy: 0.8976\n",
      "Epoch 606/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7252 - accuracy: 0.7370 - val_loss: 0.3519 - val_accuracy: 0.9004\n",
      "Epoch 607/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6993 - accuracy: 0.7497 - val_loss: 0.3748 - val_accuracy: 0.9004\n",
      "Epoch 608/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7262 - accuracy: 0.7395 - val_loss: 0.3897 - val_accuracy: 0.8962\n",
      "Epoch 609/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7276 - accuracy: 0.7391 - val_loss: 0.3567 - val_accuracy: 0.9032\n",
      "Epoch 610/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7324 - accuracy: 0.7434 - val_loss: 0.3648 - val_accuracy: 0.9074\n",
      "Epoch 611/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7287 - accuracy: 0.7441 - val_loss: 0.3858 - val_accuracy: 0.8976\n",
      "Epoch 612/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7197 - accuracy: 0.7469 - val_loss: 0.3884 - val_accuracy: 0.8976\n",
      "Epoch 613/800\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.7228 - accuracy: 0.7349 - val_loss: 0.3786 - val_accuracy: 0.9046\n",
      "Epoch 614/800\n",
      "45/45 [==============================] - 12s 254ms/step - loss: 0.7330 - accuracy: 0.7391 - val_loss: 0.3960 - val_accuracy: 0.8990\n",
      "Epoch 615/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7016 - accuracy: 0.7543 - val_loss: 0.3642 - val_accuracy: 0.9130\n",
      "Epoch 616/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7139 - accuracy: 0.7427 - val_loss: 0.3640 - val_accuracy: 0.9088\n",
      "Epoch 617/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7267 - accuracy: 0.7441 - val_loss: 0.3576 - val_accuracy: 0.9046\n",
      "Epoch 618/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7367 - accuracy: 0.7402 - val_loss: 0.3745 - val_accuracy: 0.9116\n",
      "Epoch 619/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7400 - accuracy: 0.7395 - val_loss: 0.3683 - val_accuracy: 0.9116\n",
      "Epoch 620/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7172 - accuracy: 0.7476 - val_loss: 0.3788 - val_accuracy: 0.9018\n",
      "Epoch 621/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7060 - accuracy: 0.7388 - val_loss: 0.3704 - val_accuracy: 0.9018\n",
      "Epoch 622/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7125 - accuracy: 0.7462 - val_loss: 0.3576 - val_accuracy: 0.9074\n",
      "Epoch 623/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7187 - accuracy: 0.7501 - val_loss: 0.3741 - val_accuracy: 0.9004\n",
      "Epoch 624/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6994 - accuracy: 0.7473 - val_loss: 0.3722 - val_accuracy: 0.9046\n",
      "Epoch 625/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7212 - accuracy: 0.7448 - val_loss: 0.3678 - val_accuracy: 0.9046\n",
      "Epoch 626/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7061 - accuracy: 0.7547 - val_loss: 0.3577 - val_accuracy: 0.9060\n",
      "Epoch 627/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7063 - accuracy: 0.7487 - val_loss: 0.3671 - val_accuracy: 0.9102\n",
      "Epoch 628/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7115 - accuracy: 0.7547 - val_loss: 0.3744 - val_accuracy: 0.9004\n",
      "Epoch 629/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6917 - accuracy: 0.7423 - val_loss: 0.3538 - val_accuracy: 0.9088\n",
      "Epoch 630/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6841 - accuracy: 0.7550 - val_loss: 0.3776 - val_accuracy: 0.9032\n",
      "Epoch 631/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7142 - accuracy: 0.7409 - val_loss: 0.3663 - val_accuracy: 0.9004\n",
      "Epoch 632/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7180 - accuracy: 0.7469 - val_loss: 0.3638 - val_accuracy: 0.9018\n",
      "Epoch 633/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7254 - accuracy: 0.7437 - val_loss: 0.3693 - val_accuracy: 0.9088\n",
      "Epoch 634/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7214 - accuracy: 0.7504 - val_loss: 0.3495 - val_accuracy: 0.9046\n",
      "Epoch 635/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7130 - accuracy: 0.7423 - val_loss: 0.3342 - val_accuracy: 0.9116\n",
      "Epoch 636/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7126 - accuracy: 0.7476 - val_loss: 0.3427 - val_accuracy: 0.9088\n",
      "Epoch 637/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7224 - accuracy: 0.7490 - val_loss: 0.3447 - val_accuracy: 0.9130\n",
      "Epoch 638/800\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.7114 - accuracy: 0.7540 - val_loss: 0.3898 - val_accuracy: 0.8962\n",
      "Epoch 639/800\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 0.7006 - accuracy: 0.7547 - val_loss: 0.3443 - val_accuracy: 0.9060\n",
      "Epoch 640/800\n",
      "45/45 [==============================] - 12s 259ms/step - loss: 0.6995 - accuracy: 0.7522 - val_loss: 0.3653 - val_accuracy: 0.9046\n",
      "Epoch 641/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6892 - accuracy: 0.7543 - val_loss: 0.3576 - val_accuracy: 0.9032\n",
      "Epoch 642/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7158 - accuracy: 0.7497 - val_loss: 0.3732 - val_accuracy: 0.9004\n",
      "Epoch 643/800\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 0.7070 - accuracy: 0.7451 - val_loss: 0.4009 - val_accuracy: 0.8962\n",
      "Epoch 644/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7209 - accuracy: 0.7416 - val_loss: 0.3594 - val_accuracy: 0.9088\n",
      "Epoch 645/800\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.7002 - accuracy: 0.7593 - val_loss: 0.3732 - val_accuracy: 0.9046\n",
      "Epoch 646/800\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 0.7111 - accuracy: 0.7480 - val_loss: 0.3479 - val_accuracy: 0.9074\n",
      "Epoch 647/800\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 0.7107 - accuracy: 0.7420 - val_loss: 0.3446 - val_accuracy: 0.9130\n",
      "Epoch 648/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6928 - accuracy: 0.7603 - val_loss: 0.3925 - val_accuracy: 0.8976\n",
      "Epoch 649/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7087 - accuracy: 0.7434 - val_loss: 0.3747 - val_accuracy: 0.9074\n",
      "Epoch 650/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.7320 - accuracy: 0.7331 - val_loss: 0.3520 - val_accuracy: 0.9046\n",
      "Epoch 651/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7030 - accuracy: 0.7476 - val_loss: 0.3469 - val_accuracy: 0.9116\n",
      "Epoch 652/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6867 - accuracy: 0.7423 - val_loss: 0.3551 - val_accuracy: 0.9088\n",
      "Epoch 653/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7047 - accuracy: 0.7501 - val_loss: 0.3599 - val_accuracy: 0.9102\n",
      "Epoch 654/800\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.6869 - accuracy: 0.7582 - val_loss: 0.3635 - val_accuracy: 0.9046\n",
      "Epoch 655/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7141 - accuracy: 0.7416 - val_loss: 0.3631 - val_accuracy: 0.9088\n",
      "Epoch 656/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.7052 - accuracy: 0.7511 - val_loss: 0.3694 - val_accuracy: 0.9046\n",
      "Epoch 657/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6869 - accuracy: 0.7554 - val_loss: 0.3652 - val_accuracy: 0.9102\n",
      "Epoch 658/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6929 - accuracy: 0.7561 - val_loss: 0.3830 - val_accuracy: 0.9046\n",
      "Epoch 659/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7113 - accuracy: 0.7462 - val_loss: 0.3722 - val_accuracy: 0.9074\n",
      "Epoch 660/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6916 - accuracy: 0.7603 - val_loss: 0.3573 - val_accuracy: 0.9074\n",
      "Epoch 661/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7096 - accuracy: 0.7508 - val_loss: 0.3453 - val_accuracy: 0.9074\n",
      "Epoch 662/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6889 - accuracy: 0.7600 - val_loss: 0.3481 - val_accuracy: 0.9074\n",
      "Epoch 663/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6967 - accuracy: 0.7554 - val_loss: 0.3524 - val_accuracy: 0.9074\n",
      "Epoch 664/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7086 - accuracy: 0.7519 - val_loss: 0.3780 - val_accuracy: 0.9088\n",
      "Epoch 665/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6720 - accuracy: 0.7642 - val_loss: 0.3707 - val_accuracy: 0.9088\n",
      "Epoch 666/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6696 - accuracy: 0.7565 - val_loss: 0.3503 - val_accuracy: 0.9130\n",
      "Epoch 667/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7076 - accuracy: 0.7455 - val_loss: 0.3727 - val_accuracy: 0.9116\n",
      "Epoch 668/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7051 - accuracy: 0.7497 - val_loss: 0.3672 - val_accuracy: 0.9046\n",
      "Epoch 669/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7025 - accuracy: 0.7536 - val_loss: 0.3786 - val_accuracy: 0.9004\n",
      "Epoch 670/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6719 - accuracy: 0.7593 - val_loss: 0.3994 - val_accuracy: 0.9004\n",
      "Epoch 671/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6681 - accuracy: 0.7674 - val_loss: 0.4337 - val_accuracy: 0.8920\n",
      "Epoch 672/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6688 - accuracy: 0.7635 - val_loss: 0.3729 - val_accuracy: 0.9046\n",
      "Epoch 673/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7091 - accuracy: 0.7480 - val_loss: 0.3932 - val_accuracy: 0.8990\n",
      "Epoch 674/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6764 - accuracy: 0.7568 - val_loss: 0.3770 - val_accuracy: 0.9004\n",
      "Epoch 675/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6847 - accuracy: 0.7579 - val_loss: 0.3797 - val_accuracy: 0.9018\n",
      "Epoch 676/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6521 - accuracy: 0.7702 - val_loss: 0.3712 - val_accuracy: 0.9018\n",
      "Epoch 677/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6899 - accuracy: 0.7568 - val_loss: 0.3535 - val_accuracy: 0.9144\n",
      "Epoch 678/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6543 - accuracy: 0.7688 - val_loss: 0.3613 - val_accuracy: 0.9074\n",
      "Epoch 679/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6842 - accuracy: 0.7473 - val_loss: 0.3548 - val_accuracy: 0.9102\n",
      "Epoch 680/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6881 - accuracy: 0.7568 - val_loss: 0.3675 - val_accuracy: 0.8990\n",
      "Epoch 681/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6760 - accuracy: 0.7593 - val_loss: 0.3754 - val_accuracy: 0.9004\n",
      "Epoch 682/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6866 - accuracy: 0.7540 - val_loss: 0.3773 - val_accuracy: 0.9046\n",
      "Epoch 683/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6585 - accuracy: 0.7720 - val_loss: 0.3730 - val_accuracy: 0.9074\n",
      "Epoch 684/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7045 - accuracy: 0.7522 - val_loss: 0.3825 - val_accuracy: 0.9074\n",
      "Epoch 685/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.7154 - accuracy: 0.7434 - val_loss: 0.3729 - val_accuracy: 0.9004\n",
      "Epoch 686/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6672 - accuracy: 0.7667 - val_loss: 0.3649 - val_accuracy: 0.9074\n",
      "Epoch 687/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6578 - accuracy: 0.7649 - val_loss: 0.3856 - val_accuracy: 0.9004\n",
      "Epoch 688/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6710 - accuracy: 0.7596 - val_loss: 0.3654 - val_accuracy: 0.9032\n",
      "Epoch 689/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6767 - accuracy: 0.7575 - val_loss: 0.3764 - val_accuracy: 0.9060\n",
      "Epoch 690/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6426 - accuracy: 0.7709 - val_loss: 0.3864 - val_accuracy: 0.8990\n",
      "Epoch 691/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.7067 - accuracy: 0.7504 - val_loss: 0.3537 - val_accuracy: 0.8990\n",
      "Epoch 692/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6455 - accuracy: 0.7798 - val_loss: 0.3446 - val_accuracy: 0.8976\n",
      "Epoch 693/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6571 - accuracy: 0.7671 - val_loss: 0.3748 - val_accuracy: 0.8962\n",
      "Epoch 694/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6743 - accuracy: 0.7610 - val_loss: 0.3921 - val_accuracy: 0.8920\n",
      "Epoch 695/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6622 - accuracy: 0.7695 - val_loss: 0.3710 - val_accuracy: 0.9032\n",
      "Epoch 696/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6694 - accuracy: 0.7610 - val_loss: 0.3890 - val_accuracy: 0.8976\n",
      "Epoch 697/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6498 - accuracy: 0.7731 - val_loss: 0.3636 - val_accuracy: 0.8976\n",
      "Epoch 698/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6802 - accuracy: 0.7646 - val_loss: 0.3489 - val_accuracy: 0.9060\n",
      "Epoch 699/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6600 - accuracy: 0.7554 - val_loss: 0.3482 - val_accuracy: 0.9088\n",
      "Epoch 700/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6425 - accuracy: 0.7706 - val_loss: 0.3570 - val_accuracy: 0.9032\n",
      "Epoch 701/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6708 - accuracy: 0.7610 - val_loss: 0.3800 - val_accuracy: 0.9018\n",
      "Epoch 702/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6715 - accuracy: 0.7614 - val_loss: 0.3601 - val_accuracy: 0.9004\n",
      "Epoch 703/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6608 - accuracy: 0.7699 - val_loss: 0.3697 - val_accuracy: 0.9032\n",
      "Epoch 704/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6584 - accuracy: 0.7702 - val_loss: 0.3741 - val_accuracy: 0.8976\n",
      "Epoch 705/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6684 - accuracy: 0.7646 - val_loss: 0.3532 - val_accuracy: 0.9102\n",
      "Epoch 706/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6621 - accuracy: 0.7663 - val_loss: 0.3623 - val_accuracy: 0.9004\n",
      "Epoch 707/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6326 - accuracy: 0.7770 - val_loss: 0.3722 - val_accuracy: 0.9004\n",
      "Epoch 708/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6372 - accuracy: 0.7688 - val_loss: 0.3756 - val_accuracy: 0.8934\n",
      "Epoch 709/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6604 - accuracy: 0.7695 - val_loss: 0.3643 - val_accuracy: 0.9018\n",
      "Epoch 710/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6658 - accuracy: 0.7565 - val_loss: 0.3652 - val_accuracy: 0.9018\n",
      "Epoch 711/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6314 - accuracy: 0.7798 - val_loss: 0.3761 - val_accuracy: 0.8976\n",
      "Epoch 712/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6582 - accuracy: 0.7745 - val_loss: 0.3562 - val_accuracy: 0.9060\n",
      "Epoch 713/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6648 - accuracy: 0.7709 - val_loss: 0.3653 - val_accuracy: 0.9032\n",
      "Epoch 714/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6681 - accuracy: 0.7625 - val_loss: 0.3810 - val_accuracy: 0.8976\n",
      "Epoch 715/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6546 - accuracy: 0.7621 - val_loss: 0.3610 - val_accuracy: 0.9102\n",
      "Epoch 716/800\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.6747 - accuracy: 0.7582 - val_loss: 0.3578 - val_accuracy: 0.9102\n",
      "Epoch 717/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.6681 - accuracy: 0.7695 - val_loss: 0.3837 - val_accuracy: 0.9088\n",
      "Epoch 718/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6348 - accuracy: 0.7720 - val_loss: 0.3619 - val_accuracy: 0.9032\n",
      "Epoch 719/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6358 - accuracy: 0.7773 - val_loss: 0.3442 - val_accuracy: 0.9088\n",
      "Epoch 720/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6566 - accuracy: 0.7766 - val_loss: 0.3935 - val_accuracy: 0.9004\n",
      "Epoch 721/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.6657 - accuracy: 0.7557 - val_loss: 0.3531 - val_accuracy: 0.9032\n",
      "Epoch 722/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6414 - accuracy: 0.7766 - val_loss: 0.3557 - val_accuracy: 0.9102\n",
      "Epoch 723/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6624 - accuracy: 0.7610 - val_loss: 0.3647 - val_accuracy: 0.9046\n",
      "Epoch 724/800\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.6563 - accuracy: 0.7741 - val_loss: 0.3510 - val_accuracy: 0.9130\n",
      "Epoch 725/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6406 - accuracy: 0.7731 - val_loss: 0.3567 - val_accuracy: 0.9060\n",
      "Epoch 726/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6521 - accuracy: 0.7706 - val_loss: 0.3743 - val_accuracy: 0.9032\n",
      "Epoch 727/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6758 - accuracy: 0.7625 - val_loss: 0.3553 - val_accuracy: 0.9074\n",
      "Epoch 728/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6450 - accuracy: 0.7787 - val_loss: 0.3596 - val_accuracy: 0.9060\n",
      "Epoch 729/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6630 - accuracy: 0.7656 - val_loss: 0.3705 - val_accuracy: 0.9060\n",
      "Epoch 730/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6756 - accuracy: 0.7540 - val_loss: 0.3665 - val_accuracy: 0.9004\n",
      "Epoch 731/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6790 - accuracy: 0.7582 - val_loss: 0.3428 - val_accuracy: 0.9046\n",
      "Epoch 732/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6666 - accuracy: 0.7625 - val_loss: 0.3638 - val_accuracy: 0.9032\n",
      "Epoch 733/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6258 - accuracy: 0.7755 - val_loss: 0.3579 - val_accuracy: 0.9088\n",
      "Epoch 734/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6371 - accuracy: 0.7791 - val_loss: 0.3834 - val_accuracy: 0.8990\n",
      "Epoch 735/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6658 - accuracy: 0.7632 - val_loss: 0.3644 - val_accuracy: 0.9046\n",
      "Epoch 736/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6298 - accuracy: 0.7819 - val_loss: 0.3560 - val_accuracy: 0.9018\n",
      "Epoch 737/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6436 - accuracy: 0.7688 - val_loss: 0.3766 - val_accuracy: 0.9046\n",
      "Epoch 738/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6586 - accuracy: 0.7649 - val_loss: 0.3511 - val_accuracy: 0.8976\n",
      "Epoch 739/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6460 - accuracy: 0.7791 - val_loss: 0.3398 - val_accuracy: 0.9046\n",
      "Epoch 740/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6402 - accuracy: 0.7748 - val_loss: 0.3783 - val_accuracy: 0.8962\n",
      "Epoch 741/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6417 - accuracy: 0.7628 - val_loss: 0.4622 - val_accuracy: 0.8752\n",
      "Epoch 742/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6564 - accuracy: 0.7653 - val_loss: 0.3669 - val_accuracy: 0.9046\n",
      "Epoch 743/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6643 - accuracy: 0.7674 - val_loss: 0.3579 - val_accuracy: 0.9046\n",
      "Epoch 744/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6412 - accuracy: 0.7762 - val_loss: 0.3660 - val_accuracy: 0.8976\n",
      "Epoch 745/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6294 - accuracy: 0.7812 - val_loss: 0.3555 - val_accuracy: 0.9074\n",
      "Epoch 746/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6809 - accuracy: 0.7526 - val_loss: 0.4931 - val_accuracy: 0.8710\n",
      "Epoch 747/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6456 - accuracy: 0.7688 - val_loss: 0.3726 - val_accuracy: 0.9046\n",
      "Epoch 748/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6444 - accuracy: 0.7720 - val_loss: 0.3720 - val_accuracy: 0.9060\n",
      "Epoch 749/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6495 - accuracy: 0.7635 - val_loss: 0.3743 - val_accuracy: 0.9102\n",
      "Epoch 750/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6739 - accuracy: 0.7596 - val_loss: 0.3687 - val_accuracy: 0.9116\n",
      "Epoch 751/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6471 - accuracy: 0.7745 - val_loss: 0.3964 - val_accuracy: 0.8948\n",
      "Epoch 752/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6480 - accuracy: 0.7702 - val_loss: 0.3986 - val_accuracy: 0.8934\n",
      "Epoch 753/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6398 - accuracy: 0.7635 - val_loss: 0.3817 - val_accuracy: 0.9018\n",
      "Epoch 754/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6488 - accuracy: 0.7731 - val_loss: 0.3839 - val_accuracy: 0.9032\n",
      "Epoch 755/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6553 - accuracy: 0.7678 - val_loss: 0.3737 - val_accuracy: 0.9116\n",
      "Epoch 756/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6502 - accuracy: 0.7618 - val_loss: 0.4269 - val_accuracy: 0.8990\n",
      "Epoch 757/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6435 - accuracy: 0.7706 - val_loss: 0.3692 - val_accuracy: 0.9060\n",
      "Epoch 758/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6532 - accuracy: 0.7713 - val_loss: 0.3766 - val_accuracy: 0.9060\n",
      "Epoch 759/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6496 - accuracy: 0.7748 - val_loss: 0.3701 - val_accuracy: 0.9102\n",
      "Epoch 760/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6753 - accuracy: 0.7653 - val_loss: 0.4001 - val_accuracy: 0.8948\n",
      "Epoch 761/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6546 - accuracy: 0.7734 - val_loss: 0.4310 - val_accuracy: 0.8948\n",
      "Epoch 762/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6370 - accuracy: 0.7823 - val_loss: 0.4244 - val_accuracy: 0.8948\n",
      "Epoch 763/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6405 - accuracy: 0.7794 - val_loss: 0.4105 - val_accuracy: 0.8906\n",
      "Epoch 764/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6541 - accuracy: 0.7713 - val_loss: 0.3867 - val_accuracy: 0.9074\n",
      "Epoch 765/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6482 - accuracy: 0.7734 - val_loss: 0.3983 - val_accuracy: 0.8962\n",
      "Epoch 766/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6275 - accuracy: 0.7770 - val_loss: 0.3693 - val_accuracy: 0.9088\n",
      "Epoch 767/800\n",
      "45/45 [==============================] - 12s 254ms/step - loss: 0.6173 - accuracy: 0.7770 - val_loss: 0.3920 - val_accuracy: 0.8976\n",
      "Epoch 768/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6460 - accuracy: 0.7773 - val_loss: 0.3925 - val_accuracy: 0.8990\n",
      "Epoch 769/800\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 0.6574 - accuracy: 0.7724 - val_loss: 0.4216 - val_accuracy: 0.8892\n",
      "Epoch 770/800\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.6345 - accuracy: 0.7798 - val_loss: 0.3885 - val_accuracy: 0.8976\n",
      "Epoch 771/800\n",
      "45/45 [==============================] - 12s 255ms/step - loss: 0.6240 - accuracy: 0.7854 - val_loss: 0.3847 - val_accuracy: 0.8990\n",
      "Epoch 772/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6050 - accuracy: 0.7812 - val_loss: 0.4061 - val_accuracy: 0.8934\n",
      "Epoch 773/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6421 - accuracy: 0.7699 - val_loss: 0.3625 - val_accuracy: 0.9046\n",
      "Epoch 774/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6056 - accuracy: 0.7858 - val_loss: 0.3505 - val_accuracy: 0.9032\n",
      "Epoch 775/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6379 - accuracy: 0.7681 - val_loss: 0.3770 - val_accuracy: 0.9074\n",
      "Epoch 776/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6573 - accuracy: 0.7653 - val_loss: 0.3883 - val_accuracy: 0.9032\n",
      "Epoch 777/800\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.6366 - accuracy: 0.7798 - val_loss: 0.3762 - val_accuracy: 0.9046\n",
      "Epoch 778/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6304 - accuracy: 0.7819 - val_loss: 0.3930 - val_accuracy: 0.8962\n",
      "Epoch 779/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6614 - accuracy: 0.7642 - val_loss: 0.3778 - val_accuracy: 0.9060\n",
      "Epoch 780/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6307 - accuracy: 0.7900 - val_loss: 0.3874 - val_accuracy: 0.9088\n",
      "Epoch 781/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6497 - accuracy: 0.7731 - val_loss: 0.4064 - val_accuracy: 0.9046\n",
      "Epoch 782/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6524 - accuracy: 0.7702 - val_loss: 0.3855 - val_accuracy: 0.9116\n",
      "Epoch 783/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6215 - accuracy: 0.7738 - val_loss: 0.3783 - val_accuracy: 0.9088\n",
      "Epoch 784/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6096 - accuracy: 0.7840 - val_loss: 0.3913 - val_accuracy: 0.8990\n",
      "Epoch 785/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6121 - accuracy: 0.7812 - val_loss: 0.3770 - val_accuracy: 0.9088\n",
      "Epoch 786/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6244 - accuracy: 0.7801 - val_loss: 0.3780 - val_accuracy: 0.9046\n",
      "Epoch 787/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6114 - accuracy: 0.7900 - val_loss: 0.3785 - val_accuracy: 0.9116\n",
      "Epoch 788/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6126 - accuracy: 0.7798 - val_loss: 0.3741 - val_accuracy: 0.9102\n",
      "Epoch 789/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6307 - accuracy: 0.7801 - val_loss: 0.3958 - val_accuracy: 0.9102\n",
      "Epoch 790/800\n",
      "45/45 [==============================] - 12s 269ms/step - loss: 0.6494 - accuracy: 0.7695 - val_loss: 0.3934 - val_accuracy: 0.9046\n",
      "Epoch 791/800\n",
      "45/45 [==============================] - 12s 259ms/step - loss: 0.6036 - accuracy: 0.7837 - val_loss: 0.3788 - val_accuracy: 0.8990\n",
      "Epoch 792/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6575 - accuracy: 0.7625 - val_loss: 0.3676 - val_accuracy: 0.9116\n",
      "Epoch 793/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6096 - accuracy: 0.7844 - val_loss: 0.3811 - val_accuracy: 0.9046\n",
      "Epoch 794/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6082 - accuracy: 0.7830 - val_loss: 0.3765 - val_accuracy: 0.9018\n",
      "Epoch 795/800\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.6365 - accuracy: 0.7755 - val_loss: 0.4018 - val_accuracy: 0.8962\n",
      "Epoch 796/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6271 - accuracy: 0.7798 - val_loss: 0.3848 - val_accuracy: 0.9088\n",
      "Epoch 797/800\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.6301 - accuracy: 0.7805 - val_loss: 0.3718 - val_accuracy: 0.9004\n",
      "Epoch 798/800\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 0.6754 - accuracy: 0.7649 - val_loss: 0.3863 - val_accuracy: 0.8962\n",
      "Epoch 799/800\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.6148 - accuracy: 0.7780 - val_loss: 0.3754 - val_accuracy: 0.9032\n",
      "Epoch 800/800\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 0.6348 - accuracy: 0.7709 - val_loss: 0.3869 - val_accuracy: 0.9032\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = train_gen,\n",
    "    validation_data = val_gen,\n",
    "    epochs = 800,\n",
    "    callbacks = callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\zheng\\\\Documents\\\\Uni\\\\Magistrale\\\\ANNDL\\\\22-23\\\\Homework1\\\\Env'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientnetV2_Nov22_23-39-14\n"
     ]
    }
   ],
   "source": [
    "print(foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1667968886371,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "liuoATAmrUOK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f=open(os.path.join(os.getcwd(), 'experiments\\EfficientnetV2B0_Nov22_23-39-14\\history'),\"w\")\n",
    "f.write(str(history))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nov23_03-17-17\n"
     ]
    }
   ],
   "source": [
    "callbacks, date = create_folders_and_callbacks(\"EfficientnetV2B0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# foldername = mode + '_' + str(date)\n",
    "# print(foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "newmodel = tfk.models.load_model(\"experiments/EfficientnetV2B0_Nov22_23-39-14\"+\"/base_ckpts/cp_\"+str(504)+\".ckpt\",\n",
    "                                 custom_objects={\"categorical_focal_loss\": categorical_focal_loss}\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "newmodel.compile(\n",
    "    optimizer=tfk.optimizers.Adam(learning_rate=5e-5, epsilon=0.1),\n",
    "    loss=categorical_focal_loss,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.7197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_01.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_01.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 75s 1s/step - loss: 0.0608 - accuracy: 0.7197 - val_loss: 0.0433 - val_accuracy: 0.8976\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.7271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_02.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_02.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 68s 2s/step - loss: 0.0595 - accuracy: 0.7271 - val_loss: 0.0396 - val_accuracy: 0.9060\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 12s 251ms/step - loss: 0.0613 - accuracy: 0.7363 - val_loss: 0.0403 - val_accuracy: 0.8976\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.7215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_04.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_04.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 63s 1s/step - loss: 0.0608 - accuracy: 0.7215 - val_loss: 0.0383 - val_accuracy: 0.9130\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 12s 250ms/step - loss: 0.0631 - accuracy: 0.7101 - val_loss: 0.0418 - val_accuracy: 0.9004\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0607 - accuracy: 0.7246 - val_loss: 0.0410 - val_accuracy: 0.9046\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.0567 - accuracy: 0.7317 - val_loss: 0.0411 - val_accuracy: 0.9088\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0623 - accuracy: 0.7183 - val_loss: 0.0413 - val_accuracy: 0.9116\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0590 - accuracy: 0.7317 - val_loss: 0.0394 - val_accuracy: 0.9116\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0585 - accuracy: 0.7310 - val_loss: 0.0400 - val_accuracy: 0.9060\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0572 - accuracy: 0.7416 - val_loss: 0.0391 - val_accuracy: 0.9102\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0600 - accuracy: 0.7342 - val_loss: 0.0376 - val_accuracy: 0.9130\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0585 - accuracy: 0.7367 - val_loss: 0.0387 - val_accuracy: 0.9116\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.0594 - accuracy: 0.7229 - val_loss: 0.0409 - val_accuracy: 0.9032\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.7204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_15.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_15.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 63s 1s/step - loss: 0.0621 - accuracy: 0.7204 - val_loss: 0.0394 - val_accuracy: 0.9144\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.0601 - accuracy: 0.7154 - val_loss: 0.0397 - val_accuracy: 0.9102\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0611 - accuracy: 0.7193 - val_loss: 0.0388 - val_accuracy: 0.9074\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.0597 - accuracy: 0.7207 - val_loss: 0.0382 - val_accuracy: 0.9116\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0626 - accuracy: 0.7172 - val_loss: 0.0402 - val_accuracy: 0.9074\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0565 - accuracy: 0.7310 - val_loss: 0.0411 - val_accuracy: 0.9060\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0585 - accuracy: 0.7239 - val_loss: 0.0394 - val_accuracy: 0.9116\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0553 - accuracy: 0.7370 - val_loss: 0.0399 - val_accuracy: 0.9088\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0573 - accuracy: 0.7268 - val_loss: 0.0415 - val_accuracy: 0.9102\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0618 - accuracy: 0.7116 - val_loss: 0.0385 - val_accuracy: 0.9144\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0642 - accuracy: 0.7112 - val_loss: 0.0386 - val_accuracy: 0.9102\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0560 - accuracy: 0.7356 - val_loss: 0.0405 - val_accuracy: 0.9074\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.7087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_27.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_27.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 63s 1s/step - loss: 0.0614 - accuracy: 0.7087 - val_loss: 0.0380 - val_accuracy: 0.9158\n",
      "Epoch 28/200\n",
      "45/45 [==============================] - 12s 249ms/step - loss: 0.0574 - accuracy: 0.7349 - val_loss: 0.0385 - val_accuracy: 0.9130\n",
      "Epoch 29/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0582 - accuracy: 0.7363 - val_loss: 0.0400 - val_accuracy: 0.9060\n",
      "Epoch 30/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0625 - accuracy: 0.7126 - val_loss: 0.0401 - val_accuracy: 0.9102\n",
      "Epoch 31/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0603 - accuracy: 0.7250 - val_loss: 0.0396 - val_accuracy: 0.9088\n",
      "Epoch 32/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0600 - accuracy: 0.7183 - val_loss: 0.0418 - val_accuracy: 0.8990\n",
      "Epoch 33/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0588 - accuracy: 0.7370 - val_loss: 0.0405 - val_accuracy: 0.9088\n",
      "Epoch 34/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0581 - accuracy: 0.7229 - val_loss: 0.0374 - val_accuracy: 0.9116\n",
      "Epoch 35/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0572 - accuracy: 0.7275 - val_loss: 0.0413 - val_accuracy: 0.9102\n",
      "Epoch 36/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0597 - accuracy: 0.7183 - val_loss: 0.0413 - val_accuracy: 0.9046\n",
      "Epoch 37/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0592 - accuracy: 0.7158 - val_loss: 0.0412 - val_accuracy: 0.9004\n",
      "Epoch 38/200\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.7367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_38.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments\\EfficientnetV2B0_Nov23_03-17-17\\base_ckpts\\cp_38.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 63s 1s/step - loss: 0.0565 - accuracy: 0.7367 - val_loss: 0.0400 - val_accuracy: 0.9173\n",
      "Epoch 39/200\n",
      "45/45 [==============================] - 12s 250ms/step - loss: 0.0620 - accuracy: 0.7147 - val_loss: 0.0388 - val_accuracy: 0.9102\n",
      "Epoch 40/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0585 - accuracy: 0.7317 - val_loss: 0.0392 - val_accuracy: 0.9060\n",
      "Epoch 41/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0544 - accuracy: 0.7427 - val_loss: 0.0387 - val_accuracy: 0.9173\n",
      "Epoch 42/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0586 - accuracy: 0.7324 - val_loss: 0.0390 - val_accuracy: 0.9130\n",
      "Epoch 43/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0581 - accuracy: 0.7137 - val_loss: 0.0381 - val_accuracy: 0.9144\n",
      "Epoch 44/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0568 - accuracy: 0.7200 - val_loss: 0.0389 - val_accuracy: 0.9102\n",
      "Epoch 45/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0594 - accuracy: 0.7197 - val_loss: 0.0406 - val_accuracy: 0.9074\n",
      "Epoch 46/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0571 - accuracy: 0.7331 - val_loss: 0.0384 - val_accuracy: 0.9074\n",
      "Epoch 47/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0593 - accuracy: 0.7169 - val_loss: 0.0379 - val_accuracy: 0.9102\n",
      "Epoch 48/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0572 - accuracy: 0.7268 - val_loss: 0.0397 - val_accuracy: 0.9102\n",
      "Epoch 49/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0566 - accuracy: 0.7349 - val_loss: 0.0423 - val_accuracy: 0.9074\n",
      "Epoch 50/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0619 - accuracy: 0.7144 - val_loss: 0.0385 - val_accuracy: 0.9116\n",
      "Epoch 51/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0572 - accuracy: 0.7243 - val_loss: 0.0394 - val_accuracy: 0.9088\n",
      "Epoch 52/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0575 - accuracy: 0.7250 - val_loss: 0.0404 - val_accuracy: 0.9088\n",
      "Epoch 53/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0603 - accuracy: 0.7232 - val_loss: 0.0391 - val_accuracy: 0.9060\n",
      "Epoch 54/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0575 - accuracy: 0.7299 - val_loss: 0.0414 - val_accuracy: 0.9046\n",
      "Epoch 55/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0550 - accuracy: 0.7377 - val_loss: 0.0402 - val_accuracy: 0.9102\n",
      "Epoch 56/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0596 - accuracy: 0.7140 - val_loss: 0.0405 - val_accuracy: 0.9032\n",
      "Epoch 57/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0571 - accuracy: 0.7289 - val_loss: 0.0411 - val_accuracy: 0.9088\n",
      "Epoch 58/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0563 - accuracy: 0.7328 - val_loss: 0.0408 - val_accuracy: 0.9046\n",
      "Epoch 59/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0564 - accuracy: 0.7374 - val_loss: 0.0394 - val_accuracy: 0.9004\n",
      "Epoch 60/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0561 - accuracy: 0.7204 - val_loss: 0.0411 - val_accuracy: 0.9116\n",
      "Epoch 61/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0581 - accuracy: 0.7246 - val_loss: 0.0410 - val_accuracy: 0.9018\n",
      "Epoch 62/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0576 - accuracy: 0.7229 - val_loss: 0.0428 - val_accuracy: 0.8976\n",
      "Epoch 63/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0585 - accuracy: 0.7091 - val_loss: 0.0395 - val_accuracy: 0.9158\n",
      "Epoch 64/200\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0564 - accuracy: 0.7303 - val_loss: 0.0400 - val_accuracy: 0.9060\n",
      "Epoch 65/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0541 - accuracy: 0.7299 - val_loss: 0.0386 - val_accuracy: 0.9088\n",
      "Epoch 66/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0581 - accuracy: 0.7193 - val_loss: 0.0415 - val_accuracy: 0.9004\n",
      "Epoch 67/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0558 - accuracy: 0.7257 - val_loss: 0.0385 - val_accuracy: 0.9102\n",
      "Epoch 68/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0566 - accuracy: 0.7282 - val_loss: 0.0424 - val_accuracy: 0.8990\n",
      "Epoch 69/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0544 - accuracy: 0.7253 - val_loss: 0.0394 - val_accuracy: 0.9102\n",
      "Epoch 70/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0598 - accuracy: 0.7137 - val_loss: 0.0402 - val_accuracy: 0.9060\n",
      "Epoch 71/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0542 - accuracy: 0.7395 - val_loss: 0.0402 - val_accuracy: 0.9074\n",
      "Epoch 72/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0565 - accuracy: 0.7211 - val_loss: 0.0388 - val_accuracy: 0.9032\n",
      "Epoch 73/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0571 - accuracy: 0.7222 - val_loss: 0.0427 - val_accuracy: 0.9116\n",
      "Epoch 74/200\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 0.0559 - accuracy: 0.7352 - val_loss: 0.0386 - val_accuracy: 0.9116\n",
      "Epoch 75/200\n",
      "45/45 [==============================] - 11s 257ms/step - loss: 0.0586 - accuracy: 0.7215 - val_loss: 0.0387 - val_accuracy: 0.9088\n",
      "Epoch 76/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0561 - accuracy: 0.7356 - val_loss: 0.0404 - val_accuracy: 0.9018\n",
      "Epoch 77/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0563 - accuracy: 0.7282 - val_loss: 0.0399 - val_accuracy: 0.9102\n",
      "Epoch 78/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0559 - accuracy: 0.7321 - val_loss: 0.0397 - val_accuracy: 0.9060\n",
      "Epoch 79/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0577 - accuracy: 0.7264 - val_loss: 0.0404 - val_accuracy: 0.9158\n",
      "Epoch 80/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0595 - accuracy: 0.7200 - val_loss: 0.0426 - val_accuracy: 0.9074\n",
      "Epoch 81/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0540 - accuracy: 0.7310 - val_loss: 0.0413 - val_accuracy: 0.9032\n",
      "Epoch 82/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0552 - accuracy: 0.7275 - val_loss: 0.0395 - val_accuracy: 0.9144\n",
      "Epoch 83/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0546 - accuracy: 0.7183 - val_loss: 0.0394 - val_accuracy: 0.9032\n",
      "Epoch 84/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0584 - accuracy: 0.7261 - val_loss: 0.0399 - val_accuracy: 0.9102\n",
      "Epoch 85/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0550 - accuracy: 0.7328 - val_loss: 0.0397 - val_accuracy: 0.9074\n",
      "Epoch 86/200\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0542 - accuracy: 0.7303 - val_loss: 0.0413 - val_accuracy: 0.9018\n",
      "Epoch 87/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0537 - accuracy: 0.7328 - val_loss: 0.0408 - val_accuracy: 0.9018\n",
      "Epoch 88/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0571 - accuracy: 0.7328 - val_loss: 0.0435 - val_accuracy: 0.9032\n",
      "Epoch 89/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0573 - accuracy: 0.7285 - val_loss: 0.0420 - val_accuracy: 0.9018\n",
      "Epoch 90/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0562 - accuracy: 0.7268 - val_loss: 0.0397 - val_accuracy: 0.9060\n",
      "Epoch 91/200\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 0.0551 - accuracy: 0.7345 - val_loss: 0.0384 - val_accuracy: 0.9144\n",
      "Epoch 92/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0559 - accuracy: 0.7292 - val_loss: 0.0392 - val_accuracy: 0.9102\n",
      "Epoch 93/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0585 - accuracy: 0.7172 - val_loss: 0.0384 - val_accuracy: 0.9144\n",
      "Epoch 94/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0581 - accuracy: 0.7200 - val_loss: 0.0400 - val_accuracy: 0.9046\n",
      "Epoch 95/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0562 - accuracy: 0.7345 - val_loss: 0.0402 - val_accuracy: 0.9004\n",
      "Epoch 96/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0543 - accuracy: 0.7473 - val_loss: 0.0405 - val_accuracy: 0.9046\n",
      "Epoch 97/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0563 - accuracy: 0.7253 - val_loss: 0.0400 - val_accuracy: 0.9046\n",
      "Epoch 98/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0569 - accuracy: 0.7250 - val_loss: 0.0402 - val_accuracy: 0.9074\n",
      "Epoch 99/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0558 - accuracy: 0.7310 - val_loss: 0.0366 - val_accuracy: 0.9102\n",
      "Epoch 100/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0561 - accuracy: 0.7345 - val_loss: 0.0409 - val_accuracy: 0.9088\n",
      "Epoch 101/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0584 - accuracy: 0.7250 - val_loss: 0.0382 - val_accuracy: 0.9074\n",
      "Epoch 102/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0559 - accuracy: 0.7275 - val_loss: 0.0391 - val_accuracy: 0.9060\n",
      "Epoch 103/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0579 - accuracy: 0.7176 - val_loss: 0.0378 - val_accuracy: 0.9074\n",
      "Epoch 104/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0565 - accuracy: 0.7162 - val_loss: 0.0392 - val_accuracy: 0.9116\n",
      "Epoch 105/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0565 - accuracy: 0.7268 - val_loss: 0.0381 - val_accuracy: 0.9074\n",
      "Epoch 106/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0555 - accuracy: 0.7207 - val_loss: 0.0395 - val_accuracy: 0.9060\n",
      "Epoch 107/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0568 - accuracy: 0.7289 - val_loss: 0.0395 - val_accuracy: 0.9088\n",
      "Epoch 108/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0568 - accuracy: 0.7200 - val_loss: 0.0391 - val_accuracy: 0.9116\n",
      "Epoch 109/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0558 - accuracy: 0.7289 - val_loss: 0.0395 - val_accuracy: 0.9102\n",
      "Epoch 110/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0549 - accuracy: 0.7253 - val_loss: 0.0389 - val_accuracy: 0.9032\n",
      "Epoch 111/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0555 - accuracy: 0.7285 - val_loss: 0.0395 - val_accuracy: 0.9144\n",
      "Epoch 112/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0563 - accuracy: 0.7264 - val_loss: 0.0409 - val_accuracy: 0.9074\n",
      "Epoch 113/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0575 - accuracy: 0.7165 - val_loss: 0.0397 - val_accuracy: 0.9074\n",
      "Epoch 114/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0548 - accuracy: 0.7338 - val_loss: 0.0413 - val_accuracy: 0.9046\n",
      "Epoch 115/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0542 - accuracy: 0.7331 - val_loss: 0.0409 - val_accuracy: 0.9018\n",
      "Epoch 116/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0578 - accuracy: 0.7246 - val_loss: 0.0413 - val_accuracy: 0.9102\n",
      "Epoch 117/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0528 - accuracy: 0.7356 - val_loss: 0.0409 - val_accuracy: 0.9088\n",
      "Epoch 118/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0549 - accuracy: 0.7285 - val_loss: 0.0387 - val_accuracy: 0.9102\n",
      "Epoch 119/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0548 - accuracy: 0.7261 - val_loss: 0.0387 - val_accuracy: 0.9046\n",
      "Epoch 120/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0556 - accuracy: 0.7271 - val_loss: 0.0405 - val_accuracy: 0.9088\n",
      "Epoch 121/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0556 - accuracy: 0.7296 - val_loss: 0.0417 - val_accuracy: 0.9032\n",
      "Epoch 122/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0543 - accuracy: 0.7328 - val_loss: 0.0405 - val_accuracy: 0.9032\n",
      "Epoch 123/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0609 - accuracy: 0.7197 - val_loss: 0.0394 - val_accuracy: 0.9046\n",
      "Epoch 124/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0531 - accuracy: 0.7374 - val_loss: 0.0408 - val_accuracy: 0.9074\n",
      "Epoch 125/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0531 - accuracy: 0.7321 - val_loss: 0.0385 - val_accuracy: 0.9130\n",
      "Epoch 126/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0550 - accuracy: 0.7236 - val_loss: 0.0403 - val_accuracy: 0.9046\n",
      "Epoch 127/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0572 - accuracy: 0.7204 - val_loss: 0.0388 - val_accuracy: 0.9102\n",
      "Epoch 128/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0573 - accuracy: 0.7158 - val_loss: 0.0408 - val_accuracy: 0.9018\n",
      "Epoch 129/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0559 - accuracy: 0.7225 - val_loss: 0.0406 - val_accuracy: 0.9032\n",
      "Epoch 130/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0527 - accuracy: 0.7250 - val_loss: 0.0413 - val_accuracy: 0.9046\n",
      "Epoch 131/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0573 - accuracy: 0.7179 - val_loss: 0.0407 - val_accuracy: 0.9004\n",
      "Epoch 132/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0569 - accuracy: 0.7261 - val_loss: 0.0399 - val_accuracy: 0.9088\n",
      "Epoch 133/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0563 - accuracy: 0.7123 - val_loss: 0.0405 - val_accuracy: 0.9046\n",
      "Epoch 134/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0549 - accuracy: 0.7169 - val_loss: 0.0398 - val_accuracy: 0.9060\n",
      "Epoch 135/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0563 - accuracy: 0.7207 - val_loss: 0.0382 - val_accuracy: 0.9130\n",
      "Epoch 136/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0551 - accuracy: 0.7264 - val_loss: 0.0404 - val_accuracy: 0.9018\n",
      "Epoch 137/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0549 - accuracy: 0.7222 - val_loss: 0.0391 - val_accuracy: 0.9074\n",
      "Epoch 138/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0590 - accuracy: 0.7116 - val_loss: 0.0414 - val_accuracy: 0.9102\n",
      "Epoch 139/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0563 - accuracy: 0.7289 - val_loss: 0.0380 - val_accuracy: 0.9088\n",
      "Epoch 140/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0552 - accuracy: 0.7282 - val_loss: 0.0386 - val_accuracy: 0.9102\n",
      "Epoch 141/200\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 0.0571 - accuracy: 0.7303 - val_loss: 0.0373 - val_accuracy: 0.9088\n",
      "Epoch 142/200\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 0.0565 - accuracy: 0.7126 - val_loss: 0.0402 - val_accuracy: 0.9088\n",
      "Epoch 143/200\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0545 - accuracy: 0.7250 - val_loss: 0.0399 - val_accuracy: 0.9060\n",
      "Epoch 144/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0598 - accuracy: 0.7116 - val_loss: 0.0373 - val_accuracy: 0.9130\n",
      "Epoch 145/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0558 - accuracy: 0.7158 - val_loss: 0.0390 - val_accuracy: 0.9074\n",
      "Epoch 146/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0552 - accuracy: 0.7169 - val_loss: 0.0401 - val_accuracy: 0.9088\n",
      "Epoch 147/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0550 - accuracy: 0.7356 - val_loss: 0.0413 - val_accuracy: 0.9060\n",
      "Epoch 148/200\n",
      "45/45 [==============================] - 11s 251ms/step - loss: 0.0577 - accuracy: 0.7183 - val_loss: 0.0398 - val_accuracy: 0.9088\n",
      "Epoch 149/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0567 - accuracy: 0.7296 - val_loss: 0.0406 - val_accuracy: 0.9088\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0555 - accuracy: 0.7268 - val_loss: 0.0387 - val_accuracy: 0.9116\n",
      "Epoch 151/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0568 - accuracy: 0.7324 - val_loss: 0.0391 - val_accuracy: 0.9144\n",
      "Epoch 152/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0522 - accuracy: 0.7398 - val_loss: 0.0408 - val_accuracy: 0.8990\n",
      "Epoch 153/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0592 - accuracy: 0.7119 - val_loss: 0.0383 - val_accuracy: 0.9130\n",
      "Epoch 154/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0558 - accuracy: 0.7119 - val_loss: 0.0403 - val_accuracy: 0.9102\n",
      "Epoch 155/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0557 - accuracy: 0.7317 - val_loss: 0.0403 - val_accuracy: 0.9144\n",
      "Epoch 156/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0532 - accuracy: 0.7342 - val_loss: 0.0409 - val_accuracy: 0.9018\n",
      "Epoch 157/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0543 - accuracy: 0.7271 - val_loss: 0.0389 - val_accuracy: 0.9074\n",
      "Epoch 158/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0568 - accuracy: 0.7193 - val_loss: 0.0372 - val_accuracy: 0.9130\n",
      "Epoch 159/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0556 - accuracy: 0.7303 - val_loss: 0.0382 - val_accuracy: 0.9102\n",
      "Epoch 160/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0513 - accuracy: 0.7462 - val_loss: 0.0398 - val_accuracy: 0.9046\n",
      "Epoch 161/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0562 - accuracy: 0.7264 - val_loss: 0.0395 - val_accuracy: 0.9088\n",
      "Epoch 162/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0557 - accuracy: 0.7264 - val_loss: 0.0408 - val_accuracy: 0.9074\n",
      "Epoch 163/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0544 - accuracy: 0.7285 - val_loss: 0.0386 - val_accuracy: 0.9144\n",
      "Epoch 164/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0550 - accuracy: 0.7349 - val_loss: 0.0377 - val_accuracy: 0.9102\n",
      "Epoch 165/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0538 - accuracy: 0.7310 - val_loss: 0.0385 - val_accuracy: 0.9074\n",
      "Epoch 166/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0570 - accuracy: 0.7207 - val_loss: 0.0399 - val_accuracy: 0.9046\n",
      "Epoch 167/200\n",
      "45/45 [==============================] - 12s 254ms/step - loss: 0.0543 - accuracy: 0.7328 - val_loss: 0.0413 - val_accuracy: 0.9102\n",
      "Epoch 168/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0531 - accuracy: 0.7324 - val_loss: 0.0389 - val_accuracy: 0.9088\n",
      "Epoch 169/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0551 - accuracy: 0.7314 - val_loss: 0.0403 - val_accuracy: 0.9046\n",
      "Epoch 170/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0538 - accuracy: 0.7303 - val_loss: 0.0396 - val_accuracy: 0.9074\n",
      "Epoch 171/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0560 - accuracy: 0.7179 - val_loss: 0.0404 - val_accuracy: 0.9102\n",
      "Epoch 172/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0560 - accuracy: 0.7186 - val_loss: 0.0389 - val_accuracy: 0.9018\n",
      "Epoch 173/200\n",
      "45/45 [==============================] - 11s 248ms/step - loss: 0.0530 - accuracy: 0.7427 - val_loss: 0.0392 - val_accuracy: 0.9060\n",
      "Epoch 174/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0543 - accuracy: 0.7374 - val_loss: 0.0398 - val_accuracy: 0.9088\n",
      "Epoch 175/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0578 - accuracy: 0.7190 - val_loss: 0.0384 - val_accuracy: 0.9088\n",
      "Epoch 176/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0537 - accuracy: 0.7388 - val_loss: 0.0390 - val_accuracy: 0.9088\n",
      "Epoch 177/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0543 - accuracy: 0.7278 - val_loss: 0.0390 - val_accuracy: 0.9074\n",
      "Epoch 178/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0547 - accuracy: 0.7328 - val_loss: 0.0389 - val_accuracy: 0.9102\n",
      "Epoch 179/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0548 - accuracy: 0.7239 - val_loss: 0.0408 - val_accuracy: 0.9074\n",
      "Epoch 180/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0535 - accuracy: 0.7296 - val_loss: 0.0405 - val_accuracy: 0.9088\n",
      "Epoch 181/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0536 - accuracy: 0.7363 - val_loss: 0.0402 - val_accuracy: 0.9060\n",
      "Epoch 182/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0542 - accuracy: 0.7200 - val_loss: 0.0400 - val_accuracy: 0.9074\n",
      "Epoch 183/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0570 - accuracy: 0.7250 - val_loss: 0.0395 - val_accuracy: 0.9074\n",
      "Epoch 184/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0572 - accuracy: 0.7193 - val_loss: 0.0397 - val_accuracy: 0.9088\n",
      "Epoch 185/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0561 - accuracy: 0.7207 - val_loss: 0.0401 - val_accuracy: 0.9004\n",
      "Epoch 186/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0568 - accuracy: 0.7130 - val_loss: 0.0380 - val_accuracy: 0.9102\n",
      "Epoch 187/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0525 - accuracy: 0.7381 - val_loss: 0.0373 - val_accuracy: 0.9088\n",
      "Epoch 188/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0561 - accuracy: 0.7080 - val_loss: 0.0387 - val_accuracy: 0.9102\n",
      "Epoch 189/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0590 - accuracy: 0.7165 - val_loss: 0.0392 - val_accuracy: 0.9032\n",
      "Epoch 190/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0552 - accuracy: 0.7314 - val_loss: 0.0383 - val_accuracy: 0.9088\n",
      "Epoch 191/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0565 - accuracy: 0.7197 - val_loss: 0.0391 - val_accuracy: 0.9088\n",
      "Epoch 192/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0544 - accuracy: 0.7292 - val_loss: 0.0389 - val_accuracy: 0.8990\n",
      "Epoch 193/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0545 - accuracy: 0.7186 - val_loss: 0.0405 - val_accuracy: 0.9018\n",
      "Epoch 194/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0564 - accuracy: 0.7246 - val_loss: 0.0393 - val_accuracy: 0.9060\n",
      "Epoch 195/200\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 0.0543 - accuracy: 0.7229 - val_loss: 0.0402 - val_accuracy: 0.9032\n",
      "Epoch 196/200\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 0.0566 - accuracy: 0.7264 - val_loss: 0.0474 - val_accuracy: 0.8892\n",
      "Epoch 197/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0564 - accuracy: 0.7211 - val_loss: 0.0382 - val_accuracy: 0.9088\n",
      "Epoch 198/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0559 - accuracy: 0.7278 - val_loss: 0.0386 - val_accuracy: 0.9088\n",
      "Epoch 199/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0543 - accuracy: 0.7236 - val_loss: 0.0402 - val_accuracy: 0.9018\n",
      "Epoch 200/200\n",
      "45/45 [==============================] - 11s 250ms/step - loss: 0.0562 - accuracy: 0.7232 - val_loss: 0.0385 - val_accuracy: 0.9074\n"
     ]
    }
   ],
   "source": [
    "re_history = newmodel.fit(\n",
    "    x = train_gen,\n",
    "    validation_data = val_gen,\n",
    "    epochs = 200,\n",
    "    callbacks = callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um4Ebl0aqiYa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Trend plot\n",
    "Model loss and accuracy trends can be plotted for a better understanding of the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMTI1OpUGDBK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1667968557297,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "V75c5PjD0b6e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1667968557880,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "uKzFy9BmJ1oc",
    "outputId": "669b0d2b-0eb2-4439-bb32-93d5751263a3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history['loss'], label='Training', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\n",
    "plt.title(mode + ' Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1667968567331,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "Q1T2m3MhJ1H9",
    "outputId": "040dac2e-7437-436a-b790-da1811a52b26",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history['accuracy'], label='Training', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(history['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\n",
    "plt.title(mode + ' Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(re_history['loss'], label='Training', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(re_history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\n",
    "plt.title(mode + ' Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(re_history['accuracy'], label='Training', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(re_history['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\n",
    "plt.title(mode + ' Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIkjM67YNay_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model evaluation\n",
    "For a better evaluation, we compute the validation F1 scores of the 8 classes locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from albumentations import *\n",
    "import albumentations as alb\n",
    "\n",
    "class PlantDataset():\n",
    "    \"\"\"The class PlantDataset loads the data and executes the pre-processing operations on it\"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        images = self.load_images(path)\n",
    "        self.images, self.labels, _,_ = self.split_images(images, 0)\n",
    "        #self.images,self.labels=self.augment_images()\n",
    "\n",
    "    @staticmethod\n",
    "    def split_images(images, rate):\n",
    "        train_data = []\n",
    "        train_labels = []\n",
    "        test_data = []\n",
    "        test_labels = []\n",
    "        for k in images.keys():\n",
    "            n = int(len(images[k]) * rate)\n",
    "            train_data += images[k][n:]\n",
    "            test_data += images[k][:n]\n",
    "            train_labels += [k] * (len(images[k]) - n)\n",
    "            test_labels += [k] * (n)\n",
    "\n",
    "        return train_data, train_labels, test_data, test_labels\n",
    "    def augment_images(self):\n",
    "        image_augmented=[]\n",
    "        labels=[]\n",
    "        for i,l in zip(self.images,self.labels):\n",
    "\n",
    "            image_augmented.append(i)\n",
    "            labels.append(l)\n",
    "\n",
    "            image_augmented.append(tf.image.flip_left_right(i))\n",
    "            labels.append(l)\n",
    "\n",
    "            image_augmented.append(tf.image.flip_up_down(i))\n",
    "            labels.append(l)\n",
    "\n",
    "            image_augmented.append(tf.image.transpose(i))\n",
    "            labels.append(l)\n",
    "\n",
    "\n",
    "        return image_augmented,labels\n",
    "\n",
    "    def get_images(self):\n",
    "        return self.images, self.labels\n",
    "\n",
    "    @staticmethod\n",
    "    def load_images(image_path):\n",
    "        \"\"\"This method loads the images from the given path\"\"\"\n",
    "        images = {}\n",
    "        for i, file in enumerate(os.listdir(image_path)):\n",
    "            for img in os.listdir(os.path.join(image_path, file)):\n",
    "                path = os.path.join(image_path, file, img)\n",
    "                image = Image.open(path)\n",
    "                if i in images:\n",
    "                    images[i].append(np.asarray(image))\n",
    "                else:\n",
    "                    images[i]=[np.asarray(image)]\n",
    "\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "ds=PlantDataset(validation_dir)\n",
    "ds.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1667961570280,
     "user": {
      "displayName": "Maria Yu",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "9KajQvAKPyjR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "\n",
    "    X = np.reshape(X, (-1, 96, 96, 3))\n",
    "    assert X.ndim == 4\n",
    "\n",
    "#     X = X/255.\n",
    "\n",
    "    X = tf.keras.applications.efficientnet_v2.preprocess_input(X)\n",
    "    \n",
    "#     prediction = model.predict(X)\n",
    "    \n",
    "    predicts = []\n",
    "    \n",
    "    fs = [tf.image.flip_left_right, tf.image.flip_up_down, tf.image.transpose]\n",
    "    for f in fs:\n",
    "        data = f(X)\n",
    "        pred = model.predict(data)\n",
    "        predicts.append(pred)\n",
    "    \n",
    "    prediction = model.predict(X)\n",
    "    \n",
    "    for j in range(0, len(predicts)):\n",
    "        prediction += predicts[j]\n",
    "    prediction = prediction / (1 + len(predicts))\n",
    "    \n",
    "    output = tf.argmax(prediction, axis=-1)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(ds, model,step=100):\n",
    "    \"\"\"Compute the accuracy rate on the given dataset with the input model\"\"\"\n",
    "\n",
    "    num_correct = 0\n",
    "    data,target=ds.get_images()\n",
    "    n =ds.__len__()\n",
    "    tp=[0]*8\n",
    "    tn=[0]*8\n",
    "    fp=[0]*8\n",
    "    fn=[0]*8\n",
    "    for i in range(0,n//step+1):\n",
    "        x=data[i*step:min(n,(i+1)*step)]\n",
    "        y=target[i*step:min(n,(i+1)*step)]\n",
    "        output = predict(model,x)\n",
    "        c=np.array(y==output)\n",
    "        num_correct += sum(c)\n",
    "        for a,b in zip(y,output):\n",
    "            if a==b:\n",
    "                tp[a]+=1\n",
    "                for i in range(8):\n",
    "                    if i==a:\n",
    "                        continue\n",
    "                    tn[i]+=1\n",
    "            else:\n",
    "                fp[b]+=1\n",
    "                fn[a]+=1\n",
    "                for i in range(8):\n",
    "                    if i==a or i==b:\n",
    "                        continue\n",
    "                    tn[i]+=1\n",
    "\n",
    "\n",
    "    print(num_correct/ds.__len__())\n",
    "    for i in range(8):\n",
    "        precision=tp[i]/(tp[i]+fp[i]+1e-3)\n",
    "        recall=tp[i]/(tp[i]+fn[i]+1e-3)\n",
    "        print(\"class:\",i,\"f1 score:\",2 * precision * recall / (precision + recall + 1e-3),\"precision:\",precision,\"recall:\",recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\zheng\\\\Documents\\\\Uni\\\\Magistrale\\\\ANNDL\\\\22-23\\\\Homework1\\\\Env'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "cRodfJu0OmU1",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713\n",
      "504\n",
      "4/4 [==============================] - 2s 115ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 36ms/step\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.9186535764375876\n",
      "class: 0 f1 score: 0.6566281300219172 precision: 0.7187275397643824 recall: 0.6052472303360438\n",
      "class: 1 f1 score: 0.9277213376158968 precision: 0.9509710689110891 recall: 0.9065335837982822\n",
      "class: 2 f1 score: 0.952321862112121 precision: 0.9265970036972138 recall: 0.9805730041455908\n",
      "class: 3 f1 score: 0.9277211546704807 precision: 0.9150857067386157 recall: 0.9417384297239833\n",
      "class: 4 f1 score: 0.9360774579779928 precision: 0.9795818410016224 recall: 0.8971878767488154\n",
      "class: 5 f1 score: 0.954024280579659 precision: 0.9767214715936839 recall: 0.9333125930534878\n",
      "class: 6 f1 score: 0.9501648745839977 precision: 0.9217311153816053 recall: 0.9814723937741316\n",
      "class: 7 f1 score: 0.885206540217216 precision: 0.861103137933908 recall: 0.9117557671003225\n",
      "361\n",
      "4/4 [==============================] - 1s 140ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.9130434782608695\n",
      "class: 0 f1 score: 0.7037083461141809 precision: 0.7575528014302597 recall: 0.6578774242783085\n",
      "class: 1 f1 score: 0.929069016249815 precision: 0.9339534532693088 recall: 0.9252249978972159\n",
      "class: 2 f1 score: 0.9564290058573329 precision: 0.9433873265346553 recall: 0.9708643605401889\n",
      "class: 3 f1 score: 0.9121127726966046 precision: 0.9126124989077775 recall: 0.9126124989077775\n",
      "class: 4 f1 score: 0.9137774613805237 precision: 0.9320297861185813 recall: 0.8971878767488154\n",
      "class: 5 f1 score: 0.9432993435527883 precision: 0.9545237608236177 recall: 0.9333125930534878\n",
      "class: 6 f1 score: 0.945438052973508 precision: 0.9210445522407698 recall: 0.9722132202479606\n",
      "class: 7 f1 score: 0.8732782575114225 precision: 0.8653762944587071 recall: 0.8823442907422476\n",
      "318\n",
      "4/4 [==============================] - 1s 101ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 36ms/step\n",
      "4/4 [==============================] - 0s 36ms/step\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 31ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.9102384291725105\n",
      "class: 0 f1 score: 0.693927055515587 precision: 0.7352724919855299 recall: 0.6578774242783085\n",
      "class: 1 f1 score: 0.9247252679558193 precision: 0.9252249978972159 recall: 0.9252249978972159\n",
      "class: 2 f1 score: 0.9514142325738904 precision: 0.9428481633508252 recall: 0.961155716934787\n",
      "class: 3 f1 score: 0.908582587495514 precision: 0.8962179602079225 recall: 0.9223211425131794\n",
      "class: 4 f1 score: 0.9042537454318683 precision: 0.9223211425131794 recall: 0.8878421696993486\n",
      "class: 5 f1 score: 0.954024280579659 precision: 0.9767214715936839 recall: 0.9333125930534878\n",
      "class: 6 f1 score: 0.9497181637072645 precision: 0.929195316855603 recall: 0.9722132202479606\n",
      "class: 7 f1 score: 0.872040751645126 precision: 0.872540465289556 recall: 0.872540465289556\n",
      "317\n",
      "4/4 [==============================] - 1s 84ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.9102384291725105\n",
      "class: 0 f1 score: 0.6818428494232616 precision: 0.6170081487627923 recall: 0.7631378121628378\n",
      "class: 1 f1 score: 0.930864886435392 precision: 0.9793713466871475 recall: 0.8878421696993486\n",
      "class: 2 f1 score: 0.9555885065160113 precision: 0.9607748943637807 recall: 0.9514470733293852\n",
      "class: 3 f1 score: 0.9240202503266896 precision: 0.8990743204190786 recall: 0.9514470733293852\n",
      "class: 4 f1 score: 0.9009002750554994 precision: 0.905651833473269 recall: 0.8971878767488154\n",
      "class: 5 f1 score: 0.9280521375075218 precision: 0.9999743596318044 recall: 0.8666474078353815\n",
      "class: 6 f1 score: 0.945438052973508 precision: 0.9210445522407698 recall: 0.9722132202479606\n",
      "class: 7 f1 score: 0.8850637211304696 precision: 0.8989808183755719 recall: 0.872540465289556\n",
      "227\n",
      "4/4 [==============================] - 5s 158ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 33ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "4/4 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.9074333800841514\n",
      "class: 0 f1 score: 0.6751581490714804 precision: 0.6944251548568096 recall: 0.6578774242783085\n",
      "class: 1 f1 score: 0.9145860242382722 precision: 0.9238007257073741 recall: 0.9065335837982822\n",
      "class: 2 f1 score: 0.9518723257494583 precision: 0.9345707049466827 recall: 0.9708643605401889\n",
      "class: 3 f1 score: 0.9058953956293934 precision: 0.9199908000919991 recall: 0.8931952116969738\n",
      "class: 4 f1 score: 0.9085827704367849 precision: 0.9313634180057058 recall: 0.8878421696993486\n",
      "class: 5 f1 score: 0.954024280579659 precision: 0.9767214715936839 recall: 0.9333125930534878\n",
      "class: 6 f1 score: 0.9583957068614085 precision: 0.9459374239871713 recall: 0.9722132202479606\n",
      "class: 7 f1 score: 0.8620519051912675 precision: 0.8348547261034303 recall: 0.8921481161949393\n"
     ]
    }
   ],
   "source": [
    "print(ds.__len__())\n",
    "for n in [504, 361, 318, 317, 227]:\n",
    "    print(n)\n",
    "    newmodel = tfk.models.load_model(\n",
    "        \"experiments/EfficientnetV2B0_Nov22_23-39-14\"+\"/base_ckpts/cp_\"+str(n)+\".ckpt\",\n",
    "        custom_objects={\"categorical_focal_loss\": categorical_focal_loss}\n",
    "    )\n",
    "    accuracy(ds,newmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-83ete1O0DT6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model saving\n",
    "The model is saved and it can be reloaded if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2376,
     "status": "ok",
     "timestamp": 1637329343715,
     "user": {
      "displayName": "Maria Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "KWuFBdq8qpDj",
    "outputId": "10047537-b514-445c-ec90-25156d117bcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Baseline/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Baseline/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(mode)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOPyCRRk0/5km7Xtc6Ky4m6",
   "mount_file_id": "1O_120kCNjLtqhdQFRsW98ZfKb0e80IiF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}