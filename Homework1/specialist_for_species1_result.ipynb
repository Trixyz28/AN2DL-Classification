{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "rGEgyogRPFYc"
      },
      "source": [
        "# Notebook for ANNDL - Homework 1\n",
        "\n",
        "Team: All Is Well\n",
        "\n",
        "Team members: Fatma Hamila, Kodai, Zheng Maria Yu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_QsOhFvo7qr"
      },
      "source": [
        "# Setup\n",
        "Firstly, we need to setup the environment by mounting Google Drive, importing the required libraries and fixing the random seed for our experiments' reproducibility.\n",
        "\n",
        "The path should be set to where this notebook file is, and the dataset should be present in the same folder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-jrxIjNPd9_"
      },
      "outputs": [],
      "source": [
        "gdrive = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmKFZO7TPeoI",
        "outputId": "b2990efb-e2e9-496b-cb9e-8bce0641a2b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\zheng\\Documents\\Uni\\Magistrale\\ANNDL\\22-23\\Homework1\\Playground\n"
          ]
        }
      ],
      "source": [
        "if(gdrive):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/gdrive')\n",
        "    path = \"/gdrive/My Drive/Colab Notebooks/AN2DL/Homework1\"\n",
        "    %cd /gdrive/My Drive/Colab Notebooks/AN2DL/Homework1\n",
        "else:\n",
        "    path = os.getcwd()\n",
        "    print(str(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:45.822447Z",
          "iopub.status.busy": "2022-11-17T19:54:45.821616Z",
          "iopub.status.idle": "2022-11-17T19:54:45.856872Z",
          "shell.execute_reply": "2022-11-17T19:54:45.854503Z",
          "shell.execute_reply.started": "2022-11-17T19:54:45.822405Z"
        },
        "id": "yQFwFti7OMl6",
        "outputId": "af993660-4333-49da-f828-629849654760"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 13374501323155411370\n",
              " xla_global_id: -1,\n",
              " name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 5738397696\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 9919746650561388401\n",
              " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2d:00.0, compute capability: 8.6\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:45.962657Z",
          "iopub.status.busy": "2022-11-17T19:54:45.961991Z",
          "iopub.status.idle": "2022-11-17T19:54:45.968027Z",
          "shell.execute_reply": "2022-11-17T19:54:45.966488Z",
          "shell.execute_reply.started": "2022-11-17T19:54:45.962608Z"
        },
        "id": "Z9l-AdB1uPvC"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:46.236187Z",
          "iopub.status.busy": "2022-11-17T19:54:46.234747Z",
          "iopub.status.idle": "2022-11-17T19:54:46.243940Z",
          "shell.execute_reply": "2022-11-17T19:54:46.241978Z",
          "shell.execute_reply.started": "2022-11-17T19:54:46.236121Z"
        },
        "id": "76iRDDThuZsI"
      },
      "outputs": [],
      "source": [
        "# Fix random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tiaTPpzp3xZ"
      },
      "source": [
        "# Data splitting\n",
        "Now the dataset file should be unzipped and split into two parts: a training folder and a validation folder. (Current split ratio: 19:1)\n",
        "\n",
        "Two data splitting modes are provided here:\n",
        "- make a random split using the package split-folders,\n",
        "- make a regular split using the function we defined below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:46.448040Z",
          "iopub.status.busy": "2022-11-17T19:54:46.447678Z",
          "iopub.status.idle": "2022-11-17T19:54:46.453947Z",
          "shell.execute_reply": "2022-11-17T19:54:46.452086Z",
          "shell.execute_reply.started": "2022-11-17T19:54:46.448015Z"
        },
        "id": "yDohWCxatbUK"
      },
      "outputs": [],
      "source": [
        "# Set to True to use the random seed for data splitting\n",
        "split_folder = False\n",
        "random_split = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:46.665198Z",
          "iopub.status.busy": "2022-11-17T19:54:46.664750Z",
          "iopub.status.idle": "2022-11-17T19:54:46.682310Z",
          "shell.execute_reply": "2022-11-17T19:54:46.681222Z",
          "shell.execute_reply.started": "2022-11-17T19:54:46.665159Z"
        },
        "id": "0QBNxSL0BTN1"
      },
      "outputs": [],
      "source": [
        "# Random split: the operation is based on the chosen random seed\n",
        "# Regular split: the operation selects a validation sample per 20 images\n",
        "\n",
        "if(split_folder):\n",
        "    %cd '/kaggle/input/d/kodai7/an2dl-homework1-dataset2/dataset2'\n",
        "\n",
        "if(split_folder and random_split):\n",
        "\n",
        "  cwd = os.getcwd()\n",
        "  cwd\n",
        "\n",
        "  !pip install split-folders\n",
        "\n",
        "  import splitfolders\n",
        "  splitfolders.ratio(\"training\", output=\"output\", seed=seed, ratio=(.8, .1, .1), group_prefix=None)\n",
        "  print(\"Random split completed\")\n",
        "\n",
        "elif(split_folder):\n",
        "\n",
        "  import glob\n",
        "  import shutil\n",
        "\n",
        "  path = dataset_dir_path\n",
        "  os.chdir(path)\n",
        "  cwd = os.getcwd()\n",
        "  cwd\n",
        "\n",
        "  os.makedirs(\"validation\", exist_ok=True)\n",
        "\n",
        "  i = 0\n",
        "  for file in glob.glob(\"training/*/*.jpg\", recursive=True):\n",
        "    if i == 20:\n",
        "        old_path = os.path.join(cwd, str(file))\n",
        "        new_path = old_path.replace(\"training\", \"validation\")\n",
        "        print(\"Image: \" + new_path)\n",
        "        if not os.path.exists(os.path.dirname(new_path)):\n",
        "            os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
        "        shutil.move(old_path, new_path)\n",
        "        i = 0\n",
        "        continue\n",
        "    i += 1\n",
        "  print(\"Regular split completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:46.901689Z",
          "iopub.status.busy": "2022-11-17T19:54:46.901052Z",
          "iopub.status.idle": "2022-11-17T19:54:46.908277Z",
          "shell.execute_reply": "2022-11-17T19:54:46.907302Z",
          "shell.execute_reply.started": "2022-11-17T19:54:46.901651Z"
        },
        "id": "nwT9Pp6EuqXS"
      },
      "outputs": [],
      "source": [
        "# Set working paths\n",
        "# default random_split\n",
        "\n",
        "if((split_folder and random_split) or not split_folder):\n",
        "    data_dir = os.path.join(path, 'dataset2')\n",
        "    dataset_dir = os.path.join(data_dir, 'output')\n",
        "    training_dir = os.path.join(dataset_dir, 'train')\n",
        "    validation_dir = os.path.join(dataset_dir, 'val')\n",
        "    test_dir = os.path.join(dataset_dir, 'test')\n",
        "elif(split_folder):\n",
        "    dataset_dir = cwd\n",
        "    training_dir = os.path.join(dataset_dir, 'training')\n",
        "    validation_dir = os.path.join(dataset_dir, 'validation')\n",
        "    test_dir = os.path.join(dataset_dir, 'test')    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqDbLz4_rf_c"
      },
      "source": [
        "# Mode selection\n",
        "There are different available options for the model: it can be a basic convolutional neural network or based on a pre-trained one.\n",
        "\n",
        "The pre-trained models that we tried out are MobileNetV2, ResNet50V2, VGG19, EfficientNetB7.\n",
        "\n",
        "In transfer learning mode, the parameters of the supernet are freezed temporarily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:47.826832Z",
          "iopub.status.busy": "2022-11-17T19:54:47.826203Z",
          "iopub.status.idle": "2022-11-17T19:54:47.833546Z",
          "shell.execute_reply": "2022-11-17T19:54:47.832214Z",
          "shell.execute_reply.started": "2022-11-17T19:54:47.826791Z"
        },
        "id": "iKtdPypGrfPK"
      },
      "outputs": [],
      "source": [
        "# Params: [Baseline, Mobilenet, Resnet, VGG, Efficientnet]\n",
        "mode = 'VGG'\n",
        "transfer_learning = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyKeLF_IqD6j"
      },
      "source": [
        "# Data pre-processing\n",
        "In this part, data preprocessing is done with the corresponding preprocessing function or with the rescale factor.\n",
        "\n",
        "Data augmentation options are also available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:48.523694Z",
          "iopub.status.busy": "2022-11-17T19:54:48.523110Z",
          "iopub.status.idle": "2022-11-17T19:54:48.534208Z",
          "shell.execute_reply": "2022-11-17T19:54:48.531990Z",
          "shell.execute_reply.started": "2022-11-17T19:54:48.523665Z"
        },
        "id": "74IWMU_HrxPa"
      },
      "outputs": [],
      "source": [
        "# Import the correct preprocessing function for pre-trained models\n",
        "if mode == 'Mobilenet':\n",
        "  from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "if mode == 'Resnet':\n",
        "  from tensorflow.keras.applications.resnet50v2 import preprocess_input\n",
        "\n",
        "if mode == 'Efficientnet':\n",
        "  from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "if mode == 'VGG':\n",
        "  from tensorflow.keras.applications.vgg19 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:48.881766Z",
          "iopub.status.busy": "2022-11-17T19:54:48.881393Z",
          "iopub.status.idle": "2022-11-17T19:54:48.890101Z",
          "shell.execute_reply": "2022-11-17T19:54:48.888381Z",
          "shell.execute_reply.started": "2022-11-17T19:54:48.881740Z"
        },
        "id": "1Twnvp3TuTWq"
      },
      "outputs": [],
      "source": [
        "# Set batch size\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:49.379346Z",
          "iopub.status.busy": "2022-11-17T19:54:49.378957Z",
          "iopub.status.idle": "2022-11-17T19:54:49.385064Z",
          "shell.execute_reply": "2022-11-17T19:54:49.383060Z",
          "shell.execute_reply.started": "2022-11-17T19:54:49.379309Z"
        },
        "id": "-IKTqKzA4pkf"
      },
      "outputs": [],
      "source": [
        "# Set to True to apply data augmentation methods\n",
        "data_augmentation = True\n",
        "read_data_as_array = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T19:54:49.654422Z",
          "iopub.status.busy": "2022-11-17T19:54:49.653288Z",
          "iopub.status.idle": "2022-11-17T19:55:16.716475Z",
          "shell.execute_reply": "2022-11-17T19:55:16.712660Z",
          "shell.execute_reply.started": "2022-11-17T19:54:49.654359Z"
        },
        "id": "n8CXQ0kyOMmB"
      },
      "outputs": [],
      "source": [
        "if(read_data_as_array):\n",
        "    imgs_others = []\n",
        "    class_img_others_pahts = os.walk(training_dir + '/Others/')\n",
        "    for img_paths in class_img_others_pahts:\n",
        "        for img_path in img_paths[2]:\n",
        "            # load the image\n",
        "            image = Image.open(training_dir + '/Others/'+img_path)\n",
        "            # convert image to numpy array\n",
        "            data = np.asarray(image)\n",
        "            imgs_others.append(data)\n",
        "    imgs_others_y = np.zeros(shape=(1, len(imgs_others)), dtype=int)[0]\n",
        "    \n",
        "    imgs_sp1 = []\n",
        "    class_img_sp1_pahts = os.walk(training_dir + '/Species1/')\n",
        "    for img_paths in class_img_sp1_pahts:\n",
        "        for img_path in img_paths[2]:\n",
        "            # load the image\n",
        "            image = Image.open(training_dir + '/Species1/'+img_path)\n",
        "            # convert image to numpy array\n",
        "            data = np.asarray(image)\n",
        "            imgs_sp1.append(data)\n",
        "    imgs_sp1_y = np.ones(shape=(1, len(imgs_sp1)), dtype=int)[0]\n",
        "    \n",
        "    # TRAINING UNDER SAMPLING\n",
        "    mask_others = np.full(len(imgs_others), False)\n",
        "    mask_others[:len(imgs_sp1)] = True\n",
        "    np.random.shuffle(mask_others)\n",
        "    imgs_others = np.array(imgs_others)\n",
        "    imgs_others_undersampled = imgs_others[mask_others]\n",
        "    imgs_others_undersampled_y = np.zeros(shape=(1, len(imgs_others_undersampled)), dtype=int)[0]\n",
        "    \n",
        "#     imgs_x, imgs_y are after undersampling\n",
        "    imgs_x = np.concatenate((imgs_others_undersampled, imgs_sp1))\n",
        "    imgs_y = np.concatenate((imgs_others_undersampled_y, imgs_sp1_y), dtype=int)\n",
        "\n",
        "    train_imgs_x, valid_imgs_x, train_imgs_y, valid_imgs_y = train_test_split(imgs_x, imgs_y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-17T19:56:33.301640Z",
          "iopub.status.busy": "2022-11-17T19:56:33.301264Z",
          "iopub.status.idle": "2022-11-17T19:56:33.309801Z",
          "shell.execute_reply": "2022-11-17T19:56:33.308330Z",
          "shell.execute_reply.started": "2022-11-17T19:56:33.301608Z"
        },
        "id": "Audq90CbOMmC",
        "outputId": "0755b045-dd55-4612-81a0-1cd160da9424"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((236, 96, 96, 3), (236,), (60, 96, 96, 3), (60,))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_imgs_x.shape, train_imgs_y.shape, valid_imgs_x.shape, valid_imgs_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOEN7HBhG_WY"
      },
      "outputs": [],
      "source": [
        "# Define augmented images generator\n",
        "\n",
        "import albumentations as alb\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class AugmentDataGenerator(Sequence):\n",
        "    def __init__(self, datagen, augment=None):\n",
        "        self.datagen = datagen\n",
        "        if augment is None:\n",
        "            self.augment = alb.Compose([])\n",
        "        else:\n",
        "            self.augment = augment\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.datagen)\n",
        "    \n",
        "    def __getitem__(self, x):\n",
        "        images, *rest = self.datagen[x]\n",
        "        augmented = []\n",
        "        for image in images:\n",
        "            image = self.augment(image=image)['image']\n",
        "            augmented.append(image)\n",
        "        return (np.array(augmented), *rest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-17T20:04:14.571925Z",
          "iopub.status.busy": "2022-11-17T20:04:14.571503Z",
          "iopub.status.idle": "2022-11-17T20:04:14.588387Z",
          "shell.execute_reply": "2022-11-17T20:04:14.587010Z",
          "shell.execute_reply.started": "2022-11-17T20:04:14.571887Z"
        },
        "id": "DBPFKJxkvJcK",
        "outputId": "d9ae3c0c-60b9-4bec-9637-4cafe54f65ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data augmentation and input preprocessing completed\n"
          ]
        }
      ],
      "source": [
        "# Load data with ImageDataGenerator\n",
        "# Other available parameters: width_shift_range = 0.2, height_shift_range = 0.2, zoom_range = 0.15, rotation_range = 20\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "if(data_augmentation):\n",
        "    if(mode == 'Baseline'):\n",
        "        train_data_gen = ImageDataGenerator(\n",
        "            horizontal_flip = True,\n",
        "            vertical_flip = True,\n",
        "            fill_mode = \"reflect\",\n",
        "            rescale = 1/255.\n",
        "        )\n",
        "\n",
        "        val_data_gen = ImageDataGenerator(\n",
        "            rescale = 1/255.)\n",
        "\n",
        "        test_data_gen = ImageDataGenerator(\n",
        "            rescale = 1/255.)\n",
        "\n",
        "        print(\"Data augmentation and rescaling completed\")\n",
        "    \n",
        "    else:\n",
        "        # train_data_gen = ImageDataGenerator(\n",
        "        #     rotation_range = 90,\n",
        "        #     zoom_range = 0.2,\n",
        "        #     width_shift_range = 0.2,\n",
        "        #     height_shift_range = 0.2,\n",
        "        #     horizontal_flip = True,\n",
        "        #     vertical_flip = True,\n",
        "        #     fill_mode = \"reflect\",\n",
        "        #     preprocessing_function = preprocess_input\n",
        "        # )\n",
        "\n",
        "        train_data_gen = ImageDataGenerator(\n",
        "            preprocessing_function = preprocess_input)\n",
        "\n",
        "        val_data_gen = ImageDataGenerator(\n",
        "            preprocessing_function = preprocess_input)\n",
        "\n",
        "        test_data_gen = ImageDataGenerator(\n",
        "            preprocessing_function = preprocess_input)\n",
        "\n",
        "        print(\"Data augmentation and input preprocessing completed\")\n",
        "        \n",
        "else:\n",
        "\n",
        "    if(mode == 'Baseline'):\n",
        "      train_data_gen = ImageDataGenerator(\n",
        "          rescale = 1/255.)\n",
        "      val_data_gen = ImageDataGenerator(\n",
        "          rescale = 1/255.)\n",
        "      test_data_gen = ImageDataGenerator(\n",
        "          rescale = 1/255.)\n",
        "      print(\"Rescaling completed\")\n",
        "\n",
        "    else:\n",
        "      train_data_gen = ImageDataGenerator(\n",
        "          preprocessing_function = preprocess_input)\n",
        "      val_data_gen = ImageDataGenerator(\n",
        "          preprocessing_function = preprocess_input)\n",
        "      test_data_gen = ImageDataGenerator(\n",
        "          preprocessing_function = preprocess_input)\n",
        "      print(\"Input preprocessing completed\")\n",
        "\n",
        "        \n",
        "if (read_data_as_array):\n",
        "    train_gen = train_data_gen.flow(\n",
        "        train_imgs_x,\n",
        "        train_imgs_y,\n",
        "        batch_size = batch_size,\n",
        "        shuffle = True,\n",
        "        seed = seed\n",
        "    )\n",
        "\n",
        "    val_gen = val_data_gen.flow(\n",
        "        valid_imgs_x,\n",
        "        valid_imgs_y,\n",
        "        batch_size = batch_size,\n",
        "        shuffle = False,\n",
        "        seed = seed\n",
        "    )\n",
        "\n",
        "#     test_gen = test_data_gen.flow(\n",
        "#         train_imgs_x,\n",
        "#         train_imgs_y,\n",
        "#         target_size = (96,96),\n",
        "#         color_mode = 'rgb',\n",
        "#         classes = None,\n",
        "#         class_mode = 'binary',\n",
        "#         batch_size = batch_size,\n",
        "#         shuffle = False,\n",
        "#         seed = seed\n",
        "#     )\n",
        "    \n",
        "else:\n",
        "    train_gen = train_data_gen.flow_from_directory(\n",
        "        directory = training_dir,\n",
        "        target_size = (96,96),\n",
        "        color_mode = 'rgb',\n",
        "        classes = None,\n",
        "        class_mode = 'binary',\n",
        "        batch_size = batch_size,\n",
        "        shuffle = True,\n",
        "        seed = seed\n",
        "    )\n",
        "\n",
        "    val_gen = val_data_gen.flow_from_directory(\n",
        "        directory = validation_dir,\n",
        "        target_size = (96,96),\n",
        "        color_mode = 'rgb',\n",
        "        classes = None,\n",
        "        class_mode = 'binary',\n",
        "        batch_size = batch_size,\n",
        "        shuffle = False,\n",
        "        seed = seed\n",
        "    )\n",
        "\n",
        "    test_gen = test_data_gen.flow_from_directory(\n",
        "        directory = test_dir,\n",
        "        target_size = (96,96),\n",
        "        color_mode = 'rgb',\n",
        "        classes = None,\n",
        "        class_mode = 'binary',\n",
        "        batch_size = batch_size,\n",
        "        shuffle = False,\n",
        "        seed = seed\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s48CMlY5HvnI",
        "outputId": "dd502b1c-50e9-4e61-c1b1-9f6ff5fab150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data augmentation applied\n"
          ]
        }
      ],
      "source": [
        "if(data_augmentation):\n",
        "    train_gen = AugmentDataGenerator(train_gen, alb.Compose([\n",
        "        alb.HorizontalFlip(),\n",
        "        alb.VerticalFlip(),\n",
        "        alb.Transpose(),\n",
        "        alb.CoarseDropout(),\n",
        "        alb.RandomBrightnessContrast(),\n",
        "        alb.GaussNoise(),\n",
        "        alb.SafeRotate(limit=20),\n",
        "        alb.OneOf([\n",
        "            alb.GridDistortion(),\n",
        "            alb.OpticalDistortion()\n",
        "        ], p=0.3)\n",
        "    ]))\n",
        "    \n",
        "    print(\"Data augmentation applied\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2ZFGy0YOMmD"
      },
      "source": [
        "## Get some samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T20:04:14.675895Z",
          "iopub.status.busy": "2022-11-17T20:04:14.675262Z",
          "iopub.status.idle": "2022-11-17T20:04:14.680892Z",
          "shell.execute_reply": "2022-11-17T20:04:14.679616Z",
          "shell.execute_reply.started": "2022-11-17T20:04:14.675831Z"
        },
        "id": "etJWW6PVOMmD"
      },
      "outputs": [],
      "source": [
        "# def get_next_batch(generator):\n",
        "#   batch = next(generator)\n",
        "\n",
        "#   image = batch[0]\n",
        "#   target = batch[1]\n",
        "\n",
        "#   print(\"(Input) image shape:\", image.shape)\n",
        "#   print(\"Target shape:\",target.shape)\n",
        "\n",
        "#   # Visualize only the first sample\n",
        "#   image = image[0]\n",
        "#   target = target[0]\n",
        "#   target_idx = np.argmax(target)\n",
        "#   print()\n",
        "#   print(\"Categorical label:\", target)\n",
        "#   print(\"Label:\", target_idx)\n",
        "#   print(\"Class name:\", labels[target_idx])\n",
        "#   fig = plt.figure(figsize=(6, 4))\n",
        "#   plt.imshow(np.uint8(image))\n",
        "\n",
        "#   return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T19:00:51.973268Z",
          "iopub.status.busy": "2022-11-15T19:00:51.972887Z",
          "iopub.status.idle": "2022-11-15T19:00:51.993939Z",
          "shell.execute_reply": "2022-11-15T19:00:51.992817Z",
          "shell.execute_reply.started": "2022-11-15T19:00:51.973216Z"
        },
        "id": "KtmuURaJOMmD"
      },
      "outputs": [],
      "source": [
        "# # Get a sample from dataset and show info\n",
        "# _ = get_next_batch(train_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7jnjBD2u2tS"
      },
      "source": [
        "# Hyperparameters setting\n",
        "In this part, the hyperparameters of the model are defining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T20:04:40.827068Z",
          "iopub.status.busy": "2022-11-17T20:04:40.826666Z",
          "iopub.status.idle": "2022-11-17T20:04:40.832727Z",
          "shell.execute_reply": "2022-11-17T20:04:40.831569Z",
          "shell.execute_reply.started": "2022-11-17T20:04:40.827026Z"
        },
        "id": "tFigwY1Kx1eH"
      },
      "outputs": [],
      "source": [
        "# Fix input shape and number of epochs\n",
        "input_shape = (96, 96, 3)\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T20:04:44.627064Z",
          "iopub.status.busy": "2022-11-17T20:04:44.626642Z",
          "iopub.status.idle": "2022-11-17T20:04:44.639709Z",
          "shell.execute_reply": "2022-11-17T20:04:44.638838Z",
          "shell.execute_reply.started": "2022-11-17T20:04:44.627030Z"
        },
        "id": "5moa_FFb3xX8"
      },
      "outputs": [],
      "source": [
        "# Define loss\n",
        "loss = tfk.losses.BinaryCrossentropy()\n",
        "\n",
        "# Define learning rate\n",
        "lr = 3e-4\n",
        "\n",
        "# Define optimizer for regularization\n",
        "optimizer = tfk.optimizers.Adam(learning_rate = lr)\n",
        "\n",
        "# Define metrics for evaluation\n",
        "# metrics = [tf.keras.metrics.Precision()]\n",
        "metrics = ['accuracy']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0lT-umHqX8j"
      },
      "source": [
        "# Model structure\n",
        "According to the chosen mode, the corresponding model structure is loaded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4mFAHjcFIz8"
      },
      "source": [
        "## Basic CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T14:35:56.487931Z",
          "iopub.status.busy": "2022-11-15T14:35:56.487366Z",
          "iopub.status.idle": "2022-11-15T14:35:56.500853Z",
          "shell.execute_reply": "2022-11-15T14:35:56.499580Z",
          "shell.execute_reply.started": "2022-11-15T14:35:56.487877Z"
        },
        "id": "C48KSuCdCoMh"
      },
      "outputs": [],
      "source": [
        "# Use base CNN model\n",
        "if(mode == 'Baseline' or False):\n",
        "  model = tfk.Sequential()\n",
        "\n",
        "  # Input layer\n",
        "  model.add(tfkl.Input(shape=input_shape, name='Input'))\n",
        "\n",
        "  # Convolution + Pooling\n",
        "  model.add(tfkl.Conv2D(\n",
        "      filters=16,\n",
        "      kernel_size=(3, 3),\n",
        "      strides=(1, 1),\n",
        "      padding='same',\n",
        "      activation='relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))\n",
        "  model.add(tfkl.BatchNormalization())\n",
        "  model.add(tfkl.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(tfkl.Conv2D(\n",
        "      filters=32,\n",
        "      kernel_size=(3, 3),\n",
        "      strides=(1, 1),\n",
        "      padding='same',\n",
        "      activation='relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))\n",
        "  model.add(tfkl.BatchNormalization())\n",
        "  model.add(tfkl.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(tfkl.Conv2D(\n",
        "      filters=64,\n",
        "      kernel_size=(3, 3),\n",
        "      strides=(1, 1),\n",
        "      padding='same',\n",
        "      activation='relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))\n",
        "  model.add(tfkl.BatchNormalization())\n",
        "  model.add(tfkl.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # Global average pooling\n",
        "  model.add(tfkl.Flatten(name='Flatten'))\n",
        "\n",
        "  # Dropout layer\n",
        "  model.add(tfkl.Dropout(0.4, seed=seed))\n",
        "\n",
        "  # Linear layer with ReLU activation\n",
        "  model.add(tfkl.Dense(\n",
        "      units=64,\n",
        "      activation='relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))\n",
        "\n",
        "  # Dropout layer\n",
        "  model.add(tfkl.Dropout(0.4, seed=seed))\n",
        "\n",
        "  # Output layer\n",
        "  model.add(tfkl.Dense(\n",
        "      units=1,\n",
        "      activation='sigmoid',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "      name='Output'\n",
        "  ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T14:35:56.503010Z",
          "iopub.status.busy": "2022-11-15T14:35:56.502616Z",
          "iopub.status.idle": "2022-11-15T14:35:56.517013Z",
          "shell.execute_reply": "2022-11-15T14:35:56.515991Z",
          "shell.execute_reply.started": "2022-11-15T14:35:56.502973Z"
        },
        "id": "H0nhHpQTOMmF"
      },
      "outputs": [],
      "source": [
        "# Use base CNN model\n",
        "if(mode == 'Baseline'):\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(input_layer)\n",
        "    pool1 = tfkl.MaxPooling2D()(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool1)\n",
        "    pool2 = tfkl.MaxPooling2D()(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D()(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=256,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool3)\n",
        "    pool4 = tfkl.MaxPooling2D()(conv4)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=512,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D()(conv5)\n",
        "\n",
        "    flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    dropout = tfkl.Dropout(0.3, seed=seed)(flattening_layer)\n",
        "    classifier_layer = tfkl.Dense(units=512, name='Classifier', kernel_initializer=tfk.initializers.HeUniform(seed), activation='relu')(dropout)\n",
        "    dropout = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    output_layer = tfkl.Dense(units=1, activation='sigmoid', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='output_layer')(dropout)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqkwFZMrFC8A"
      },
      "source": [
        "## Supernet: MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T14:35:56.521959Z",
          "iopub.status.busy": "2022-11-15T14:35:56.521698Z",
          "iopub.status.idle": "2022-11-15T14:35:56.530468Z",
          "shell.execute_reply": "2022-11-15T14:35:56.529473Z",
          "shell.execute_reply.started": "2022-11-15T14:35:56.521934Z"
        },
        "id": "dsWBI1fIvOH6"
      },
      "outputs": [],
      "source": [
        "# Use MobileNetV2\n",
        "if(mode == 'Mobilenet'):\n",
        "  supernet = tfk.applications.MobileNetV2(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=input_shape)\n",
        "\n",
        "  model = tfk.Sequential()\n",
        "  model.add(supernet)\n",
        "\n",
        "  model.add(tfkl.AveragePooling2D(pool_size=(2, 2)))\n",
        "  model.add(tfkl.Flatten())\n",
        "\n",
        "  model.add(tfkl.Dense(\n",
        "      units=128,\n",
        "      activation='relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))\n",
        "  model.add(tfkl.Dropout(0.5, seed=seed))\n",
        "  model.add(tfkl.Dense(\n",
        "      units=1,\n",
        "      activation='sigmoid',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))\n",
        "#   model.add(tfkl.Flatten(name='FlattenOutput'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MExAxJIzZo-N"
      },
      "source": [
        "## Supernet: ResNet50V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T14:35:56.532827Z",
          "iopub.status.busy": "2022-11-15T14:35:56.531933Z",
          "iopub.status.idle": "2022-11-15T14:35:56.542718Z",
          "shell.execute_reply": "2022-11-15T14:35:56.541873Z",
          "shell.execute_reply.started": "2022-11-15T14:35:56.532789Z"
        },
        "id": "jpfsk-l1ZoOh"
      },
      "outputs": [],
      "source": [
        "# Use ResNet50V2\n",
        "if(mode == 'Resnet'):\n",
        "  supernet = tfk.applications.ResNet50V2(\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    input_shape = input_shape)\n",
        "\n",
        "  model = tfk.Sequential()\n",
        "  model.add(supernet)\n",
        "  model.add(tfkl.Flatten())\n",
        "  model.add(tfkl.Dropout(0.3, seed=seed))\n",
        "  model.add(tfkl.Dense(\n",
        "      units = 256,\n",
        "      activation = 'relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))\n",
        "  model.add(tfkl.Dropout(0.5, seed=seed))\n",
        "  model.add(tfkl.Dense(\n",
        "      units = 14,\n",
        "      activation = 'softmax',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFUCj7uYa0eS"
      },
      "source": [
        "## Supernet: VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T20:05:56.283122Z",
          "iopub.status.busy": "2022-11-17T20:05:56.282761Z",
          "iopub.status.idle": "2022-11-17T20:05:56.789265Z",
          "shell.execute_reply": "2022-11-17T20:05:56.788483Z",
          "shell.execute_reply.started": "2022-11-17T20:05:56.283093Z"
        },
        "id": "lcqRohtaay6s"
      },
      "outputs": [],
      "source": [
        "if(mode == 'VGG'):\n",
        "  supernet = tfk.applications.VGG19(\n",
        "    include_top = False,\n",
        "    weights = \"imagenet\",\n",
        "    input_shape = input_shape)\n",
        "  \n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(supernet)\n",
        "  model.add(tfkl.Flatten())\n",
        "  model.add(tfkl.Dropout(0.4, seed=seed))\n",
        "\n",
        "  model.add(tfkl.Dense(\n",
        "    units = 96,\n",
        "    activation = 'relu',\n",
        "    kernel_initializer = tfk.initializers.GlorotUniform(seed)))\n",
        "  \n",
        "  model.add(tfkl.Dropout(0.4, seed=seed))\n",
        "  \n",
        "  model.add(tfkl.Dense(\n",
        "    units = 1,\n",
        "    activation = 'sigmoid',\n",
        "    kernel_initializer = tfk.initializers.GlorotUniform(seed)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caYlR35qFREK"
      },
      "source": [
        "## Supernet: EfficientNetB7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T14:35:56.985952Z",
          "iopub.status.busy": "2022-11-15T14:35:56.985606Z",
          "iopub.status.idle": "2022-11-15T14:35:56.993143Z",
          "shell.execute_reply": "2022-11-15T14:35:56.992028Z",
          "shell.execute_reply.started": "2022-11-15T14:35:56.985914Z"
        },
        "id": "GTigcmX5kPfj"
      },
      "outputs": [],
      "source": [
        "# Use EfficientNetB7\n",
        "if(mode == 'Efficientnet'):\n",
        "  supernet = tf.keras.applications.EfficientNetB7(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=input_shape)\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(supernet)\n",
        "  model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "  model.add(tfkl.Dense(\n",
        "      units=128,\n",
        "      activation='relu',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))\n",
        "  model.add(tfkl.Dropout(0.5, seed=seed))\n",
        "  model.add(tfkl.Dense(\n",
        "      units=14,\n",
        "      activation='softmax',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "  ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDzNuoKEOMmG"
      },
      "source": [
        "## Transfer learning setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T20:06:06.404075Z",
          "iopub.status.busy": "2022-11-17T20:06:06.403467Z",
          "iopub.status.idle": "2022-11-17T20:06:06.411112Z",
          "shell.execute_reply": "2022-11-17T20:06:06.409464Z",
          "shell.execute_reply.started": "2022-11-17T20:06:06.404016Z"
        },
        "id": "fc0_XL7MbRUa"
      },
      "outputs": [],
      "source": [
        "# Freeze the supernet if it is in transfer learning mode\n",
        "if(transfer_learning):\n",
        "    supernet.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDPUj0TwR0rW"
      },
      "source": [
        "## Model summary and compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-17T20:06:08.866918Z",
          "iopub.status.busy": "2022-11-17T20:06:08.866487Z",
          "iopub.status.idle": "2022-11-17T20:06:08.875168Z",
          "shell.execute_reply": "2022-11-17T20:06:08.873530Z",
          "shell.execute_reply.started": "2022-11-17T20:06:08.866878Z"
        },
        "id": "Mn70Fj1Kvuax",
        "outputId": "6a6b614b-9857-4cae-f269-62e90100d226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 3, 3, 512)         20024384  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                442464    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 97        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,466,945\n",
            "Trainable params: 442,561\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Show model structure\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T20:06:11.457767Z",
          "iopub.status.busy": "2022-11-17T20:06:11.457370Z",
          "iopub.status.idle": "2022-11-17T20:06:11.474392Z",
          "shell.execute_reply": "2022-11-17T20:06:11.473041Z",
          "shell.execute_reply.started": "2022-11-17T20:06:11.457735Z"
        },
        "id": "IcLW6Rnz3U8a"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4dDAxvsXLPY"
      },
      "source": [
        "# Fine Tuning\n",
        "If transfer learning was done, we can improve the performance by unfreezing some layers of the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T14:36:18.519777Z",
          "iopub.status.busy": "2022-11-15T14:36:18.519404Z",
          "iopub.status.idle": "2022-11-15T14:36:18.524575Z",
          "shell.execute_reply": "2022-11-15T14:36:18.523533Z",
          "shell.execute_reply.started": "2022-11-15T14:36:18.519743Z"
        },
        "id": "tdKwpTtMXhva"
      },
      "outputs": [],
      "source": [
        "# Load and show the transfer learning model\n",
        "# model = tfk.models.load_model('TLModel')\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-15T14:36:18.751002Z",
          "iopub.status.busy": "2022-11-15T14:36:18.750710Z",
          "iopub.status.idle": "2022-11-15T14:36:18.755442Z",
          "shell.execute_reply": "2022-11-15T14:36:18.754370Z",
          "shell.execute_reply.started": "2022-11-15T14:36:18.750975Z"
        },
        "id": "Dxsh7Hk7Xr4f",
        "outputId": "a7f4c35e-6f3c-405d-f2f0-fa3eccbf4155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 False\n",
            "1 block1_conv1 False\n",
            "2 block1_conv2 False\n",
            "3 block1_pool False\n",
            "4 block2_conv1 False\n",
            "5 block2_conv2 False\n",
            "6 block2_pool False\n",
            "7 block3_conv1 False\n",
            "8 block3_conv2 False\n",
            "9 block3_conv3 False\n",
            "10 block3_conv4 False\n",
            "11 block3_pool False\n",
            "12 block4_conv1 False\n",
            "13 block4_conv2 False\n",
            "14 block4_conv3 False\n",
            "15 block4_conv4 True\n",
            "16 block4_pool True\n",
            "17 block5_conv1 True\n",
            "18 block5_conv2 True\n",
            "19 block5_conv3 True\n",
            "20 block5_conv4 True\n",
            "21 block5_pool True\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 3, 3, 512)         20024384  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                442464    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 97        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,466,945\n",
            "Trainable params: 442,561\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Unfreeze some layers and show the result\n",
        "for i, layer in enumerate(model.get_layer('vgg19').layers[15:]):\n",
        "  layer.trainable = True\n",
        "\n",
        "for i, layer in enumerate(model.get_layer('vgg19').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T14:36:19.557858Z",
          "iopub.status.busy": "2022-11-15T14:36:19.557139Z",
          "iopub.status.idle": "2022-11-15T14:36:19.576727Z",
          "shell.execute_reply": "2022-11-15T14:36:19.575578Z",
          "shell.execute_reply.started": "2022-11-15T14:36:19.557820Z"
        },
        "id": "qBqXmHw6YCbA"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok9qde99qbhC"
      },
      "source": [
        "# Checkpoint and Early stopping settings\n",
        "Early stopping options can be activated to limit model overfitting.\n",
        "\n",
        "There is possibility to save checkpoints during the training, in order to keep track of the performance and to get more choices of the final model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3tzme4mOMmH"
      },
      "source": [
        "## Custom callback function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T19:04:54.519047Z",
          "iopub.status.busy": "2022-11-15T19:04:54.518669Z",
          "iopub.status.idle": "2022-11-15T19:04:54.526563Z",
          "shell.execute_reply": "2022-11-15T19:04:54.525438Z",
          "shell.execute_reply.started": "2022-11-15T19:04:54.519017Z"
        },
        "id": "JL9axzCaOMmI"
      },
      "outputs": [],
      "source": [
        "class UnfreezeCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, optimizer, loss, metrics, n_epochs=0, layer=''):\n",
        "        super().__init__()\n",
        "        self.n_epochs = n_epochs\n",
        "        self.layer = layer\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "        self.metrics = metrics\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch == self.n_epochs:\n",
        "            self.model.get_layer(self.layer).trainable = True\n",
        "            for i, layer in enumerate(model.get_layer(self.layer).layers[:10]):\n",
        "                layer.trainable = True\n",
        "            self.model.compile(\n",
        "                optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=self.metrics\n",
        "            )\n",
        "            print(\"Unfreezed all layers at epoch {}\".format(epoch))\n",
        "            for i, layer in enumerate(model.get_layer(self.layer).layers):\n",
        "                print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-17T20:06:35.728752Z",
          "iopub.status.busy": "2022-11-17T20:06:35.728199Z",
          "iopub.status.idle": "2022-11-17T20:06:35.745784Z",
          "shell.execute_reply": "2022-11-17T20:06:35.744714Z",
          "shell.execute_reply.started": "2022-11-17T20:06:35.728714Z"
        },
        "id": "cWGfO5V5EB5F"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# %cd /kaggle/working\n",
        "\n",
        "# Utility function to create folders and callbacks for training\n",
        "def create_folders_and_callbacks(model_name):\n",
        "    exps_dir = os.path.join('experiments')\n",
        "    if not os.path.exists(exps_dir):\n",
        "        os.makedirs(exps_dir)\n",
        "\n",
        "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "    print(str(now))\n",
        "\n",
        "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "    if not os.path.exists(exp_dir):\n",
        "        os.makedirs(exp_dir)\n",
        "      \n",
        "    callbacks = []\n",
        "\n",
        "    # Model checkpoint\n",
        "    ckpt_dir = os.path.join(exp_dir, 'base_ckpts')\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        os.makedirs(ckpt_dir)\n",
        "\n",
        "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
        "                                                     save_weights_only=False, # True to save only weights\n",
        "                                                     save_best_only=True) # True to save only the best epoch \n",
        "    callbacks.append(ckpt_callback)\n",
        "\n",
        "    # Visualize Learning on Tensorboard\n",
        "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "    if not os.path.exists(tb_dir):\n",
        "        os.makedirs(tb_dir)\n",
        "      \n",
        "#     # By default shows losses and metrics for both training and validation\n",
        "#     tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
        "#                                                profile_batch=0,\n",
        "#                                                histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
        "#     callbacks.append(tb_callback)\n",
        "\n",
        "    # Early Stopping\n",
        "\n",
        "    # # Monitoring parameter: validation loss\n",
        "    # monitor = 'val_loss'\n",
        "  \n",
        "    # # Number of epochs after that the training stops, if there are no improvements\n",
        "    # patience = 20\n",
        "\n",
        "    # es_callback = tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=patience, restore_best_weights=True)\n",
        "    # callbacks.append(es_callback)\n",
        "\n",
        "#     # Unfreeze layers\n",
        "    # uf_callback = UnfreezeCallback(n_epochs=10, layer='vgg19', optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "    # callbacks.append(uf_callback)\n",
        "\n",
        "    return callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5csUQfVqhx2"
      },
      "source": [
        "# Model fitting\n",
        "The chosen model is fit on the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-17T20:06:38.937778Z",
          "iopub.status.busy": "2022-11-17T20:06:38.936938Z",
          "iopub.status.idle": "2022-11-17T20:06:38.944185Z",
          "shell.execute_reply": "2022-11-17T20:06:38.943360Z",
          "shell.execute_reply.started": "2022-11-17T20:06:38.937704Z"
        },
        "id": "MAeK-cKwSeUI",
        "outputId": "48a796d6-a117-4043-b18b-6ae19a8cb3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nov18_20-45-18\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<keras.callbacks.ModelCheckpoint at 0x2406d584760>]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "callbacks = create_folders_and_callbacks(model_name = mode)\n",
        "callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T19:08:10.162941Z",
          "iopub.status.busy": "2022-11-15T19:08:10.162585Z",
          "iopub.status.idle": "2022-11-15T19:08:10.167641Z",
          "shell.execute_reply": "2022-11-15T19:08:10.166587Z",
          "shell.execute_reply.started": "2022-11-15T19:08:10.162911Z"
        },
        "id": "CVFp-ml8OMmI"
      },
      "outputs": [],
      "source": [
        "class_weight = {0: 1.,\n",
        "                1: 18.\n",
        "               }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "execution": {
          "iopub.execute_input": "2022-11-15T19:08:10.282354Z",
          "iopub.status.busy": "2022-11-15T19:08:10.282039Z",
          "iopub.status.idle": "2022-11-15T19:08:10.288501Z",
          "shell.execute_reply": "2022-11-15T19:08:10.287574Z",
          "shell.execute_reply.started": "2022-11-15T19:08:10.282326Z"
        },
        "id": "6GYFH8qDOMmI",
        "outputId": "af8b0953-9fbf-445d-d633-3f56c095f02d"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NumpyArrayIterator' object has no attribute 'class_indices'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mval_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_indices\u001b[49m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NumpyArrayIterator' object has no attribute 'class_indices'"
          ]
        }
      ],
      "source": [
        "val_gen.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-17T20:07:36.948499Z",
          "iopub.status.busy": "2022-11-17T20:07:36.948114Z",
          "iopub.status.idle": "2022-11-17T20:08:05.368136Z",
          "shell.execute_reply": "2022-11-17T20:08:05.366226Z",
          "shell.execute_reply.started": "2022-11-17T20:07:36.948470Z"
        },
        "id": "cAZYPolE4RNE",
        "outputId": "65f24407-9c7f-490e-dd4a-1974e8313037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.8110 - accuracy: 0.4873"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_01.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_01.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 9s 2s/step - loss: 1.8110 - accuracy: 0.4873 - val_loss: 1.4091 - val_accuracy: 0.5500\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.2260 - accuracy: 0.5169"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_02.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_02.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 1.2260 - accuracy: 0.5169 - val_loss: 1.2931 - val_accuracy: 0.5833\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 1.1802 - accuracy: 0.5636 - val_loss: 1.3621 - val_accuracy: 0.6167\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 1.2455 - accuracy: 0.5127 - val_loss: 1.3523 - val_accuracy: 0.6000\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 1.1555 - accuracy: 0.5466 - val_loss: 1.3762 - val_accuracy: 0.6000\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 1.0488 - accuracy: 0.5339 - val_loss: 1.4129 - val_accuracy: 0.6167\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 1.2859 - accuracy: 0.5254 - val_loss: 1.4174 - val_accuracy: 0.6167\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.9938 - accuracy: 0.5636 - val_loss: 1.3140 - val_accuracy: 0.5833\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9017 - accuracy: 0.5847"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_09.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_09.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 1s/step - loss: 0.9017 - accuracy: 0.5847 - val_loss: 1.2818 - val_accuracy: 0.6667\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.1790 - accuracy: 0.5678"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_10.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_10.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 1.1790 - accuracy: 0.5678 - val_loss: 1.2367 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.9401 - accuracy: 0.5833"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_11.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_11.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 1.0386 - accuracy: 0.5678 - val_loss: 1.1813 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0011 - accuracy: 0.6102"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_12.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_12.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 1.0011 - accuracy: 0.6102 - val_loss: 1.1392 - val_accuracy: 0.6667\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8447 - accuracy: 0.6144"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_13.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_13.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8447 - accuracy: 0.6144 - val_loss: 1.1157 - val_accuracy: 0.6833\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 1.0120 - accuracy: 0.5593"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_14.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_14.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 1.0120 - accuracy: 0.5593 - val_loss: 1.0596 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.9549 - accuracy: 0.6198"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_15.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_15.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 1.0070 - accuracy: 0.6271 - val_loss: 1.0021 - val_accuracy: 0.6500\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9526 - accuracy: 0.6102"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_16.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_16.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.9526 - accuracy: 0.6102 - val_loss: 0.9948 - val_accuracy: 0.6333\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8889 - accuracy: 0.5381"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_17.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_17.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8889 - accuracy: 0.5381 - val_loss: 0.9870 - val_accuracy: 0.6167\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8893 - accuracy: 0.6102"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_18.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_18.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8893 - accuracy: 0.6102 - val_loss: 0.9836 - val_accuracy: 0.6333\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9257 - accuracy: 0.5975"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_19.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_19.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.9257 - accuracy: 0.5975 - val_loss: 0.9816 - val_accuracy: 0.6333\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8393 - accuracy: 0.5763"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_20.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_20.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8393 - accuracy: 0.5763 - val_loss: 0.9604 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.8251 - accuracy: 0.5930"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_21.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_21.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.9047 - accuracy: 0.5847 - val_loss: 0.9551 - val_accuracy: 0.6833\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8050 - accuracy: 0.6017"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_22.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_22.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8050 - accuracy: 0.6017 - val_loss: 0.9406 - val_accuracy: 0.6667\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.9730 - accuracy: 0.6102"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_23.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_23.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.9730 - accuracy: 0.6102 - val_loss: 0.9288 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.7247 - accuracy: 0.6525 - val_loss: 0.9291 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7086 - accuracy: 0.6102"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_25.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_25.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 1s/step - loss: 0.7086 - accuracy: 0.6102 - val_loss: 0.9147 - val_accuracy: 0.6833\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7204 - accuracy: 0.6441"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_26.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_26.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7204 - accuracy: 0.6441 - val_loss: 0.9034 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.7325 - accuracy: 0.6354"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_27.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_27.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7811 - accuracy: 0.6229 - val_loss: 0.8935 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.7529 - accuracy: 0.6562"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_28.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_28.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8430 - accuracy: 0.6398 - val_loss: 0.8895 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8371 - accuracy: 0.5932"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_29.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_29.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8371 - accuracy: 0.5932 - val_loss: 0.8843 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5921 - accuracy: 0.6615"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_30.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_30.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6042 - accuracy: 0.6356 - val_loss: 0.8733 - val_accuracy: 0.7167\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8912 - accuracy: 0.6059"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_31.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_31.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8912 - accuracy: 0.6059 - val_loss: 0.8476 - val_accuracy: 0.7167\n",
            "Epoch 32/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.6381 - accuracy: 0.6395"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_32.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_32.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6982 - accuracy: 0.6186 - val_loss: 0.8401 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.7874 - accuracy: 0.5847 - val_loss: 0.8513 - val_accuracy: 0.6833\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8207 - accuracy: 0.5975"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_34.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_34.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 1s/step - loss: 0.8207 - accuracy: 0.5975 - val_loss: 0.8258 - val_accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8173 - accuracy: 0.6102"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_35.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_35.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8173 - accuracy: 0.6102 - val_loss: 0.8159 - val_accuracy: 0.6833\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.8129 - accuracy: 0.6102"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_36.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_36.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.8129 - accuracy: 0.6102 - val_loss: 0.8135 - val_accuracy: 0.6833\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7713 - accuracy: 0.5763"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_37.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_37.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7713 - accuracy: 0.5763 - val_loss: 0.8064 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.8335 - accuracy: 0.6144 - val_loss: 0.8079 - val_accuracy: 0.6500\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.7573 - accuracy: 0.6017 - val_loss: 0.8089 - val_accuracy: 0.6167\n",
            "Epoch 40/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.8105 - accuracy: 0.5260"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_40.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_40.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7828 - accuracy: 0.5593 - val_loss: 0.8061 - val_accuracy: 0.6167\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7617 - accuracy: 0.6144"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_41.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_41.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7617 - accuracy: 0.6144 - val_loss: 0.7850 - val_accuracy: 0.6333\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7951 - accuracy: 0.6017"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_42.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_42.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7951 - accuracy: 0.6017 - val_loss: 0.7292 - val_accuracy: 0.6500\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7393 - accuracy: 0.6271"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_43.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_43.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7393 - accuracy: 0.6271 - val_loss: 0.7224 - val_accuracy: 0.6500\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.6314"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_44.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_44.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6579 - accuracy: 0.6314 - val_loss: 0.6996 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7080 - accuracy: 0.5805"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_45.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_45.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7080 - accuracy: 0.5805 - val_loss: 0.6965 - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 96ms/step - loss: 0.6070 - accuracy: 0.6568 - val_loss: 0.7198 - val_accuracy: 0.6833\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.6576 - accuracy: 0.6186 - val_loss: 0.7612 - val_accuracy: 0.6167\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.5900 - accuracy: 0.6610 - val_loss: 0.8018 - val_accuracy: 0.6333\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.7299 - accuracy: 0.5890 - val_loss: 0.7855 - val_accuracy: 0.6167\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.7389 - accuracy: 0.6314 - val_loss: 0.7413 - val_accuracy: 0.6167\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.7177 - accuracy: 0.6398 - val_loss: 0.7142 - val_accuracy: 0.6333\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.6483"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_52.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_52.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6361 - accuracy: 0.6483 - val_loss: 0.6943 - val_accuracy: 0.6333\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.5975"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_53.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_53.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7438 - accuracy: 0.5975 - val_loss: 0.6767 - val_accuracy: 0.6667\n",
            "Epoch 54/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.6391 - accuracy: 0.6667"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_54.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_54.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6671 - accuracy: 0.6356 - val_loss: 0.6575 - val_accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.6568"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_55.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_55.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7082 - accuracy: 0.6568 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.6653"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_56.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_56.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6422 - accuracy: 0.6653 - val_loss: 0.6235 - val_accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 92ms/step - loss: 0.6473 - accuracy: 0.6653 - val_loss: 0.6243 - val_accuracy: 0.6333\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.6579 - accuracy: 0.6568 - val_loss: 0.6301 - val_accuracy: 0.6500\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.7543 - accuracy: 0.6144 - val_loss: 0.6432 - val_accuracy: 0.6500\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.6992 - accuracy: 0.6271 - val_loss: 0.6523 - val_accuracy: 0.6333\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.6892 - accuracy: 0.5890 - val_loss: 0.6645 - val_accuracy: 0.6333\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.7056 - accuracy: 0.6314 - val_loss: 0.6568 - val_accuracy: 0.6333\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.6665 - accuracy: 0.6059 - val_loss: 0.6305 - val_accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.6271"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_64.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_64.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 1s/step - loss: 0.6964 - accuracy: 0.6271 - val_loss: 0.6093 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.6398"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_65.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_65.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.7203 - accuracy: 0.6398 - val_loss: 0.6074 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 92ms/step - loss: 0.6820 - accuracy: 0.6186 - val_loss: 0.6183 - val_accuracy: 0.6500\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.6620 - accuracy: 0.6737 - val_loss: 0.6282 - val_accuracy: 0.6167\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.6046 - accuracy: 0.6441 - val_loss: 0.6337 - val_accuracy: 0.6333\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.6398 - accuracy: 0.6186 - val_loss: 0.6443 - val_accuracy: 0.6333\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.6290 - accuracy: 0.6314 - val_loss: 0.6575 - val_accuracy: 0.6500\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 0.7189 - accuracy: 0.6314 - val_loss: 0.6550 - val_accuracy: 0.6500\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.6361 - accuracy: 0.6907 - val_loss: 0.6586 - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 0.7053 - accuracy: 0.6483 - val_loss: 0.6765 - val_accuracy: 0.6333\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.7373 - accuracy: 0.5890 - val_loss: 0.6759 - val_accuracy: 0.6500\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.6555 - accuracy: 0.6186 - val_loss: 0.6769 - val_accuracy: 0.6500\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.7776 - accuracy: 0.6356 - val_loss: 0.6578 - val_accuracy: 0.6333\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.7067 - accuracy: 0.5551 - val_loss: 0.6443 - val_accuracy: 0.6167\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.6587 - accuracy: 0.6271 - val_loss: 0.6348 - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.5892 - accuracy: 0.6568 - val_loss: 0.6323 - val_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.6582 - accuracy: 0.5932 - val_loss: 0.6294 - val_accuracy: 0.6667\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.6317 - accuracy: 0.6864 - val_loss: 0.6255 - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.5993 - accuracy: 0.6695 - val_loss: 0.6245 - val_accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.6415 - accuracy: 0.6568 - val_loss: 0.6221 - val_accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.6897 - accuracy: 0.6186 - val_loss: 0.6249 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.5549 - accuracy: 0.6610 - val_loss: 0.6235 - val_accuracy: 0.7167\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.6198 - accuracy: 0.6314 - val_loss: 0.6245 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.5874 - accuracy: 0.6907 - val_loss: 0.6230 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.6456 - accuracy: 0.6695 - val_loss: 0.6160 - val_accuracy: 0.7167\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.6551 - accuracy: 0.6271 - val_loss: 0.6152 - val_accuracy: 0.7333\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 101ms/step - loss: 0.6662 - accuracy: 0.6441 - val_loss: 0.6145 - val_accuracy: 0.7333\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.6125 - accuracy: 0.6610 - val_loss: 0.6139 - val_accuracy: 0.7333\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.6214 - accuracy: 0.6525 - val_loss: 0.6124 - val_accuracy: 0.7167\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.6497 - accuracy: 0.6314 - val_loss: 0.6080 - val_accuracy: 0.7167\n",
            "Epoch 94/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.6172 - accuracy: 0.6667"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_94.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_94.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 1s/step - loss: 0.6334 - accuracy: 0.6653 - val_loss: 0.6024 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.6441"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_95.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_95.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6268 - accuracy: 0.6441 - val_loss: 0.6009 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5921 - accuracy: 0.6395"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_96.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_96.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6192 - accuracy: 0.6059 - val_loss: 0.6008 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6218 - accuracy: 0.6780"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_97.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_97.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6218 - accuracy: 0.6780 - val_loss: 0.5982 - val_accuracy: 0.7167\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6279 - accuracy: 0.6483"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_98.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_98.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6279 - accuracy: 0.6483 - val_loss: 0.5978 - val_accuracy: 0.7333\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.6568"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_99.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_99.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 1s/step - loss: 0.6207 - accuracy: 0.6568 - val_loss: 0.5943 - val_accuracy: 0.7167\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6167 - accuracy: 0.6441"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_100.ckpt\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: experiments\\VGG_Nov18_20-45-18\\base_ckpts\\cp_100.ckpt\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
            "4/4 [==============================] - 4s 1s/step - loss: 0.6167 - accuracy: 0.6441 - val_loss: 0.5940 - val_accuracy: 0.7333\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x = train_gen,\n",
        "    epochs = 100,\n",
        "    validation_data = val_gen,\n",
        "    callbacks = callbacks\n",
        "#     class_weight=class_weight\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T19:10:28.042939Z",
          "iopub.status.busy": "2022-11-15T19:10:28.042582Z",
          "iopub.status.idle": "2022-11-15T19:10:28.048802Z",
          "shell.execute_reply": "2022-11-15T19:10:28.047630Z",
          "shell.execute_reply.started": "2022-11-15T19:10:28.042909Z"
        },
        "id": "liuoATAmrUOK"
      },
      "outputs": [],
      "source": [
        "f=open(\"/gdrive/MyDrive/Colab Notebooks/AN2DL/Homework1/experiments/VGG_Nov17_21-14-22/history\",\"w\")\n",
        "f.write(str(history))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um4Ebl0aqiYa"
      },
      "source": [
        "# Trend plot\n",
        "Model loss and accuracy trends can be plotted for a better understanding of the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMTI1OpUGDBK"
      },
      "source": [
        "## Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T19:10:34.501817Z",
          "iopub.status.busy": "2022-11-15T19:10:34.501418Z",
          "iopub.status.idle": "2022-11-15T19:10:34.506841Z",
          "shell.execute_reply": "2022-11-15T19:10:34.505824Z",
          "shell.execute_reply.started": "2022-11-15T19:10:34.501783Z"
        },
        "id": "V75c5PjD0b6e"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "execution": {
          "iopub.execute_input": "2022-11-15T19:10:34.869862Z",
          "iopub.status.busy": "2022-11-15T19:10:34.869373Z",
          "iopub.status.idle": "2022-11-15T19:11:03.832497Z",
          "shell.execute_reply": "2022-11-15T19:11:03.831585Z",
          "shell.execute_reply.started": "2022-11-15T19:10:34.869830Z"
        },
        "id": "uKzFy9BmJ1oc",
        "outputId": "5b0eb536-9ba8-424a-e793-e7953966d062"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the accuracy\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(history['loss'], label='Training', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\n",
        "plt.title(mode + ' Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-15T19:11:03.835474Z",
          "iopub.status.busy": "2022-11-15T19:11:03.834755Z",
          "iopub.status.idle": "2022-11-15T19:11:03.841891Z",
          "shell.execute_reply": "2022-11-15T19:11:03.840816Z",
          "shell.execute_reply.started": "2022-11-15T19:11:03.835423Z"
        },
        "id": "2pzPIfV5OMmJ",
        "outputId": "6394a83a-431b-494e-8451-a9b18ba9f91c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "execution": {
          "iopub.execute_input": "2022-11-15T19:11:03.844109Z",
          "iopub.status.busy": "2022-11-15T19:11:03.843672Z",
          "iopub.status.idle": "2022-11-15T19:11:04.068555Z",
          "shell.execute_reply": "2022-11-15T19:11:04.067113Z",
          "shell.execute_reply.started": "2022-11-15T19:11:03.844066Z"
        },
        "id": "Q1T2m3MhJ1H9",
        "outputId": "5bd084e5-044c-44c6-d3fe-f6607ca9111b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(history['accuracy'], label='Training', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\n",
        "plt.title(mode + ' Accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klvPMoR2F-JJ"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngBGK7jMGOSp"
      },
      "outputs": [],
      "source": [
        "%cd /gdrive/MyDrive/Colab Notebooks/AN2DL/Homework1\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir results\n",
        "# logdir: directory of the experiments\n",
        "# --logdir ... --port 6006: default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIkjM67YNay_"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-16T17:51:32.442043Z",
          "iopub.status.busy": "2022-11-16T17:51:32.441539Z",
          "iopub.status.idle": "2022-11-16T17:51:35.895617Z",
          "shell.execute_reply": "2022-11-16T17:51:35.894444Z",
          "shell.execute_reply.started": "2022-11-16T17:51:32.442004Z"
        },
        "id": "VuIl-h8SNaf4"
      },
      "outputs": [],
      "source": [
        "# Load a chosen model\n",
        "# model = tfk.models.load_model(\"/kaggle/working/experiments/VGG_\"+\"Nov15_19-08-09\"+\"/base_ckpts/cp_13.ckpt\",)\n",
        "model = tfk.models.load_model(\"/gdrive/MyDrive/Colab Notebooks/AN2DL/Homework1/experiments/VGG_Nov17_21-14-22/base_ckpts/cp_78.ckpt\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T21:43:17.435417Z",
          "iopub.status.busy": "2022-11-15T21:43:17.434987Z",
          "iopub.status.idle": "2022-11-15T21:43:17.448136Z",
          "shell.execute_reply": "2022-11-15T21:43:17.447002Z",
          "shell.execute_reply.started": "2022-11-15T21:43:17.435381Z"
        },
        "id": "9KajQvAKPyjR"
      },
      "outputs": [],
      "source": [
        "def predict(model, X):\n",
        "    # # X = tf.image.resize(X, (256, 256))\n",
        "    # image_array = np.reshape(X, (1, 256, 256, 3))\n",
        "    # # image_array = tf.keras.preprocessing.image.img_to_array(image_array)\n",
        "    #\n",
        "    # out = loaded_model.predict(x=image_array / 255.)\n",
        "    # # out = loaded_model.predict(image_array)\n",
        "    #\n",
        "    # out = tf.argmax(out, axis=-1)\n",
        "    #\n",
        "    # return out\n",
        "\n",
        "    # Insert your preprocessing here\n",
        "\n",
        "    X = np.reshape(X, (1, 96, 96, 3))\n",
        "    assert X.ndim == 4\n",
        "\n",
        "    # X = tf.keras.applications.efficientnet.preprocess_input(X)\n",
        "    X = X / 255.\n",
        "    # predicts = []\n",
        "    # fs = [tf.image.flip_left_right, tf.image.flip_up_down, tf.image.transpose]\n",
        "    # for f in fs:\n",
        "    #     data = f(X)\n",
        "    #     pred = model.predict(data)\n",
        "    #     predicts.append(pred)\n",
        "    # prediction = model.predict(X)\n",
        "    # for j in range(0, len(predicts)):\n",
        "    #     prediction += predicts[j]\n",
        "    # prediction = prediction / (1 + len(predicts))\n",
        "\n",
        "    prediction = model.predict(X)\n",
        "    output = tf.argmax(prediction, axis=-1)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T21:47:13.564639Z",
          "iopub.status.busy": "2022-11-15T21:47:13.564163Z",
          "iopub.status.idle": "2022-11-15T21:47:13.646052Z",
          "shell.execute_reply": "2022-11-15T21:47:13.644988Z",
          "shell.execute_reply.started": "2022-11-15T21:47:13.564587Z"
        },
        "id": "ZUDL69WDOMmL",
        "outputId": "c7a84f3e-0353-461f-fe45-05892efac845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([1])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = predict(model, imgs_x[0])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-14T21:48:32.802190Z",
          "iopub.status.busy": "2022-11-14T21:48:32.801817Z",
          "iopub.status.idle": "2022-11-14T21:48:32.808493Z",
          "shell.execute_reply": "2022-11-14T21:48:32.807442Z",
          "shell.execute_reply.started": "2022-11-14T21:48:32.802158Z"
        },
        "id": "UdxvEKZmCj1C",
        "outputId": "4b3a8871-0da2-4fe7-dca6-a2946ec2c338"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Others': 0, 'Species1': 1}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_gen.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-15T19:13:22.888192Z",
          "iopub.status.busy": "2022-11-15T19:13:22.887162Z",
          "iopub.status.idle": "2022-11-15T19:13:28.327779Z",
          "shell.execute_reply": "2022-11-15T19:13:28.326643Z",
          "shell.execute_reply.started": "2022-11-15T19:13:22.888156Z"
        },
        "id": "cRodfJu0OmU1",
        "outputId": "f2290398-f9bb-42c0-e92a-a06087656678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 32ms/step - loss: 0.4281 - accuracy: 0.8133\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.4281134009361267, 0.8133333325386047]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluation = model.evaluate(val_gen)\n",
        "evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T19:20:31.939288Z",
          "iopub.status.busy": "2022-11-15T19:20:31.938839Z",
          "iopub.status.idle": "2022-11-15T19:20:37.933726Z",
          "shell.execute_reply": "2022-11-15T19:20:37.932479Z",
          "shell.execute_reply.started": "2022-11-15T19:20:31.939231Z"
        },
        "id": "IjG78Da3OMmL",
        "outputId": "df59fb84-ccdb-4042-9a94-d727409567dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 5s 42ms/step - loss: 0.3416 - accuracy: 0.9472\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3416038453578949, 0.9472049474716187]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluation = model.evaluate(imgs_x, imgs_y)\n",
        "evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T20:39:08.171108Z",
          "iopub.status.busy": "2022-11-15T20:39:08.170712Z",
          "iopub.status.idle": "2022-11-15T20:39:08.178996Z",
          "shell.execute_reply": "2022-11-15T20:39:08.177792Z",
          "shell.execute_reply.started": "2022-11-15T20:39:08.171072Z"
        },
        "id": "WODcX3U0OMmL",
        "outputId": "d3ab35fa-99e6-4adc-e519-7d5a83f13ee9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(96, 96, 3)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_imgs_x[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-16T18:02:21.997602Z",
          "iopub.status.busy": "2022-11-16T18:02:21.997207Z",
          "iopub.status.idle": "2022-11-16T18:02:22.660984Z",
          "shell.execute_reply": "2022-11-16T18:02:22.659886Z",
          "shell.execute_reply.started": "2022-11-16T18:02:21.997572Z"
        },
        "id": "LUU6Foa2Lhi6",
        "outputId": "62fc9d8f-a284-496f-f6db-1f50a2778882"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 1])>"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.reshape(imgs_x, (-1, 96, 96, 3))\n",
        "# predictions = model.predict(train_gen)\n",
        "# output = tf.argmax(predictions, axis=-1)\n",
        "# output = tf.argmax(predictions, axis=-1)\n",
        "a = np.array([[0,0.1,0.2,0.3],[0.8,0.6,0.7,0.5]])\n",
        "output = tf.argmax(a[:,1:], axis=-1)\n",
        "# predictions[predictions>0.99] = 1\n",
        "# predictions[predictions<=0.99] = 0\n",
        "# predictions = np.array(predictions.T[0], dtype=int)\n",
        "# predictions\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEEf2ulxfFbV",
        "outputId": "aa05261a-2f1f-4e37-e9cb-510c0a7fbc80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0])"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_gen.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga6wm8rcgYgR",
        "outputId": "b0394af0-8e7d-4fb4-818a-9e63c9703480"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([False,  True,  True, False,  True,  True, False,  True,  True,\n",
              "        True, False, False, False,  True,  True, False,  True,  True,\n",
              "       False, False, False,  True,  True, False,  True, False, False,\n",
              "       False, False,  True, False, False, False, False, False, False,\n",
              "        True, False,  True, False,  True,  True,  True, False,  True,\n",
              "       False, False, False,  True,  True,  True,  True,  True, False,\n",
              "        True, False,  True,  True,  True,  True,  True, False, False,\n",
              "        True, False,  True,  True,  True, False, False, False, False,\n",
              "       False,  True, False,  True,  True, False,  True,  True, False,\n",
              "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
              "       False, False,  True,  True,  True, False,  True, False,  True,\n",
              "       False,  True, False, False, False, False, False,  True,  True,\n",
              "       False, False,  True, False,  True,  True, False, False,  True,\n",
              "       False, False, False, False,  True, False,  True,  True, False,\n",
              "       False, False,  True, False,  True, False, False,  True,  True,\n",
              "       False, False, False,  True,  True, False,  True,  True, False,\n",
              "        True, False, False,  True,  True, False,  True, False,  True,\n",
              "       False,  True, False,  True,  True,  True,  True,  True, False,\n",
              "        True, False, False,  True, False, False,  True, False,  True,\n",
              "       False, False,  True, False,  True, False,  True,  True,  True,\n",
              "       False, False, False, False, False, False, False,  True, False,\n",
              "       False, False,  True,  True, False,  True,  True,  True, False,\n",
              "       False, False,  True, False, False, False,  True, False,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False,  True,  True, False,  True,\n",
              "       False, False,  True,  True,  True,  True, False, False,  True,\n",
              "       False,  True,  True, False, False,  True, False,  True, False,\n",
              "        True, False, False,  True, False, False, False, False,  True,\n",
              "        True,  True, False, False, False, False,  True,  True, False,\n",
              "       False, False,  True, False,  True, False, False, False, False,\n",
              "       False, False,  True,  True,  True,  True,  True, False, False,\n",
              "        True, False,  True, False,  True,  True, False, False,  True])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(predictions==train_gen.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-16T18:01:04.970161Z",
          "iopub.status.busy": "2022-11-16T18:01:04.969375Z",
          "iopub.status.idle": "2022-11-16T18:01:04.976709Z",
          "shell.execute_reply": "2022-11-16T18:01:04.975824Z",
          "shell.execute_reply.started": "2022-11-16T18:01:04.970123Z"
        },
        "id": "znuWSzLpOMmM",
        "outputId": "b4528804-53d8-49ea-e268-33cfab07e429"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 2, 5, 9])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "=out = np.where(np.any(predictions>0.1, axis=1))[0]\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-16T18:02:42.701891Z",
          "iopub.status.busy": "2022-11-16T18:02:42.700589Z",
          "iopub.status.idle": "2022-11-16T18:02:42.719362Z",
          "shell.execute_reply": "2022-11-16T18:02:42.718058Z",
          "shell.execute_reply.started": "2022-11-16T18:02:42.701847Z"
        },
        "id": "dy52JHV1OMmM",
        "outputId": "4042dc25-bea3-475c-aa97-794333014c53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for idx in output:\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T20:54:44.242661Z",
          "iopub.status.busy": "2022-11-15T20:54:44.242288Z",
          "iopub.status.idle": "2022-11-15T20:54:44.251015Z",
          "shell.execute_reply": "2022-11-15T20:54:44.248927Z",
          "shell.execute_reply.started": "2022-11-15T20:54:44.242630Z"
        },
        "id": "cgZiGoBtOMmM"
      },
      "outputs": [],
      "source": [
        "import tensorflow.experimental.numpy as tnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T21:47:34.341003Z",
          "iopub.status.busy": "2022-11-15T21:47:34.340631Z",
          "iopub.status.idle": "2022-11-15T21:47:34.352698Z",
          "shell.execute_reply": "2022-11-15T21:47:34.351398Z",
          "shell.execute_reply.started": "2022-11-15T21:47:34.340971Z"
        },
        "id": "lKosDykBOMmM",
        "outputId": "62da3898-4be8-4622-a023-bbf06842a842"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = tnp.zeros(1, dtype=tf.dtypes.int64)\n",
        "len(list(a.numpy()))\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T20:53:14.452587Z",
          "iopub.status.busy": "2022-11-15T20:53:14.451478Z",
          "iopub.status.idle": "2022-11-15T20:53:14.480314Z",
          "shell.execute_reply": "2022-11-15T20:53:14.478924Z",
          "shell.execute_reply.started": "2022-11-15T20:53:14.452532Z"
        },
        "id": "jrsqF1hMOMmM",
        "outputId": "2ce9967f-405e-47f1-baa9-3a6a174eec0f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_23/981408806.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
          ]
        }
      ],
      "source": [
        "a = np.array\n",
        "a.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-11-15T19:14:32.449264Z",
          "iopub.status.busy": "2022-11-15T19:14:32.448161Z",
          "iopub.status.idle": "2022-11-15T19:14:32.457516Z",
          "shell.execute_reply": "2022-11-15T19:14:32.456398Z",
          "shell.execute_reply.started": "2022-11-15T19:14:32.449217Z"
        },
        "id": "pNo7fG3vOMmN",
        "outputId": "9aecd0b3-d4c2-4981-fd00-8ebfe9f23e7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_gen.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T13:46:26.075742Z",
          "iopub.status.busy": "2022-11-15T13:46:26.075408Z",
          "iopub.status.idle": "2022-11-15T13:46:26.081413Z",
          "shell.execute_reply": "2022-11-15T13:46:26.080292Z",
          "shell.execute_reply.started": "2022-11-15T13:46:26.075710Z"
        },
        "id": "jAgdSKqjNG50",
        "outputId": "6dcbd59f-94af-4735-9477-406ea45a53bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(0 in output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T10:24:57.182965Z",
          "iopub.status.busy": "2022-11-15T10:24:57.182563Z",
          "iopub.status.idle": "2022-11-15T10:24:57.190205Z",
          "shell.execute_reply": "2022-11-15T10:24:57.189192Z",
          "shell.execute_reply.started": "2022-11-15T10:24:57.182931Z"
        },
        "id": "Fiw8TQBMPGwe",
        "outputId": "40fc7945-a581-4551-97ae-1804dfd820fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1], dtype=int32)"
            ]
          },
          "execution_count": 388,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_gen.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-14T22:09:24.207809Z",
          "iopub.status.busy": "2022-11-14T22:09:24.207454Z",
          "iopub.status.idle": "2022-11-14T22:09:24.212552Z",
          "shell.execute_reply": "2022-11-14T22:09:24.211478Z",
          "shell.execute_reply.started": "2022-11-14T22:09:24.207777Z"
        },
        "id": "k1hREHJCOMmN"
      },
      "outputs": [],
      "source": [
        "n_others = (test_gen.labels == 0).sum()\n",
        "n_others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-14T22:09:22.056662Z",
          "iopub.status.busy": "2022-11-14T22:09:22.056272Z",
          "iopub.status.idle": "2022-11-14T22:09:22.063081Z",
          "shell.execute_reply": "2022-11-14T22:09:22.062006Z",
          "shell.execute_reply.started": "2022-11-14T22:09:22.056631Z"
        },
        "id": "0_cQ4BACOMmO"
      },
      "outputs": [],
      "source": [
        "n_ones = (test_gen.labels == 1).sum()\n",
        "n_ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-14T22:09:40.136131Z",
          "iopub.status.busy": "2022-11-14T22:09:40.135748Z",
          "iopub.status.idle": "2022-11-14T22:09:40.143867Z",
          "shell.execute_reply": "2022-11-14T22:09:40.142392Z",
          "shell.execute_reply.started": "2022-11-14T22:09:40.136098Z"
        },
        "id": "0lAkdhd0OMmO",
        "outputId": "5ff53f6a-f742-41e3-efef-1395f8a5b9e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16.85"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_others/n_ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-83ete1O0DT6"
      },
      "source": [
        "# Model saving\n",
        "The model is saved and it can be reloaded if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWuFBdq8qpDj"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save(mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWuzJ8KirX8c"
      },
      "outputs": [],
      "source": [
        "(test_gen.labels == 0).sum()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "L2ZFGy0YOMmD",
        "lqkwFZMrFC8A",
        "MExAxJIzZo-N",
        "caYlR35qFREK",
        "klvPMoR2F-JJ",
        "-83ete1O0DT6"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}