{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Notebook for ANNDL - Homework 1\n",
    "\n",
    "Team: All Is Well\n",
    "\n",
    "Team members: Fatma Hamila, Kodai Takigawa, Zheng Maria Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction\n",
    "This notebook is used to ensemble K-Fold cross validation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2607, 96, 96, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from albumentations import *\n",
    "import albumentations as alb\n",
    "\n",
    "class PlantDataset():\n",
    "    \"\"\"The class PlantDataset loads the data and executes the pre-processing operations on it\"\"\"\n",
    "\n",
    "    def __init__(self, path,n_fold,i,one_hot=False):\n",
    "        images = self.load_images(path)\n",
    "        self.images1, self.labels1, self.images2,self.labels2 = self.split_images(images, n_fold,i)\n",
    "        if one_hot:\n",
    "            self.labels1=self.onehot(self.labels1)\n",
    "            self.labels2=self.onehot(self.labels2)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_images(images, n_fold,i):\n",
    "        train_data = []\n",
    "        train_labels = []\n",
    "        test_data = []\n",
    "        test_labels = []\n",
    "        for k in images.keys():\n",
    "            n = len(images[k])//n_fold\n",
    "            train_data += images[k][:i*n]+images[k][(i+1)*n:]\n",
    "            test_data += images[k][i*n:(i+1)*n]\n",
    "            train_labels += [k] * (len(images[k]) - n)\n",
    "            test_labels += [k] * (n)\n",
    "        return np.asarray(train_data), np.asarray(train_labels), np.asarray(test_data), np.asarray(test_labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def onehot(x,n_class=8):\n",
    "        y=np.zeros((len(x),n_class))\n",
    "        for i in range(n_class):\n",
    "            y[np.where(x==i),i]=1\n",
    "        return y\n",
    "\n",
    "    def get_images(self):\n",
    "        return self.images1, self.labels1,self.images2, self.labels2\n",
    "\n",
    "    @staticmethod\n",
    "    def load_images(image_path):\n",
    "        \"\"\"This method loads the images from the given path\"\"\"\n",
    "        images = {}\n",
    "        for i, file in enumerate(os.listdir(image_path)):\n",
    "            for img in os.listdir(os.path.join(image_path, file)):\n",
    "                path = os.path.join(image_path, file, img)\n",
    "                image = Image.open(path)\n",
    "                if i in images:\n",
    "                    images[i].append(np.asarray(image))\n",
    "                else:\n",
    "                    images[i]=[np.asarray(image)]\n",
    "\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images1)\n",
    "\n",
    "ds=PlantDataset(\"data/train/\",n_fold=1,i=0,one_hot=True)\n",
    "train_data,train_labels,test_data,test_labels=ds.get_images()\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "seed = 23\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define categorical focal loss\n",
    "from keras import backend as K\n",
    "def categorical_focal_loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred: A tensor resulting from a softmax\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        alpha = np.array([0.25,0.1,0.1,0.1,0.1,0.1,0.1,0.15], dtype=np.float32)\n",
    "        gamma=2\n",
    "        # Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Calculate Cross Entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        # Calculate Focal Loss\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "        # Compute mean loss in mini_batch\n",
    "        return K.mean(K.sum(loss, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3264, 96, 96, 3) (3264,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3264, 96, 96, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=PlantDataset(\"training_data_final/\",n_fold=1,i=0)\n",
    "train_data,train_labels,test_data,test_labels=ds.get_images()\n",
    "print(test_data.shape,test_labels.shape)\n",
    "data=np.asarray(test_data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    X = np.reshape(X, (-1, 96, 96, 3))\n",
    "    assert X.ndim == 4\n",
    "    from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "    X = preprocess_input(X)\n",
    "    X=tf.image.resize(X,(224,224),method='gaussian')\n",
    "    prediction = model.predict(X)\n",
    "    output = tf.argmax(prediction, axis=-1)\n",
    "    return output,prediction\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(ds, model,step=100,data=None):\n",
    "    \"\"\"Compute the accuracy rate on the given dataset with the input model\"\"\"\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    num_correct = 0\n",
    "    if data is not None:\n",
    "        data,target=data\n",
    "    else:\n",
    "        data,target=ds.get_images()\n",
    "    loop=tqdm(range(0,len(data)//step+1))\n",
    "    tp=[0]*8\n",
    "    tn=[0]*8\n",
    "    fp=[0]*8\n",
    "    fn=[0]*8\n",
    "    for i in loop:\n",
    "        x=data[i*step:min(len(data),(i+1)*step)]\n",
    "        y=target[i*step:min(len(data),(i+1)*step)]\n",
    "        output,_ = predict(model,x)\n",
    "        c=np.array(y==output)\n",
    "        num_correct += sum(c)\n",
    "        for a,b in zip(y,output):\n",
    "            if a==b:\n",
    "                tp[a]+=1\n",
    "                for i in range(8):\n",
    "                    if i==a:\n",
    "                        continue\n",
    "                    tn[i]+=1\n",
    "            else:\n",
    "                fp[b]+=1\n",
    "                fn[a]+=1\n",
    "                for i in range(8):\n",
    "                    if i==a or i==b:\n",
    "                        continue\n",
    "                    tn[i]+=1\n",
    "\n",
    "\n",
    "    print(num_correct/len(data))\n",
    "    f1=[]\n",
    "    for i in range(8):\n",
    "        precision=tp[i]/(tp[i]+fp[i]+1e-3)\n",
    "        recall=tp[i]/(tp[i]+fn[i]+1e-3)\n",
    "        f1.append(2 * precision * recall / (precision + recall + 1e-3))\n",
    "        print(\"class:\",i,\"f1 score:\",2 * precision * recall / (precision + recall + 1e-3),\"precision:\",precision,\"recall:\",recall)\n",
    "    print(\"overall:\",sum(f1)/8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load single models\n",
    "model = tfk.models.load_model(\"Final/KF1.ckpt\")\n",
    "#accuracy(ds,model,data=(data,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:15<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9954044117647058\n",
      "class: 0 f1 score: 0.9888567486842236 precision: 0.9789422160935994 recall: 0.9999946236848188\n",
      "class: 1 f1 score: 0.9947769472249179 precision: 0.9999981024703939 recall: 0.9905996417299968\n",
      "class: 2 f1 score: 0.995622353261903 precision: 0.9941953690611818 recall: 0.9980563144537584\n",
      "class: 3 f1 score: 0.9955844072479714 precision: 0.9960841563910834 recall: 0.9960841563910834\n",
      "class: 4 f1 score: 0.9938379996080113 precision: 0.9962173984548234 recall: 0.9924651742652086\n",
      "class: 5 f1 score: 0.9972384121821163 precision: 0.9999954751335967 recall: 0.9954910113017509\n",
      "class: 6 f1 score: 0.9976361942224039 precision: 0.998135943880924 recall: 0.998135943880924\n",
      "class: 7 f1 score: 0.9908379612547786 precision: 0.9870647109279701 recall: 0.9956478450093695\n",
      "overall: 0.9942988779607908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of single models\n",
    "accuracy(ds,model,data=(data,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Ensembling\n",
    "Here we define the model ensembling procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ensemble the models together\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model0=tfk.models.load_model(\"Final/KF_0.ckpt\")\n",
    "        self.model1=tfk.models.load_model(\"Final/KF_1.ckpt\")\n",
    "        self.model2=tfk.models.load_model(\"Final/KF_2.ckpt\")\n",
    "        self.model3=tfk.models.load_model(\"Final/KF_3.ckpt\")\n",
    "        self.model4=tfk.models.load_model(\"Final/KF_4.ckpt\")\n",
    "\n",
    "\n",
    "    def call(self,x):\n",
    "        y=self.model0(x)\n",
    "        y+=self.model1(x)\n",
    "        y+=self.model2(x)\n",
    "        y+=self.model3(x)\n",
    "        y+=self.model4(x)\n",
    "\n",
    "        return y/5\n",
    "\n",
    "    def predict(self,x):\n",
    "        y=self.model0.predict(x)\n",
    "        y+=self.model1.predict(x)\n",
    "        y+=self.model2.predict(x)\n",
    "        y+=self.model3.predict(x)\n",
    "        y+=self.model4.predict(x)\n",
    "\n",
    "        return y/5\n",
    "\n",
    "model=Model()\n",
    "#accuracy(ds,model,data=(data,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Final/KF1.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Final/KF1.ckpt\\assets\n"
     ]
    }
   ],
   "source": [
    "# Compile and save the final model\n",
    "loss=tfk.losses.CategoricalCrossentropy()\n",
    "optimizer = tfk.optimizers.SGD(learning_rate=1e-1)\n",
    "metrics = ['accuracy']\n",
    "input_layer = tfkl.Input(shape=(224,224,3), name='Input')\n",
    "x=model(input_layer)\n",
    "model = tfk.Model(inputs=input_layer, outputs=x)\n",
    "model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics\n",
    "    )\n",
    "model.save('Final/KF1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8569254185692542\n",
      "class: 0 f1 score: 0.6217208758828198 precision: 0.538451183631084 recall: 0.7368227151917055\n",
      "class: 1 f1 score: 0.8664882867488837 precision: 0.9166571181550192 recall: 0.8224222203530808\n",
      "class: 2 f1 score: 0.8947300295443079 precision: 0.8784964626498818 recall: 0.9126124989077775\n",
      "class: 3 f1 score: 0.8818446219209709 precision: 0.8910802863337987 recall: 0.87377792448617\n",
      "class: 4 f1 score: 0.871052091961182 precision: 0.8558481455122026 recall: 0.8878421696993486\n",
      "class: 5 f1 score: 0.8935986170395227 precision: 0.9499762505937352 recall: 0.8444256794293461\n",
      "class: 6 f1 score: 0.9478482653943285 precision: 0.9618956009942762 recall: 0.9351765261432764\n",
      "class: 7 f1 score: 0.636849081924881 precision: 0.6444301237750273 recall: 0.6304210778026565\n",
      "overall: 0.826766483802112\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863013698630137\n",
      "class: 0 f1 score: 0.5864592845378112 precision: 0.49999074091220536 recall: 0.7105076182205732\n",
      "class: 1 f1 score: 0.8757852190421765 precision: 0.9770002643647774 recall: 0.7943850992046803\n",
      "class: 2 f1 score: 0.9225683642888186 precision: 0.9142770068856486 recall: 0.9320297861185813\n",
      "class: 3 f1 score: 0.872040799647595 precision: 0.8811793942634231 recall: 0.8640692808807681\n",
      "class: 4 f1 score: 0.8762048676579934 precision: 0.8571352041499629 recall: 0.8971878767488154\n",
      "class: 5 f1 score: 0.9190199571059905 precision: 0.9523582771838767 recall: 0.888869136241417\n",
      "class: 6 f1 score: 0.9669331301773257 precision: 0.97195353314455 recall: 0.9629540467217895\n",
      "class: 7 f1 score: 0.6310665445838176 precision: 0.6122324034203384 recall: 0.6521597356579205\n",
      "overall: 0.8312597708801911\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8736681887366818\n",
      "class: 0 f1 score: 0.6185378113469693 precision: 0.5652051042368644 recall: 0.6841925212494409\n",
      "class: 1 f1 score: 0.8926962446536012 precision: 0.9292835425904789 recall: 0.8598050485509481\n",
      "class: 2 f1 score: 0.9321836536608701 precision: 0.9238007257073741 recall: 0.9417384297239833\n",
      "class: 3 f1 score: 0.8872965099439855 precision: 0.8921481161949393 recall: 0.8834865680915719\n",
      "class: 4 f1 score: 0.8957182834517574 precision: 0.9047532880639232 recall: 0.8878421696993486\n",
      "class: 5 f1 score: 0.8983565465054967 precision: 0.9090702484034454 recall: 0.888869136241417\n",
      "class: 6 f1 score: 0.93902642069785 precision: 0.9439164119961495 recall: 0.9351765261432764\n",
      "class: 7 f1 score: 0.6731708966807848 precision: 0.6530478969816943 recall: 0.6956370513684486\n",
      "overall: 0.8421232958676643\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867579908675799\n",
      "class: 0 f1 score: 0.6201837692386253 precision: 0.5510091630783045 recall: 0.7105076182205732\n",
      "class: 1 f1 score: 0.8794939311965403 precision: 0.9462263846625305 recall: 0.8224222203530808\n",
      "class: 2 f1 score: 0.9233011773883858 precision: 0.9065335837982822 recall: 0.9417384297239833\n",
      "class: 3 f1 score: 0.8782801018556415 precision: 0.9157798338964852 recall: 0.8446519936699644\n",
      "class: 4 f1 score: 0.8773208959075021 precision: 0.8508697292129016 recall: 0.9065335837982822\n",
      "class: 5 f1 score: 0.8935986170395227 precision: 0.9499762505937352 recall: 0.8444256794293461\n",
      "class: 6 f1 score: 0.9478482653943285 precision: 0.9618956009942762 recall: 0.9351765261432764\n",
      "class: 7 f1 score: 0.6994895524952208 precision: 0.6481361456269329 recall: 0.7608530249342406\n",
      "overall: 0.8399395388144708\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8751902587519026\n",
      "class: 0 f1 score: 0.5778033001205505 precision: 0.5333214817448502 recall: 0.6315623273071762\n",
      "class: 1 f1 score: 0.8994937249540469 precision: 0.9677315297684971 recall: 0.8411136344520145\n",
      "class: 2 f1 score: 0.9127357025933729 precision: 0.8620615339522935 recall: 0.9708643605401889\n",
      "class: 3 f1 score: 0.9004816515634985 precision: 0.9191826345188432 recall: 0.8834865680915719\n",
      "class: 4 f1 score: 0.8937228659346326 precision: 0.9207829625449253 recall: 0.8691507556004149\n",
      "class: 5 f1 score: 0.8883694173395458 precision: 0.888869136241417 recall: 0.888869136241417\n",
      "class: 6 f1 score: 0.9523216398504022 precision: 0.9711445082258824 recall: 0.9351765261432764\n",
      "class: 7 f1 score: 0.7194891427226576 precision: 0.6666543212162738 recall: 0.7825916827895046\n",
      "overall: 0.8430521806348384\n",
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8858447488584474\n",
      "class: 0 f1 score: 0.6105960856477562 precision: 0.6470397929472663 recall: 0.5789321333649114\n",
      "class: 1 f1 score: 0.9049659923645027 precision: 0.9680748077148115 recall: 0.8504593415014813\n",
      "class: 2 f1 score: 0.9340716702975307 precision: 0.9008927847496869 recall: 0.9708643605401889\n",
      "class: 3 f1 score: 0.8775405106886773 precision: 0.8823442907422476 recall: 0.87377792448617\n",
      "class: 4 f1 score: 0.8980428922746311 precision: 0.929990700092999 recall: 0.8691507556004149\n",
      "class: 5 f1 score: 0.9445344997865772 precision: 0.9347622877763527 recall: 0.9555343214595232\n",
      "class: 6 f1 score: 0.9406684743737991 precision: 0.9203458376474544 recall: 0.9629540467217895\n",
      "class: 7 f1 score: 0.7567728741079278 precision: 0.6841985228329328 recall: 0.8478076563552966\n",
      "overall: 0.8583991249426753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose the best models to ensemble together\n",
    "for n in [16,18,27,28,34,90]:\n",
    "    print(n)\n",
    "    model = tfk.models.load_model(\"experiments/FT_KF_EFF_B0_4Cos_0_Nov23_10-56-11\"+\"/base_ckpts/cp_\"+str(n)+\".ckpt\",\n",
    "                                  custom_objects={\"categorical_focal_loss\": categorical_focal_loss})\n",
    "    accuracy(ds,model,data=(data,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-83ete1O0DT6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model saving\n",
    "The model is saved and it can be reloaded if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2376,
     "status": "ok",
     "timestamp": 1637329343715,
     "user": {
      "displayName": "Maria Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14411329470521378870"
     },
     "user_tz": -60
    },
    "id": "KWuFBdq8qpDj",
    "outputId": "10047537-b514-445c-ec90-25156d117bcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Baseline/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Baseline/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(mode)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOPyCRRk0/5km7Xtc6Ky4m6",
   "mount_file_id": "1O_120kCNjLtqhdQFRsW98ZfKb0e80IiF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}